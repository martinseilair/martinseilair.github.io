<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="3.8.4">Jekyll</generator><link href="http://localhost:4000/feed.xml" rel="self" type="application/atom+xml" /><link href="http://localhost:4000/" rel="alternate" type="text/html" /><updated>2018-11-07T01:10:28+09:00</updated><id>http://localhost:4000/feed.xml</id><title type="html">Ikigai</title><subtitle>A dump for random thoughts and observations</subtitle><entry><title type="html">Observability: A Bayesian perspective</title><link href="http://localhost:4000/jekyll/update/2018/11/07/observability.html" rel="alternate" type="text/html" title="Observability: A Bayesian perspective" /><published>2018-11-07T01:04:07+09:00</published><updated>2018-11-07T01:04:07+09:00</updated><id>http://localhost:4000/jekyll/update/2018/11/07/observability</id><content type="html" xml:base="http://localhost:4000/jekyll/update/2018/11/07/observability.html">&lt;p&gt;Observability is an important concept of classical control theory. Quite often it is motivated by abstract concepts, that are not intuitive at all. In this article, we will take a look at observability from a Bayesian perspective and will find a natural interpretation of observability.
&lt;!--more--&gt;
&lt;script src=&quot;https://d3js.org/d3.v5.min.js&quot; charset=&quot;utf-8&quot;&gt;&lt;/script&gt;
&lt;script type=&quot;text/javascript&quot; async=&quot;&quot; src=&quot;https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_SVG&quot;&gt;&lt;/script&gt;
  &lt;script src=&quot;https://cdn.plot.ly/plotly-latest.min.js&quot;&gt;&lt;/script&gt;&lt;/p&gt;

&lt;p&gt;Let’s begin by stating the definition of &lt;a href=&quot;https://en.wikipedia.org/wiki/Observability&quot;&gt;observability&lt;/a&gt; from classical control theory.&lt;/p&gt;
&lt;div class=&quot;important_box&quot;&gt;
  Formally, a system is said to be observable, if for any possible sequence of state and control vectors (the latter being variables whose values one can choose), the current state (the values of the underlying dynamically evolving variables) can be determined in finite time using only the outputs.
&lt;/div&gt;

&lt;p&gt;We can easily translate this definition into the language of Bayesian inference:&lt;/p&gt;

&lt;div class=&quot;important_box&quot;&gt;
  A system is said to be observable if for any possible initial state and sequence of control vectors, the probability mass of the posterior of the current state will collapse into a single point in finite time.
&lt;/div&gt;

&lt;p&gt;Normally, we are using the idea of observability in the setting of deterministic time-invariant linear state space models, which are defined by&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{align}x_{t+1} &amp;= Ax_t + B u_t \\ 
y_t &amp;= Cx_t  \end{align} %]]&gt;&lt;/script&gt;

&lt;p&gt;with state \(x_t\), output \(y_t\), input \(u_t\), system matrix \(A\), input matrix \(B\) and output matrix \(C\).&lt;/p&gt;

&lt;p&gt;Based on the methods shown in the last post about &lt;a href=&quot;/jekyll/update/2018/11/06/linalg-gaussian.html&quot;&gt;linear algebra with Gauss and Bayes&lt;/a&gt;, we can reformulate these deterministic equations with Gaussian distributions&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\mathcal{N}(x_{t+1}|Ax_t + Bu_t, \delta I)&lt;/script&gt;

&lt;p&gt;and&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\mathcal{N}(y_t|Cx_t, \delta I)&lt;/script&gt;

&lt;p&gt;where \(\delta \to 0\).&lt;/p&gt;

&lt;p&gt;Now that we arrived at a probabilistic description, we can use Bayesian inference to infer the current state \(x_t\). In particular, we are interested in the uncertainty of our estimate of the current state: Our system will be observable if the covariance of the estimate will go to zero.&lt;/p&gt;

&lt;h1 id=&quot;derivation&quot;&gt;Derivation&lt;/h1&gt;

&lt;p&gt;First of all, we are defining a Gaussian prior distribution of the initial state \(x_0\)&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;p(x_0) = \mathcal{N}(x_0|0,I).&lt;/script&gt;

&lt;p&gt;The choice of the mean and covariance are actually arbitrary, as long as the covariance is positive definite.&lt;/p&gt;

&lt;p&gt;Now let’s plug our distributions into the equations of the Bayes filter, which are described by the &lt;strong&gt;prediction step&lt;/strong&gt;&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;p(x_{t+1}|y_{0:t},u_{0:t}) = \int_{x_{t}} p(x_{t+1}|x_{t}, u_{t})p(x_{t}|y_{0:t},u_{0:t-1}) dx_{t}&lt;/script&gt;

&lt;p&gt;and the &lt;strong&gt;update step&lt;/strong&gt;&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;p(x_t|y_{0:t},u_{0:t-1}) = \frac{p(y_t|x_t)p(x_t|y_{0:t-1},u_{0:t-1})}{\int_{x_t}p(y_t|x_t)p(x_t|y_{0:t-1},u_{0:t-1}) \,dx_t} .&lt;/script&gt;

&lt;p&gt;Fortunately, we already know how to do inference in linear Gaussian state space models. We can simply use the equations of the Kalman filter and obtain the following equations for the &lt;strong&gt;prediction step&lt;/strong&gt;&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{align}\hat x_{t+1|t} &amp;=  A \hat x_{t|t} + Bu_t \\ 
P_{t+1|t} &amp;= \delta I + A P_{t|t} A^T  \end{align} %]]&gt;&lt;/script&gt;

&lt;p&gt;and the &lt;strong&gt;update step&lt;/strong&gt;&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{align}\hat x_{t|t} &amp;= \hat x_{t|t-1} + P_{t|t-1}C^T(\delta I + CP_{t|t-1}C^T)^{-1}(y_{t}-C\hat x_{t|t-1}) \\ 
P_{t|t} &amp;= P_{t|t-1} - P_{t|t-1}C^T (\delta I + CP_{t|t-1}C^T)^{-1}CP_{t|t-1} .\end{align} %]]&gt;&lt;/script&gt;

&lt;p&gt;If this was too fast, please check out the earlier blog post on &lt;a href=&quot;/jekyll/update/2018/10/10/kalman_filter.html&quot;&gt;Kalman filtering&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;Observability depends only on the covariance of the estimates \( P \). Therefore, the question of observability of a linear state space model is reduced to the question, if the equations&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{align}
P_{t+1|t} &amp;= \delta I + A P_{t|t} A^T \\ 
P_{t|t} &amp;=(I-P_{t|t-1}C^T(\delta I + CP_{t|t-1}C^T)^{-1}C)P_{t|t-1}  
\end{align} %]]&gt;&lt;/script&gt;

&lt;p&gt;are going to transform an arbitrary positive definite initial covariance matrix \(P_0\) to 0.&lt;/p&gt;
&lt;div class=&quot;extra_box&quot;&gt;
  &lt;p&gt;When we combine the prediction and update to a single equation&lt;/p&gt;

  &lt;script type=&quot;math/tex; mode=display&quot;&gt;P_{t+1} = \delta I + A (I-P_{t}C^T(\delta I + CP_{t}C^T)^{-1}C)P_{t} A^T&lt;/script&gt;

  &lt;p&gt;and look very closely we can identify the &lt;a href=&quot;https://en.wikipedia.org/wiki/Algebraic_Riccati_equation#Context_of_the_discrete-time_algebraic_Riccati_equation&quot;&gt;discrete-time algebraic Ricatti equation&lt;/a&gt;&lt;/p&gt;

  &lt;script type=&quot;math/tex; mode=display&quot;&gt;P_{t+1} = \delta I + AP_{t} A^T  - AP_{t}C^T(\delta I + CP_{t}C^T)^{-1}CP_{t} A^T.&lt;/script&gt;

&lt;/div&gt;
&lt;p&gt;Let’s try to interpret what our two equations are doing with the covariance estimate \(P\). As a mental model, it is helpful to imagine the particular covariance matrices as subspaces.
We begin with our prior variance \(P_0\). We have selected our prior variance in such a way, that it describes the entire state space.&lt;/p&gt;

&lt;p&gt;We are starting by taking an update step. The update step can be interpreted as calculating the intersection of the prior subspace and the subspace defined by all points \(x\) that map to the observed output \(y_0\). We will call this last subspace the &lt;em&gt;inverse subspace&lt;/em&gt;.
We took the intersection of the whole state space and &lt;em&gt;inverse subspace&lt;/em&gt;. As a result, our posterior will be simply the inverse subspace.
Let’s see what happens, if we take the prediction step. If we assume that \(A\) has full rank, the dimensionality of the subspace will remain the same. Depending on the matrix \(A\) two things can happen:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;The transformation won’t change the subspace, but only the representation of the subspace.&lt;/li&gt;
  &lt;li&gt;The transformation is changing the subspace.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Depending on these two cases we will have two cases for the next update step:&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;The transformation didn’t change the subspace.&lt;/strong&gt; In this case, the update step would have no effect, because we are intersecting again with the &lt;em&gt;same&lt;/em&gt; inverse subspace. Formally, after the prediction step our posterior would still be the orthogonal &lt;a href=&quot;https://en.wikipedia.org/wiki/Moore%E2%80%93Penrose_inverse#Projectors&quot;&gt;projector&lt;/a&gt; onto the kernel of \(C\)&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;P_{0|0} = I - C^+C.&lt;/script&gt;

&lt;p&gt;We know that \(C(I - C^+C) = 0\) and \((I - C^+C)C^T = 0\), therefore, our update step simplifies to&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;P_{t|t} =P_{t|t-1}-\underbrace{P_{t|t-1}C^T}_{0}(\delta I + \underbrace{CP_{t|t-1}}_{0}C^T)^{-1}\underbrace{CP_{t|t-1}}_{0} =  P_{t|t-1}.&lt;/script&gt;

&lt;p&gt;It seems, that we can’t rid of this &lt;em&gt;unobservable&lt;/em&gt; subspace. Therefore, we have &lt;strong&gt;no&lt;/strong&gt; observability.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;The transformation did change the subspace.&lt;/strong&gt; In this case, the intersection with the inverse subspace will again have an effect. The dimensionality of the posterior subspace will get smaller.&lt;/p&gt;

&lt;p&gt;We have to repeat the process of prediction and updating until the subspace of our posterior has either dimension zero or the prediction step is again not changing our subspace.
In the first case, we have no uncertainty: The system is observable. In the second case, the system is not observable.&lt;/p&gt;

&lt;h1 id=&quot;summary&quot;&gt;Summary&lt;/h1&gt;

&lt;p&gt;In this post, we looked at the concept of observability from a Bayesian standpoint. We found an intuitive way to reason about the effect of the update step and prediction step in terms of subspaces, described by covariance matrices.&lt;/p&gt;</content><author><name></name></author><summary type="html">Observability is an important concept of classical control theory. Quite often it is motivated by abstract concepts, that are not intuitive at all. In this article, we will take a look at observability from a Bayesian perspective and will find a natural interpretation of observability.</summary></entry><entry><title type="html">Linear algebra with Gauss and Bayes</title><link href="http://localhost:4000/jekyll/update/2018/11/06/linalg-gaussian.html" rel="alternate" type="text/html" title="Linear algebra with Gauss and Bayes" /><published>2018-11-06T12:04:07+09:00</published><updated>2018-11-06T12:04:07+09:00</updated><id>http://localhost:4000/jekyll/update/2018/11/06/linalg-gaussian</id><content type="html" xml:base="http://localhost:4000/jekyll/update/2018/11/06/linalg-gaussian.html">&lt;p&gt;&lt;a href=&quot;https://en.wikipedia.org/wiki/Linear_algebra&quot;&gt;Linear algebra&lt;/a&gt; is a wonderful field of mathematics with endless applications. Despite its obvious beauty, it can also be quite confusing. Especially, when it comes to subspaces, inverses and determinants. In this article, I want to present a different view on some aspects of linear algebra with the help of &lt;a href=&quot;https://en.wikipedia.org/wiki/Multivariate_normal_distribution&quot;&gt;Gaussian distributions&lt;/a&gt; and &lt;a href=&quot;https://en.wikipedia.org/wiki/Bayes%27_theorem&quot;&gt;Bayes theorem&lt;/a&gt;.
&lt;!--more--&gt;
&lt;script src=&quot;https://d3js.org/d3.v5.min.js&quot; charset=&quot;utf-8&quot;&gt;&lt;/script&gt;
&lt;script type=&quot;text/javascript&quot; async=&quot;&quot; src=&quot;https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_SVG&quot;&gt;&lt;/script&gt;
  &lt;script src=&quot;https://cdn.plot.ly/plotly-latest.min.js&quot;&gt;&lt;/script&gt;
  &lt;script type=&quot;text/javascript&quot; src=&quot;http://localhost:4000/assets/js/math.min.js&quot;&gt;&lt;/script&gt;&lt;/p&gt;

&lt;p&gt;This post is about the very basic equation&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;Ax = b,&lt;/script&gt;

&lt;p&gt;where \(A \in \mathbb{R}^{m\times n}\), \(x \in \mathbb{R}^{n}\) and \(b \in \mathbb{R}^{m}\). With the help of the Gaussian distribution&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\mathcal{N}(x|\mu, \Sigma),&lt;/script&gt;

&lt;p&gt;we can restate this equation in the language of probability theory.&lt;/p&gt;

&lt;h1 id=&quot;matrix-transformation&quot;&gt;Matrix transformation&lt;/h1&gt;
&lt;p&gt;The transformation of our vector \(x\) with matrix \(A\) becomes a marginalization&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\int_\hat{x} \mathcal{N}(b|A\hat{x}, \Sigma_b)\mathcal{N}(\hat{x}|x, \Sigma_x) \,d\hat{x}.&lt;/script&gt;

&lt;p&gt;Please be aware, that this formula is &lt;strong&gt;not&lt;/strong&gt; equivalent to our matrix product above. We introduced two new variables \(\Sigma_x\) and \(\Sigma_b\), which represents the covariance matrix of the corresponding Gaussian distributions.
The two formulations will become equivalent if the covariance matrices will go to zero.
Let’s check if this is true!&lt;/p&gt;

&lt;p&gt;We can use the propagation formula&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\int_{y}\mathcal{N}(x|a + Fy, A)\mathcal{N}(y|b,B) dx_t = \mathcal{N}(x|a + Fb, A + FBF^T ).&lt;/script&gt;

&lt;p&gt;from the &lt;a href=&quot;https://ipvs.informatik.uni-stuttgart.de/mlr/marc/notes/gaussians.pdf&quot;&gt;Gaussian identities&lt;/a&gt; by Marc Toussaint to reformulate our marginalization.&lt;/p&gt;

&lt;p&gt;In our case, we will end up with&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\int_\hat{x} \mathcal{N}(b|A\hat{x}, \Sigma_b)\mathcal{N}(\hat{x}|x, \Sigma_x) \,d\hat{x} = \mathcal{N}(b|Ax, \Sigma_b + A\Sigma_xA^T ).&lt;/script&gt;

&lt;p&gt;If we let \(\Sigma_x\) and \(\Sigma_b\) go to zero, the resulting covariance will go to zero as well. In the limit, the entire probability mass will be concentrated at our mean \(Ax\), which is exactly what we wanted to show.
Up until now, there is nothing fancy about this result. It’s just a weird way to write the matrix multiplication. But when we think about the inverse of the transformation \(Ax = b\), things will become more interesting.&lt;/p&gt;

&lt;h1 id=&quot;inverse&quot;&gt;Inverse&lt;/h1&gt;

&lt;p&gt;What does it mean to take the inverse transformation? What is the desired result? By taking the inverse operation, we are simply asking for the set of points \(x\) which would be transformed to \(b\). We normally express the inverse transformation as&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;x = A^{-1}b.&lt;/script&gt;

&lt;p&gt;But you have to be careful: This equations only hold, if the matrix \(A\) has full rank. In this case, there is exactly one point \(x\) that maps to \(b\). But we shouldn’t waste our time on special cases. Let’s directly look at the general case for an arbitrary matrix \(A\).&lt;/p&gt;

&lt;p&gt;We come back to our old friends Gauss and Bayes and try to formulate the inverse operation in terms of Gaussian distributions and Bayes theorem&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;p(x|y) = \frac{p(y|x)p(x)}{\int_x p(y|x)p(x) \,dx}.&lt;/script&gt;

&lt;p&gt;We insert our Gaussian distributions and obtain&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;p(\hat{x}|b) =  \frac{\mathcal{N}(b|A\hat{x}, \Sigma_b)\mathcal{N}(\hat{x}|x, \Sigma_x)}{\int_\hat{x} \mathcal{N}(b|A\hat{x}, \Sigma_b)\mathcal{N}(\hat{x}|x, \Sigma_x) \,d\hat{x}}.&lt;/script&gt;

&lt;p&gt;To simplify this expression we can use equation 39 and 40 from the &lt;a href=&quot;https://ipvs.informatik.uni-stuttgart.de/mlr/marc/notes/gaussians.pdf&quot;&gt;Gaussian identities&lt;/a&gt; and obtain&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\mathcal{N}(\hat{x}|\mu, \Sigma) =  \frac{\mathcal{N}(b|A\hat{x}, \Sigma_b)\mathcal{N}(\hat{x}|x, \Sigma_x)}{\int_\hat{x} \mathcal{N}(b|A\hat{x}, \Sigma_b)\mathcal{N}(\hat{x}|x, \Sigma_x) \,d\hat{x}}.&lt;/script&gt;

&lt;p&gt;with&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{align} \mu &amp;= x + \Sigma_xA^T(\Sigma_b + A\Sigma_xA^T)^{-1}(b-Ax) \\ 
\Sigma &amp;= \Sigma_x - \Sigma_xA^T (\Sigma_b + A\Sigma_xA^T)^{-1}A\Sigma_x. \end{align} %]]&gt;&lt;/script&gt;

&lt;p&gt;In this context, \(x\) and \(\Sigma_x\) are describing our prior belief about the set of points \(x\) that map to \(b\). We have no prior information about the inverse and could choose any prior that has probability mass at every point in the space.
We will set \(x=0\) and \(\Sigma_x = I\). Our equations will simplify to&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{align} \mu &amp;= A^T(\Sigma_b + AA^T)^{-1}b \\ 
\Sigma &amp;= I - A^T (\Sigma_b + AA^T)^{-1}A. \end{align} %]]&gt;&lt;/script&gt;

&lt;p&gt;But what is with \(\Sigma_b\)? We want to calculate the inverse of the deterministic linear transformation. Therefore, \(\Sigma_b\) has to go to zero. We are doing this in a fancy way by defining&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\Sigma_b = \delta I&lt;/script&gt;

&lt;p&gt;and letting \(\delta\) go to zero.&lt;/p&gt;

&lt;p&gt;The resulting formula will be&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{align} \mu &amp;= A^T(\delta I + AA^T)^{-1}b \\ 
\Sigma &amp;= I - A^T (\delta I + AA^T)^{-1}A \end{align} %]]&gt;&lt;/script&gt;

&lt;p&gt;with \(\delta \to 0 \).&lt;/p&gt;

&lt;p&gt;If we look closely we can identify the exact definition of the &lt;a href=&quot;https://en.wikipedia.org/wiki/Moore%E2%80%93Penrose_inverse&quot;&gt;pseudoinverse&lt;/a&gt;&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;A^+ = A^T(\delta I + AA^T)^{-1},&lt;/script&gt;

&lt;p&gt;where \(\delta \to 0\). In this particular form, we don’t we have to think about rank or invertibility: It is valid for any matrix!&lt;/p&gt;

&lt;p&gt;Ok, but what’s going with the covariance matrix \(\Sigma\)? It can be identified as the orthogonal &lt;a href=&quot;https://en.wikipedia.org/wiki/Moore%E2%80%93Penrose_inverse#Projectors&quot;&gt;projector&lt;/a&gt; onto the kernel of \(A\)&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;I - A^+A.&lt;/script&gt;

&lt;p&gt;Ok, nice! But what does it mean? The mean \(\mu\) and covariance \(\Sigma\) together are describing an affine linear space. The mean \(\mu\) can be interpreted as a translation vector to the linear subspace described by the covariance \(\Sigma\).&lt;/p&gt;

&lt;p&gt;The beautiful thing is, that we don’t have to trust the equations. We can simply plot&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\mathcal{N}(\hat{x}|A^+b, I - A^+A)&lt;/script&gt;

&lt;p&gt;with a very small \(\delta\) and &lt;em&gt;see&lt;/em&gt; the resulting subspace.&lt;/p&gt;

&lt;p&gt;But the niceness doesn’t stop here. We can imagine a setting, where we are not getting the whole vector \(b\) at once, but each dimension \(b_i\) separately. In this case, Bayes theorem tells us quite clearly what to do. We can update our belief of the inverse sequentially&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;p(\hat{x}|b) =  \frac{\mathcal{N}(b_1|A_1\hat{x}, \Sigma_{b_1})\,\ldots\,\mathcal{N}(b_m|A_m\hat{x}, \Sigma_{b_m})\mathcal{N}(\hat{x}|x, \Sigma_x)}{\int_\hat{x} \mathcal{N}(b_1|A_1\hat{x}, \Sigma_{b_1})\,\ldots\,\mathcal{N}(b_m|A_m\hat{x}, \Sigma_{b_m})\mathcal{N}(\hat{x}|x, \Sigma_x) \,d\hat{x}},&lt;/script&gt;

&lt;p&gt;where we assume that \(\Sigma_b\) is a diagonal matrix.&lt;/p&gt;

&lt;p&gt;We did not only obtain a nice way to describe inverses, but have found a general representation of arbitrary affine linear subspaces&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\mathcal{N}(x|a, A(\delta)),&lt;/script&gt;

&lt;p&gt;with translation vector \(a\) and covariance matrix \(A(\delta)\), where \(\delta \to 0\).&lt;/p&gt;

&lt;h1 id=&quot;intersection-of-subspaces&quot;&gt;Intersection of subspaces&lt;/h1&gt;

&lt;p&gt;Now, we can ask what the intersection of two affine linear subspaces is. An intuitive example for this are two planes intersecting in a line. With our representation of affine linear subspaces, asking for the intersection is easy! We just have to multiply the Gaussian distributions and we are done. In the &lt;a href=&quot;https://ipvs.informatik.uni-stuttgart.de/mlr/marc/notes/gaussians.pdf&quot;&gt;Gaussian identities&lt;/a&gt;, we find the formula for the product&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\mathcal{N}(x|a, A) \mathcal{N}(x|b, B) = \mathcal{N}(x|B(A+B)^{-1}a + A(A+B)^{-1}b, A(A+B)^{-1}B)\mathcal{N}(a|b, A+B).&lt;/script&gt;

&lt;p&gt;Therefore, the subspace of the intersection can be described by&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{align}
\mu &amp;= B(\delta)(A(\delta)+B(\delta))^{-1}a + A(\delta)(A(\delta)+B(\delta))^{-1}b \\
\Sigma &amp;=  A(\delta)(A(\delta)+B(\delta))^{-1}B(\delta)
\end{align} %]]&gt;&lt;/script&gt;

&lt;p&gt;for \(\delta\to 0\).&lt;/p&gt;

&lt;p&gt;Please be aware, that things will break if there is no intersection at all. In the case of two parallel lines and before you take the limit, the resulting mean \(\mu\) will lie directly in the middle of the connecting line of the two means \(a\) and \(b\) and \(\Sigma\) will be the same as \(A(\delta)=B(\delta)\).&lt;/p&gt;

&lt;h1 id=&quot;summary&quot;&gt;Summary&lt;/h1&gt;

&lt;p&gt;In this post, we took a brief look on linear algebra expressed in terms of Gaussian distributions. We saw, that we can perform matrix transformations by marginalization and that the inverse of a matrix \(A\) can be obtained naturally with Bayes theorem. As a side product, we learned a natural way to describe affine linear subspaces. The intersection of two affine linear subspaces is again an affine linear space. We saw how to calculate these intersections by simple multiplication of the corresponding Gaussian distributions. Furthermore, we learned that the word natural comes naturally with Bayes.&lt;/p&gt;

&lt;script type=&quot;text/x-mathjax-config&quot;&gt;

var mq = window.matchMedia( &quot;(max-width: 570px)&quot; );
if (!mq.matches) {
    MathJax.Hub.Config({
	  CommonHTML: { linebreaks: { automatic: true } },
	  &quot;HTML-CSS&quot;: { linebreaks: { automatic: true } },
	         SVG: { linebreaks: { automatic: true } }
	}); 
} 

&lt;/script&gt;</content><author><name></name></author><summary type="html">Linear algebra is a wonderful field of mathematics with endless applications. Despite its obvious beauty, it can also be quite confusing. Especially, when it comes to subspaces, inverses and determinants. In this article, I want to present a different view on some aspects of linear algebra with the help of Gaussian distributions and Bayes theorem.</summary></entry><entry><title type="html">Nonlinear filtering: Extended Kalman filter</title><link href="http://localhost:4000/jekyll/update/2018/10/31/nf-ekf.html" rel="alternate" type="text/html" title="Nonlinear filtering: Extended Kalman filter" /><published>2018-10-31T23:04:07+09:00</published><updated>2018-10-31T23:04:07+09:00</updated><id>http://localhost:4000/jekyll/update/2018/10/31/nf-ekf</id><content type="html" xml:base="http://localhost:4000/jekyll/update/2018/10/31/nf-ekf.html">&lt;p&gt;This article is the second part of the nonlinear filtering series, where we will derive the extended Kalman filter with non-additive and additive noise directly from the recursive equations of the Bayes filter.  &lt;!--more--&gt; If you haven’t read the &lt;a href=&quot;/jekyll/update/2018/10/29/nf-intro.html&quot;&gt;introduction&lt;/a&gt;, I would recommend to read it first. Before we dive into the derivation, let’s try to state the main idea behind extended Kalman filter.
&lt;!--more--&gt;
&lt;script src=&quot;https://d3js.org/d3.v5.min.js&quot; charset=&quot;utf-8&quot;&gt;&lt;/script&gt;&lt;/p&gt;

&lt;script src=&quot;https://cdn.plot.ly/plotly-latest.min.js&quot;&gt;&lt;/script&gt;

&lt;script src=&quot;http://localhost:4000/assets/js/nonlinear_filter/particle_filter.js&quot;&gt;&lt;/script&gt;

&lt;script src=&quot;http://localhost:4000/assets/js/nonlinear_filter/race_car.js&quot;&gt;&lt;/script&gt;

&lt;script src=&quot;http://localhost:4000/assets/js/nonlinear_filter/race_track.js&quot;&gt;&lt;/script&gt;

&lt;script src=&quot;http://localhost:4000/assets/js/nonlinear_filter/util.js&quot;&gt;&lt;/script&gt;

&lt;script src=&quot;http://localhost:4000/assets/js/nonlinear_filter/plot.js&quot;&gt;&lt;/script&gt;

&lt;script src=&quot;http://localhost:4000/assets/js/nonlinear_filter/scene.js&quot;&gt;&lt;/script&gt;

&lt;script src=&quot;http://localhost:4000/assets/js/nonlinear_filter/ekf.js&quot;&gt;&lt;/script&gt;

&lt;script src=&quot;http://localhost:4000/assets/js/nonlinear_filter/discrete_bayes_filter.js&quot;&gt;&lt;/script&gt;

&lt;link href=&quot;https://fonts.googleapis.com/css?family=Roboto&quot; rel=&quot;stylesheet&quot; /&gt;

&lt;link rel=&quot;stylesheet&quot; type=&quot;text/css&quot; href=&quot;http://localhost:4000/assets/css/nonlinear_filter/style.css&quot; /&gt;

&lt;script type=&quot;text/javascript&quot;&gt;


	scene = [];
	scenes = [];
	scenes_name = [];
	interval = null;
	loaded = false;
	var aa = 1;
	var fast_dur = 300;
	var slow_dur = 1000;
	var ani_step = 3;


	touch_id = null;





&lt;/script&gt;

&lt;div class=&quot;important_box&quot;&gt;
  &lt;p&gt;The &lt;strong&gt;extended Kalman filter&lt;/strong&gt; approximates the Bayes filter by linearizing the system and observation equations.&lt;/p&gt;
&lt;/div&gt;

&lt;h2 id=&quot;derivation&quot;&gt;Derivation&lt;/h2&gt;

&lt;p&gt;We will start the derivation directly from the recursive equations of the Bayes filter with the &lt;strong&gt;prediction step&lt;/strong&gt;&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;p(x_{t+1}|y_{0:t},u_{0:t}) = \int_{x_{t}} p(x_{t+1}|x_{t}, u_{t})p(x_{t}|y_{0:t},u_{0:t-1}) dx_{t}&lt;/script&gt;

&lt;p&gt;and the &lt;strong&gt;update step&lt;/strong&gt;&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;p(x_t|y_{0:t},u_{0:t-1}) = \frac{p(y_t|x_t)p(x_t|y_{0:t-1},u_{0:t-1})}{\int_{x_t}p(y_t|x_t)p(x_t|y_{0:t-1},u_{0:t-1}) \,dx_t} .&lt;/script&gt;

&lt;p&gt;The extended Kalman filter is normally formulated with nonlinear functions with additive noise. In this article, we directly derive the general case for non-additive noise and obtain the extended Kalman filter as a special case. Therefore, our equations of the system are&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{align}
 x_{t+1} &amp;= f(x_t, u_t, w_t) \\
 y_t &amp;= h(x_k, v_k).
 \end{align} %]]&gt;&lt;/script&gt;

&lt;p&gt;with Gaussian process noise \( w_t \sim \mathcal{N}(w_t|0, Q_t) \) and Gaussian observation noise \( v_t \sim \mathcal{N}(v_t|0, R_t) \).&lt;/p&gt;

&lt;p&gt;In our formula of the Bayes filter, we can’t find any functions \(f(x_t, u_t, w_t)\) or \(h(x_k, v_k)\). Therefore, our first step will be to express these functions as probability distributions \(p(x_{t+1}|x_{t}, u_{t})\) and \(p(y_t|x_t)\). The next box will show how to achieve this in general. &lt;strong&gt;Warning:&lt;/strong&gt; Distributions are very weird and the following treatment is &lt;strong&gt;not rigorous&lt;/strong&gt;.&lt;/p&gt;
&lt;div class=&quot;extra_box&quot;&gt;
  &lt;p&gt;We want to calculate \(p(y|x)\) given the function \(y=f(x,z)\) and \(p(z)\).
We can express the deterministic function \(y=f(x,z)\) as probability distribution&lt;/p&gt;

  &lt;script type=&quot;math/tex; mode=display&quot;&gt;p(y|x,z) = \delta(y-f(x,z)),&lt;/script&gt;

  &lt;p&gt;with the &lt;a href=&quot;https://en.wikipedia.org/wiki/Dirac_delta_function&quot;&gt;Dirac delta function&lt;/a&gt; \(\delta(x)\).&lt;/p&gt;

  &lt;p&gt;In order to calculate \(p(y|x)\) we can simply marginalize out \(z\):&lt;/p&gt;

  &lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{align}
p(y|x) &amp;= \int_z p(y|x,z)p(z)\, dx \\
 &amp;= \int_z \delta(y-f(x,z))p(z)\, dx 
\end{align} %]]&gt;&lt;/script&gt;

  &lt;p&gt;By using the composition rule of the Dirac delta function, we can express this as&lt;/p&gt;

  &lt;script type=&quot;math/tex; mode=display&quot;&gt;p(y|x) = \sum_i \frac{p(z_i)}{\left|\det\nabla_z f(x,z)|_{z_i}\right|},&lt;/script&gt;

  &lt;p&gt;where the sum goes over all \(z_i\) which satisfy the equation \(y = f(x,z)\).&lt;/p&gt;
&lt;/div&gt;

&lt;p&gt;In our case, we can express our system function \(x_{t+1} = f(x_t,u_t,w_t)\) as a probability distribution&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;p(x_{t+1}|x_t,u_t) = \sum_i \frac{p(w_i)}{\left|\det\nabla_w f(x_t, u_t, w_t)|_{w_i}\right|},&lt;/script&gt;

&lt;p&gt;where the sum goes over all \(w_i\) which satisfy \(x_{t+1} = f(x_t,u_t,w_t)\).&lt;/p&gt;

&lt;p&gt;Similarly, we can express our observation function  \(y_t = h(x_k, v_k)\) as probability distribution&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;p(y_t|x_t) = \sum_i \frac{p(v_i)}{\left|\det\nabla_v h(x_t, v_t)|_{v_i}\right|}&lt;/script&gt;

&lt;p&gt;where the sum goes over all \(v_i\) which satisfy \(x_{t+1} = h(x_t,v_t)\).&lt;/p&gt;

&lt;p&gt;Even if we are assuming Gaussian process and measurement noise, the resulting distributions of our model will, in general, be non-Gaussian.
This is where the extended Kalman filter comes into play. It approximates our probability distributions by using linearization.
In my limited scope, linearization of a probability distribution makes no sense. But what is linearized instead?&lt;/p&gt;

&lt;p&gt;Instead of linearizing our probability distributions we will do this with our deterministic functions before we express them as probability distributions.&lt;/p&gt;

&lt;p&gt;In order to linearize, we are performing a first-order Taylor expansion&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;f(x_t, u_t, w_t) \approx f(x_t, u_t, w_t)|_{x_t=\hat x_{t|t},u_t=u,w_t=0} + \nabla_{x_t} f(x_t, u_t, w_t)^T|_{x_t=\hat x_{t|t},u_t=u,w_t=0}(x_t - x)+ \nabla_{u_t} f(x_t, u_t, w_t)^T|_{x_t=\hat x_{t|t},u_t=u,w_t=0}(u_t - u) + \nabla_{w_t} f(x_t, u_t, w_t)^T|_{x_t=\hat x_{t|t},u_t=u,w_t=0}w_t&lt;/script&gt;

&lt;p&gt;around the current state estimate \(x_t = \hat x_{t|t}\), current input \(u_t=u\) and zero process noise \(w_t=0\).&lt;/p&gt;

&lt;p&gt;To unclutter the notation, we define \(A_t = \nabla_{x_t} f(x_t, u_t, w_t)^T|_ {x_t=\hat x_{t|t},u_t=u,w_t=0}\) , \(B_t = \nabla_{u_t} f(x_t, u_t, w_t)^T|_ {x_t=\hat x_{t|t},u_t=u,w_t=0}\) and \(L_t = \nabla_{w_t} f(x_t, u_t, w_t)^T|_ {x_t=\hat x_{t|t},u_t=u,w_t=0}\) to finally obtain the much cleaner representation&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\hat{f}(x_t, u_t, w_t) = f(\hat x_{t|t}, u, 0) + A_t(x_t - \hat x_{t|t})+ B_t(u_t - u)  + L_tw_t.&lt;/script&gt;

&lt;p&gt;Now we are ready to transform our linearized deterministic system function into a probability distribution. We will use the same formula as above, but replace the true function \(f(x_t, u_t, w_t)\) with \(\hat{f}(x_t, u_t, w_t)\), and arrive at&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;p(x_{t+1}|x_t,u_t) = \sum_i \frac{\mathcal{N}(w_i|0,Q_t)}{\left|\det\nabla_w \hat{f}(x_t, u_t, w_t)|_{w_i}\right|},&lt;/script&gt;

&lt;p&gt;where the sum is over all \(w_i\) which satisfy \(x_{t+1} = \hat{f}(x_t, u_t, w_t)\). Let’s try to simplify this expression! First, we notice that if the matrix \(L_t\) is invertible, then there is exactly one \(w\) that satisfies \(x_{t+1} = \hat{f}(x_t, u_t, w_t)\). We can express it as&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;w = L_t^{-1}\left(x_{t+1} - f(\hat x_{t|t}, u, 0) - A_t(x_t - \hat x_{t|t})- B_t(u_t - u)\right).&lt;/script&gt;

&lt;p&gt;Note, that if the martrix \(L_t\) is not invertible, we would have to integrate over the whole null space and the sum would become an integral.&lt;/p&gt;

&lt;p&gt;Next, let’s look at the denominator. We can express the derivative of \(\hat{f}(x_t, u_t, w_t)\) with respect to \(w_t\) as&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\nabla_w \hat{f}(x_t, u_t, w_t) =\nabla_w( f(\hat x_{t|t}, u, 0) + A_t(x_t - \hat x_{t|t})+ B_t(u_t - u)  + L_tw_t) = L_t.&lt;/script&gt;

&lt;p&gt;Let’s plug in the information our new information about \(w\) and the derivative:&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;p(x_{t+1}|x_t,u_t) = \frac{\mathcal{N}(L_t^{-1}\left(x_{t+1} - f(\hat x_{t|t}, u, 0) - A_t(x_t - \hat x_{t|t})- B_t(u_t - u)\right)|0,Q_t)}{\left|\det L_t\right|}.&lt;/script&gt;

&lt;p&gt;We apply the transformation identity (Formula 35, &lt;a href=&quot;https://ipvs.informatik.uni-stuttgart.de/mlr/marc/notes/gaussians.pdf&quot;&gt;Toussaint&lt;/a&gt;):&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;p(x_{t+1}|x_t,u_t) = \frac{\frac{1}{\left|\det L_t^{-1}\right|}\mathcal{N}(x_{t+1} - f(\hat x_{t|t}, u, 0) - A_t(x_t - \hat x_{t|t})- B_t(u_t - u)|0,L_tQ_tL_t^T)}{\left|\det L_t\right|}&lt;/script&gt;

&lt;p&gt;And apply it once more, to obtain our final result:&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;p(x_{t+1}|x_t,u_t) = \mathcal{N}(x_{t+1}|f(\hat x_{t|t}, u, 0) + A_t(x_t - \hat x_{t|t})+ B_t(u_t - u),L_tQ_tL_t^T).&lt;/script&gt;

&lt;p&gt;We are done! The linearization of our function has lead us back to Gaussianity!&lt;/p&gt;

&lt;p&gt;With the same strategy, we obtain for our observation model&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;p(y_t|x_t) = \mathcal{N}(y_T|h(\hat x_{t|t-1}, 0) + C_t(x_t - \hat x_{t|t-1}),M_tQ_tM_t^T),&lt;/script&gt;

&lt;p&gt;with \(C_t = \nabla_{x_t} h(x_t, v_t)^T|_ {x_t=\hat x_{t|t-1},v_t=0}\) and \(M_t = \nabla_{v_t} h(x_t, v_t)^T|_ {x_t=\hat x_{t|t-1},v_t=0}\)&lt;/p&gt;

&lt;p&gt;Our linearization led to a Gaussian system and observation model. Therefore, the distribution of the updated state estimate&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;p(x_t|y_{0:t},u_{0:t-1}) := \mathcal{N}(x_{t}|\hat x_{t|t}, P_{t|t})&lt;/script&gt;

&lt;p&gt;and the distribution of the predicted state estimate&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;p(x_t|y_{0:t-1},u_{0:t-1}) := \mathcal{N}(x_{t}|\hat x_{t|t-1}, P_{t|t-1})&lt;/script&gt;

&lt;p&gt;will be Gaussians as well.&lt;/p&gt;

&lt;p&gt;Now we are ready to plug our surrogate into the equations of the Bayes filter:&lt;/p&gt;
&lt;div class=&quot;important_box&quot;&gt;
  &lt;p&gt;&lt;strong&gt;Prediction step&lt;/strong&gt;&lt;/p&gt;

  &lt;script type=&quot;math/tex; mode=display&quot;&gt;\mathcal{N}(x_{t+1}|\hat x_{t+1|t}, P_{t+1|t})  = \int_{x_t}\mathcal{N}\left(x_{t+1}\middle| f(x, u, 0) + A_t(x_t - \hat x_{t|t})+ B_t(u_t - u),L_t^TQ_tL_t\right) \mathcal{N}(x_t|\hat x_{t|t}, P_{t|t}) dx_t.&lt;/script&gt;

  &lt;p&gt;&lt;strong&gt;Update step&lt;/strong&gt;&lt;/p&gt;

  &lt;script type=&quot;math/tex; mode=display&quot;&gt;\mathcal{N}(x_{t}|\hat x_{t|{t}}, P_{t|t} ) = \frac{\mathcal{N}\left(y_{t}\middle| h(x, 0) C_t(x_t - \hat x_{t|t-1}) ,M_t^TR_tM_t\right) \mathcal{N}(x_{t}|\hat x_{t|t-1}, P_{t|t-1})}{\int_{x_{t}}\mathcal{N}\left(y_{t}\middle| h(x, 0) C_t(x_t - \hat x_{t|t-1}) ,M_t^TR_tM_t\right) \mathcal{N}(x_{t}|\hat x_{t|t-1}, P_{t|t-1}) dx_{t}}&lt;/script&gt;

&lt;/div&gt;

&lt;p&gt;Let’s try to simplify these equations!&lt;/p&gt;

&lt;h3 id=&quot;prediction-step&quot;&gt;Prediction step&lt;/h3&gt;

&lt;p&gt;We will start with the prediction step&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\mathcal{N}(x_{t+1}|\hat x_{t+1|t}, P_{t+1|t})  = \int_{x_t}\mathcal{N}\left(x_{t+1}\middle| f(x, u, 0) - A_t\hat x_{t|t} - B_tu + A_tx_t + B_tu_t,L_t^TQ_tL_t\right) \mathcal{N}(x_t|\hat x_{t|t}, P_{t|t}) dx_t.&lt;/script&gt;

&lt;p&gt;To find an expression for our prediction step we can simply use the &lt;em&gt;propagation&lt;/em&gt; formula (Formula 37, &lt;a href=&quot;https://ipvs.informatik.uni-stuttgart.de/mlr/marc/notes/gaussians.pdf&quot;&gt;Toussaint&lt;/a&gt;)&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\int_{y}\mathcal{N}(x|a + Fy, A)\mathcal{N}(y|b,B) dx_t = \mathcal{N}(x|a + Fb, A + FBF^T ).&lt;/script&gt;

&lt;p&gt;By comparison with our expression, we see that&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\hat x_{t+1|t} = f(x_{t|t}, u_t, 0) -A_t \hat x_{t|t} - B_tu_t + A_t \hat x_{t|t} + B_tu_t = f(x_{t|t}, u_t, 0)&lt;/script&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;P_{t+1|t} = L_t^TQ_tL_t + A_t P_{t|t} A_t^T  .&lt;/script&gt;

&lt;h3 id=&quot;update-step&quot;&gt;Update step&lt;/h3&gt;

&lt;p&gt;We will start to simplify the update step&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\mathcal{N}(x_{t}|\hat x_{t|{t}}, P_{t|t} ) = \frac{\mathcal{N}\left(y_{t}\middle| h(\hat x_{t|t-1}, 0) - C_t\hat x_{t|t-1} + C_tx_t ,M_t^TR_tM_t\right) \mathcal{N}(x_{t}|\hat x_{t|t-1}, P_{t|t-1})}{\int_{x_{t}}\mathcal{N}\left(y_{t}\middle| h(\hat x_{t|t-1}, 0) - C_t\hat x_{t|t-1} + C_tx_t ,M_t^TR_tM_t\right) \mathcal{N}(x_{t}|\hat x_{t|t-1}, P_{t|t-1}) dx_{t}}&lt;/script&gt;

&lt;p&gt;by focussing on the numerator first. We notice that we can rewrite it as a joint distribution (Formula 39, &lt;a href=&quot;https://ipvs.informatik.uni-stuttgart.de/mlr/marc/notes/gaussians.pdf&quot;&gt;Toussaint&lt;/a&gt;)&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\mathcal{N}(x|a,A)\mathcal{N}(y|b + Fx,B) = \mathcal{N}\left(\begin{matrix}x \\y\end{matrix}\middle|\begin{matrix}a\\b + Fa \end{matrix},\begin{matrix}A &amp; A^TF^T\\FA &amp; B + FA^TF^T\end{matrix}\right) . %]]&gt;&lt;/script&gt;

&lt;p&gt;Then again, this joint distribution can be rewritten as&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\mathcal{N}\left(\begin{matrix}x \\y\end{matrix}\middle|\begin{matrix}d\\e \end{matrix},\begin{matrix}D &amp; F\\F^T &amp; E\end{matrix}\right) = \mathcal{N}(y|e,E)\mathcal{N}(x|d + F^TE^{-1}(y-e),D - F^T E^{-1}F) . %]]&gt;&lt;/script&gt;

&lt;p&gt;We can combine the two previous equations to the following expression&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\mathcal{N}(x|a,A)\mathcal{N}(y|b + Fx,B) = \mathcal{N}(y|b + Fa,B + FA^TF^T) \mathcal{N}(x|a + A^TF^T(B + FA^TF^T)^{-1}(y-b -Fa),A - A^TF^T (B + FA^TF^T)^{-1}FA) .&lt;/script&gt;

&lt;p&gt;By comparison with the numerator of our update step, we obtain&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\mathcal{N}\left(y_{t}\middle| h(\hat x_{t|t-1}, 0) - C_t x_{t|t-1} + C_t x_{t|t-1} ,M_t^TR_tM_t\right) \mathcal{N}(x_{t}|\hat x_{t|t-1}, P_{t|t-1}) = \mathcal{N}(y_{t}|h(\hat x_{t|t-1}, 0) - C_t x_{t|t-1} + C_t\hat x_{t|t-1},M_t^TR_tM_t + C_tP_{t|t-1}C_t^T)  \mathcal{N}(x_{t}|\hat x_{t|t-1} + P_{t|t-1}C_t^T(M_t^TR_tM_t + C_tP_{t|t-1}C_t^T)^{-1}(y_{t}-h(\hat x_{t|t-1}, 0) + C_t x_{t|t-1} -C_t\hat x_{t|t-1}),  P_{t|t-1} - P_{t|t-1}C_t^T (M_t^TR_tM_t + C_tP_{t|t-1}C_t^T)^{-1}C_tP_{t|t-1}),&lt;/script&gt;

&lt;p&gt;which simplifies to&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\mathcal{N}\left(y_{t}\middle| h(\hat x_{t|t-1}, 0) ,M_t^TR_tM_t\right) \mathcal{N}(x_{t}|\hat x_{t|t-1}, P_{t|t-1}) = \mathcal{N}(y_{t}|h(\hat x_{t|t-1}, 0),M_t^TR_tM_t + C_tP_{t|t-1}C_t^T)  \mathcal{N}(x_{t}|\hat x_{t|t-1} + P_{t|t-1}C_t^T(M_t^TR_tM_t + C_tP_{t|t-1}C_t^T)^{-1}(y_{t}-h(\hat x_{t|t-1}, 0)),  P_{t|t-1} - P_{t|t-1}C_t^T (M_t^TR_tM_t + C_tP_{t|t-1}C_t^T)^{-1}C_tP_{t|t-1}).&lt;/script&gt;

&lt;p&gt;We applied the same trick as in the &lt;a href=&quot;/jekyll/update/2018/10/10/kalman_filter.html&quot;&gt;derivation of the Kalman filter&lt;/a&gt;: Conceptually, we only transformed&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\frac{p(y|x)p(x)}{p(y)} \to \frac{p(y,x)}{p(y)} \to \frac{p(x|y)p(y)}{p(y)}.&lt;/script&gt;

&lt;p&gt;If we look closely at the final expression, we see that \(p(y)\) is canceling out. Therefore, the result is simply the remaining part&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\mathcal{N}(x_{t}|\hat x_{t|{t}}, P_{t|t} ) = \mathcal{N}(x_{t}|\hat x_{t|t-1} + P_{t|t-1}C_t^T(M_t^TR_tM_t + C_tP_{t|t-1}C_t^T)^{-1}(y_{t}-h(\hat x_{t|t-1}, 0)),  P_{t|t-1} - P_{t|t-1}C_t^T (M_t^TR_tM_t + C_tP_{t|t-1}C_t^T)^{-1}C_tP_{t|t-1}).&lt;/script&gt;

&lt;p&gt;If our reasoning is correct the denominator should be equal to \(\mathcal{N}(y_{t}|h(x, 0),M_t^TR_tM_t + C_tP_{t|t-1}C_t^T)\), which was canceled out. The denominator can be simplified with the &lt;em&gt;propagation&lt;/em&gt; formula (Formula 37, &lt;a href=&quot;https://ipvs.informatik.uni-stuttgart.de/mlr/marc/notes/gaussians.pdf&quot;&gt;Toussaint&lt;/a&gt;)&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\int_{x_{t}}\mathcal{N}\left(y_{t}\middle| h(\hat x_{t|t-1}, 0) - C_t x_{t|t-1} + C_t x_{t|t-1} ,M_t^TR_tM_t\right) \mathcal{N}(x_{t}|\hat x_{t|t-1}, P_{t|t-1}) dx_{t} =  \mathcal{N}({y_{t}}|h(\hat x_{t|t-1}, 0) - C_t x_{t|t-1} + C_t\hat x_{t|t-1}, M_t^TR_tM_t + C_tP_{t|t-1}C_t^T ) = \mathcal{N}(y_{t}|h(\hat x_{t|t-1}, 0),M_t^TR_tM_t + C_tP_{t|t-1}C_t^T).&lt;/script&gt;

&lt;p&gt;Yay! We see, that the denominator is exactly the same as the canceled factor in the numerator.&lt;/p&gt;

&lt;p&gt;Let’s summarize our results:&lt;/p&gt;

&lt;div class=&quot;important_box&quot;&gt;
  &lt;h1&gt;Extended Kalman filter with non-additive noise&lt;/h1&gt;

  &lt;p&gt;The recursive formula for the extended Kalman filter with non-additive noise consists of the &lt;strong&gt;prediction step&lt;/strong&gt;&lt;/p&gt;

  &lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{align}\hat x_{t+1|t} &amp;= f(x_{t|t}, u_t, 0) \\ 
P_{t+1|t} &amp;= L_t^TQ_tL_t + A_t P_{t|t} A_t^T   \end{align} %]]&gt;&lt;/script&gt;

  &lt;p&gt;and the &lt;strong&gt;update step&lt;/strong&gt;&lt;/p&gt;

  &lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{align}\hat x_{t|t} &amp;= \hat x_{t|t-1} + P_{t|t-1}C_t^T(M_t^TR_tM_t + C_tP_{t|t-1}C_t^T)^{-1}(y_{t}-h(\hat x_{t|t-1}, 0)) \\ 
P_{t|t} &amp;= P_{t|t-1} - P_{t|t-1}C_t^T (M_t^TR_tM_t + C_tP_{t|t-1}C_t^T)^{-1}C_tP_{t|t-1}  \end{align} %]]&gt;&lt;/script&gt;

  &lt;p&gt;with&lt;/p&gt;

  &lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{align}
A_t &amp;= \nabla_{x_t} f(x_t, u_t, w_t)^T|_ {x_t=\hat x_{t|t},u_t=u,w_t=0}\\
B_t &amp;= \nabla_{u_t} f(x_t, u_t, w_t)^T|_ {x_t=\hat x_{t|t},u_t=u,w_t=0}\\
C_t &amp;= \nabla_{x_t} h(x_t, v_t)^T|_ {x_t=\hat x_{t|t-1},v_t=0}\\
L_t &amp;= \nabla_{w_t} f(x_t, u_t, w_t)^T|_ {x_t=\hat x_{t|t},u_t=u,w_t=0}\\
M_t &amp;= \nabla_{v_t} h(x_t, v_t)^T|_ {x_t=\hat x_{t|t-1},v_t=0}.
\end{align} %]]&gt;&lt;/script&gt;

&lt;/div&gt;
&lt;p&gt;That’s it! We derived the equations of the extended Kalman filter. To bring the equations in a more implementation friendly form, we are restating the extended Kalman filter as:&lt;/p&gt;

&lt;div class=&quot;important_box&quot;&gt;
  &lt;h1&gt;Extended Kalman filter with non-additive noise&lt;/h1&gt;

  &lt;p&gt;The recursive formula for the extended Kalman filter with non-additive noise consists of the &lt;strong&gt;prediction step&lt;/strong&gt;&lt;/p&gt;

  &lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{align}\hat x_{t+1|t} &amp;= f(x_{t|t}, u_t, 0) \\ 
P_{t+1|t} &amp;= L_t^TQ_tL_t + A_t P_{t|t} A_t^T   \end{align} %]]&gt;&lt;/script&gt;

  &lt;p&gt;and the &lt;strong&gt;update step&lt;/strong&gt;&lt;/p&gt;

  &lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{align}
z_t &amp;= y_{t}-h(\hat x_{t|t-1}, 0)\\
S_t &amp;= M_t^TR_tM_t + C_tP_{t|t-1}C_t^T\\
K_t &amp;= P_{t|t-1}C_t^TS_t^{-1} \\
\hat x_{t|t} &amp;= \hat x_{t|t-1} + K_t z_t\\
P_{t|t} &amp;= (I - K_tC_t)P_{t|t-1}
\end{align} %]]&gt;&lt;/script&gt;

  &lt;p&gt;with&lt;/p&gt;

  &lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{align}
A_t &amp;= \nabla_{x_t} f(x_t, u_t, w_t)^T|_ {x_t=\hat x_{t|t},u_t=u,w_t=0}\\
B_t &amp;= \nabla_{u_t} f(x_t, u_t, w_t)^T|_ {x_t=\hat x_{t|t},u_t=u,w_t=0}\\
C_t &amp;= \nabla_{x_t} h(x_t, v_t)^T|_ {x_t=\hat x_{t|t-1},v_t=0}\\
L_t &amp;= \nabla_{w_t} f(x_t, u_t, w_t)^T|_ {x_t=\hat x_{t|t},u_t=u,w_t=0}\\
M_t &amp;= \nabla_{v_t} h(x_t, v_t)^T|_ {x_t=\hat x_{t|t-1},v_t=0}.
\end{align} %]]&gt;&lt;/script&gt;

&lt;/div&gt;

&lt;p&gt;As promised we will also look at the special case with &lt;strong&gt;additive&lt;/strong&gt; noise. Therefore, our functions will look like:&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;f(x_t, u_t, w_t) = \bar{f}(x_t, u_t) + w_t.&lt;/script&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;h(x_t, v_t) = \bar{h}(x_t) + v_t.&lt;/script&gt;

&lt;p&gt;In this case, the matrix \(L_t\) and \(M_t\) will be identity matrices:&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;L_t = \nabla_{w_t} f(x_t, u_t, w_t)|_{x_t=x,v_t=0} = \underbrace{\nabla_{w_t} \bar{f}(x_t, u_t)}_{0}|_{x_t=x,v_t=0} + \underbrace{\nabla_{w_t} w_t}_{I}|_{x_t=x,v_t=0} = I&lt;/script&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;M_t = \nabla_{v_t} h(x_t, v_t)|_{x_t=x,v_t=0} = \underbrace{\nabla_{v_t} \bar{h}(x_t)}_{0}|_{x_t=x,v_t=0} + \underbrace{\nabla_{v_t} v_t}_{I}|_{x_t=x,v_t=0} = I.&lt;/script&gt;

&lt;p&gt;Finally, we can state the equations of the extended Kalman filter with additive noise.&lt;/p&gt;

&lt;div class=&quot;important_box&quot;&gt;
  &lt;h1&gt;Extended Kalman filter with additive noise&lt;/h1&gt;

  &lt;p&gt;The recursive formula for the extended Kalman filter with additive noise consists of the &lt;strong&gt;prediction step&lt;/strong&gt;&lt;/p&gt;

  &lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{align}\hat x_{t+1|t} &amp;= f(x_{t|t}, u_t) \\ 
P_{t+1|t} &amp;= Q_t + A_t P_{t|t} A_t^T   \end{align} %]]&gt;&lt;/script&gt;

  &lt;p&gt;and the &lt;strong&gt;update step&lt;/strong&gt;&lt;/p&gt;

  &lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{align}
z_t &amp;= y_{t}-h(\hat x_{t|t-1})\\
S_t &amp;= R_t + C_tP_{t|t-1}C_t^T\\
K_t &amp;= P_{t|t-1}C_t^TS_t^{-1} \\
\hat x_{t|t} &amp;= \hat x_{t|t-1} + K_t z_t\\
P_{t|t} &amp;= (I - K_tC_t)P_{t|t-1}
\end{align} %]]&gt;&lt;/script&gt;

  &lt;p&gt;with&lt;/p&gt;

  &lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{align}
A_t &amp;= \nabla_{x_t} f(x_t, u_t, w_t)^T|_ {x_t=\hat x_{t|t},u_t=u,w_t=0}\\
B_t &amp;= \nabla_{u_t} f(x_t, u_t, w_t)^T|_ {x_t=\hat x_{t|t},u_t=u,w_t=0}\\
C_t &amp;= \nabla_{x_t} h(x_t, v_t)^T|_ {x_t=\hat x_{t|t-1},v_t=0}\\
\end{align} %]]&gt;&lt;/script&gt;

&lt;/div&gt;

&lt;h2 id=&quot;example&quot;&gt;Example&lt;/h2&gt;

&lt;p&gt;Enough of the dry theory! Let’s play around with the grid-based filter in our race track example.&lt;/p&gt;

&lt;svg id=&quot;race_track_mar_loc&quot; style=&quot;width:100%&quot; onclick=&quot;on_click()&quot;&gt;&lt;/svg&gt;
&lt;script&gt;


	n_scene = load_race_track(&quot;race_track_mar_loc&quot;,&quot;http://localhost:4000&quot;,1000);
	n_scene.mode = 2;
	n_scene.filter = &quot;&quot;;
	n_scene.dur=slow_dur;
	// define particle filter 

	n_scene.auto_start = false;

	n_scene.t = 1;

	n_scene.ids = [&quot;race_track_mar_loc_likelihood&quot;, &quot;race_track_mar_loc_update&quot;,&quot;race_track_mar_loc_timestep&quot;, &quot;race_track_mar_loc_predict&quot; ];

	n_scene.loaded = function(){

		var outer_color = d3.piecewise(d3.interpolateRgb, [d3.rgb(this.rt.svg.style(&quot;background-color&quot;)), d3.rgb('#006eff'), d3.rgb('#00028e')]);
		var inner_color = d3.piecewise(d3.interpolateRgb, [d3.rgb(this.rt.svg.style(&quot;background-color&quot;)), d3.rgb('#ff834d'), d3.rgb('#8e3323')]);

		this.ekf = init_ekf_1D(this.rc, this.rc.state, 3*this.rc.sigma_s_no_cache(this.rc.state));
		this.rt.init_strip(&quot;inner&quot;, get_output_dist_normalized(this.rc, this.rt, this.rc.state), inner_color, 60);
		this.rt.init_strip(&quot;outer&quot;, get_gaussian_circ_normalized(this.rt.strip_pos, this.ekf.posterior_mu, this.ekf.posterior_sigma, this.rt), outer_color, 60);



		document.getElementById(&quot;race_track_mar_loc_likelihood&quot;).style.display=&quot;block&quot;;
		this.rt.hide_strip(&quot;inner&quot;);


		this.restart = function(){
			for (var i=0; i&lt;this.ids.length;i++){

				document.getElementById(this.ids[i]).style.display=&quot;none&quot;;
			}
			document.getElementById(&quot;race_track_mar_loc_likelihood&quot;).style.display=&quot;block&quot;;
			this.rc.reset();
			this.t = 1;

			

			//this.bf.reset();
			this.ekf.reset(this.rc.state, this.rc.sigma_o_no_cache(this.rc.state))
			this.rt.hide_strip(&quot;inner&quot;);
			this.rt.show_strip(&quot;outer&quot;);
			this.rt.update_strip(&quot;outer&quot;, get_gaussian_circ_normalized(this.rt.strip_pos, this.ekf.posterior_mu, this.ekf.posterior_sigma, this.rt));
		}


		this.rt.set_restart_button(this.restart.bind(this))




	}.bind(n_scene)


	n_scene.step = function(){
		this.t++;
		for (var i=0; i&lt;this.ids.length;i++){

			document.getElementById(this.ids[i]).style.display=&quot;none&quot;;
		}


		if(this.t % 4 == 0){
			//CHOOSE ACTION
			this.rc.step(this.rc.current_input);
			this.last_input = this.rc.current_input;
			document.getElementById(&quot;race_track_mar_loc_predict&quot;).style.display=&quot;block&quot;;
			this.rt.hide_strip(&quot;inner&quot;);
		}else if(this.t % 4 == 1){
			// PREDICT
			this.ekf.predict(this.last_input);

			// trim ekf posterior
			if(this.ekf.posterior_mu&lt;0){
				this.ekf.posterior_mu+=this.rt.track_length;
			}
			this.ekf.posterior_mu = this.ekf.posterior_mu % this.rt.track_length;
			this.rt.update_strip(&quot;outer&quot;, get_gaussian_circ_normalized(this.rt.strip_pos, this.ekf.posterior_mu, this.ekf.posterior_sigma, this.rt));
			document.getElementById(&quot;race_track_mar_loc_likelihood&quot;).style.display=&quot;block&quot;;
		}else if(this.t % 4 == 2){
			// OBSERVE
			this.rt.show_strip(&quot;inner&quot;);
			this.output = scene.rc.output_dist_sample(0);
			var likelihood = this.ekf.get_likelihood(this.output,this.ekf.posterior_mu)
			this.rt.update_strip(&quot;inner&quot;, get_gaussian_circ_normalized(this.rt.strip_pos, likelihood.mu, likelihood.sigma, this.rt));

			document.getElementById(&quot;race_track_mar_loc_update&quot;).style.display=&quot;block&quot;;
		}else if(this.t % 4 == 3){
			// UPDATE

			this.ekf.update(this.output);

			this.rt.update_strip(&quot;outer&quot;, get_gaussian_circ_normalized(this.rt.strip_pos, this.ekf.posterior_mu, this.ekf.posterior_sigma, this.rt));

			document.getElementById(&quot;race_track_mar_loc_timestep&quot;).style.display=&quot;block&quot;;
		}

	}.bind(n_scene);

	scenes_name[&quot;race_track_mar_loc&quot;] = n_scene;
	scenes.push(n_scene);

&lt;/script&gt;

&lt;div id=&quot;race_track_mar_loc_timestep&quot; class=&quot;button_set&quot;&gt;
&lt;div class=&quot;bt3 bt&quot; onclick=&quot;scenes_name['race_track_mar_loc'].rc.current_input=0;scenes_name['race_track_mar_loc'].step();&quot;&gt;Backward&lt;/div&gt;
&lt;div class=&quot;bt3 bt&quot; onclick=&quot;scenes_name['race_track_mar_loc'].rc.current_input=1;scenes_name['race_track_mar_loc'].step();&quot;&gt;No action&lt;/div&gt;
&lt;div class=&quot;bt3 bt&quot; onclick=&quot;scenes_name['race_track_mar_loc'].rc.current_input=2;scenes_name['race_track_mar_loc'].step();&quot;&gt;Forward&lt;/div&gt;
 &lt;span class=&quot;stretch&quot;&gt;&lt;/span&gt;
&lt;/div&gt;

&lt;div id=&quot;race_track_mar_loc_predict&quot; class=&quot;button_set&quot;&gt;
&lt;div class=&quot;bt1  bt&quot; onclick=&quot;scenes_name['race_track_mar_loc'].step();&quot;&gt;Predict step&lt;/div&gt;
  &lt;span class=&quot;stretch&quot;&gt;&lt;/span&gt;
&lt;/div&gt;

&lt;div id=&quot;race_track_mar_loc_likelihood&quot; class=&quot;button_set&quot;&gt;
&lt;div class=&quot;bt1  bt&quot; onclick=&quot;scenes_name['race_track_mar_loc'].step();&quot;&gt;Observe&lt;/div&gt;
  &lt;span class=&quot;stretch&quot;&gt;&lt;/span&gt;
&lt;/div&gt;

&lt;div id=&quot;race_track_mar_loc_update&quot; class=&quot;button_set&quot; onclick=&quot;scenes_name['race_track_mar_loc'].step();&quot;&gt;
&lt;div class=&quot;bt1  bt&quot;&gt;Update step&lt;/div&gt;
  &lt;span class=&quot;stretch&quot;&gt;&lt;/span&gt;
&lt;/div&gt;

&lt;p&gt;On the outside the race track, you will notice a blue colored strip. This strip represents our current posterior of the current position of the race car. We will start with a Gaussian prior distribution around the true mean. By pressing the &lt;strong&gt;OBSERVE&lt;/strong&gt; button two things will happen: first, we will take a measurement of the distance of the tree and second, we will display the likelihood for this observed distance on the brown strip inside the race track. By pressing the &lt;strong&gt;UPDATE STEP&lt;/strong&gt; button, we will perform our update step and show the resulting posterior at the outer strip. Now we are ready for the next time step. Take an action, by pressing the corresponding button below the race track. After the step is performed, you have to update your posterior by pressing the &lt;strong&gt;PREDICT STEP&lt;/strong&gt; button. You will see that the outer strip will change accordingly. Now we finished one full cycle of the filtering process and are ready to start a new cycle by taking a measurement.&lt;/p&gt;

&lt;p&gt;If you want to reset the environment, just press the reset button in the bottom left corner.
As before you can control the car by using your keyboard: &lt;strong&gt;A&lt;/strong&gt; (Backward), &lt;strong&gt;S&lt;/strong&gt; (Stop),  &lt;strong&gt;D&lt;/strong&gt; (Forward) or the buttons below the race track.&lt;/p&gt;

&lt;p&gt;We see, that it is actually working pretty well. But one thing seems particularly weird: At certain positions on the race track, the brownish inner strip (our likelihood) seems to be uniformly distributed. This is not a bug, but a shortcoming of the linearization. We will always experience this behavior, if the part of the road at our current posterior mean is pointing only in &lt;em&gt;tangential&lt;/em&gt; direction, with the tree as the center. In other words: A small change in position wouldn’t change the distance. When we are linearizing, we assume this local behavior applies for the whole system and we won’t get any new information out of our measurement. To get an intuitive understanding of this, you can imagine two parallel lines. Our car is driving along one of the parallel lines and we take the nearest distance to the other line as a measurement. This measurement would be uninformative because the distance to the parallel line is always the same.&lt;/p&gt;

&lt;h1 id=&quot;acknowledgement&quot;&gt;Acknowledgement&lt;/h1&gt;

&lt;p&gt;The vector graphics of the &lt;a href=&quot;https://www.freepik.com/free-photos-vectors/car&quot;&gt;car&lt;/a&gt; were created by &lt;a href=&quot;https://www.freepik.com/&quot;&gt;Freepik&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://www.freepik.com/free-vector/flat-car-collection-with-side-view_1505022.htm&quot;&gt;&lt;/a&gt;&lt;/p&gt;

&lt;div id=&quot;rad_to_s&quot; style=&quot;width:100px&quot;&gt;&lt;/div&gt;
&lt;div id=&quot;div1&quot;&gt;&lt;/div&gt;
&lt;div id=&quot;div2&quot;&gt;&lt;/div&gt;
&lt;!-- &lt;div id=&quot;system_dist_approx&quot;  style=&quot;width: 600px; height: 600px;&quot;&gt;&lt;/div&gt; --&gt;
&lt;!--&lt;div id=&quot;output_dist_approx&quot;  style=&quot;width: 600px; height: 600px;&quot;&gt;&lt;/div&gt;--&gt;
&lt;script type=&quot;text/javascript&quot; src=&quot;https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_SVG&quot;&gt;&lt;/script&gt;

&lt;script type=&quot;text/x-mathjax-config&quot;&gt;

var mq = window.matchMedia( &quot;(max-width: 570px)&quot; );
if (!mq.matches) {
    MathJax.Hub.Config({
	  CommonHTML: { linebreaks: { automatic: true } },
	  &quot;HTML-CSS&quot;: { linebreaks: { automatic: true } },
	         SVG: { linebreaks: { automatic: true } }
	}); 
} 

&lt;/script&gt;</content><author><name></name></author><summary type="html">This article is the second part of the nonlinear filtering series, where we will derive the extended Kalman filter with non-additive and additive noise directly from the recursive equations of the Bayes filter.</summary></entry><entry><title type="html">Nonlinear filtering: Grid-based filter</title><link href="http://localhost:4000/jekyll/update/2018/10/29/nf-grid-based.html" rel="alternate" type="text/html" title="Nonlinear filtering: Grid-based filter" /><published>2018-10-29T18:05:07+09:00</published><updated>2018-10-29T18:05:07+09:00</updated><id>http://localhost:4000/jekyll/update/2018/10/29/nf-grid-based</id><content type="html" xml:base="http://localhost:4000/jekyll/update/2018/10/29/nf-grid-based.html">&lt;p&gt;The process of Bayes filtering requires to solve integrals, that are in general intractable. One approach to circumvent this problem is the use of grid-based filtering. In this article, we will derive this method directly from the recursive equations of the Bayes filter.  &lt;!--more--&gt;This marks the first part of the nonlinear filtering series. If you haven’t read the &lt;a href=&quot;/jekyll/update/2018/10/29/nf-intro.html&quot;&gt;introduction&lt;/a&gt;, I would recommend to read it first. Before we dive into the derivation, let’s try to state the main idea behind grid-based filtering.&lt;/p&gt;

&lt;script src=&quot;https://d3js.org/d3.v5.min.js&quot; charset=&quot;utf-8&quot;&gt;&lt;/script&gt;

&lt;script type=&quot;text/javascript&quot; async=&quot;&quot; src=&quot;https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_SVG&quot;&gt;&lt;/script&gt;

&lt;script src=&quot;https://cdn.plot.ly/plotly-latest.min.js&quot;&gt;&lt;/script&gt;

&lt;script src=&quot;http://localhost:4000/assets/js/nonlinear_filter/particle_filter.js&quot;&gt;&lt;/script&gt;

&lt;script src=&quot;http://localhost:4000/assets/js/nonlinear_filter/race_car.js&quot;&gt;&lt;/script&gt;

&lt;script src=&quot;http://localhost:4000/assets/js/nonlinear_filter/race_track.js&quot;&gt;&lt;/script&gt;

&lt;script src=&quot;http://localhost:4000/assets/js/nonlinear_filter/util.js&quot;&gt;&lt;/script&gt;

&lt;script src=&quot;http://localhost:4000/assets/js/nonlinear_filter/plot.js&quot;&gt;&lt;/script&gt;

&lt;script src=&quot;http://localhost:4000/assets/js/nonlinear_filter/scene.js&quot;&gt;&lt;/script&gt;

&lt;script src=&quot;http://localhost:4000/assets/js/nonlinear_filter/discrete_bayes_filter.js&quot;&gt;&lt;/script&gt;

&lt;link href=&quot;https://fonts.googleapis.com/css?family=Roboto&quot; rel=&quot;stylesheet&quot; /&gt;

&lt;link rel=&quot;stylesheet&quot; type=&quot;text/css&quot; href=&quot;http://localhost:4000/assets/css/nonlinear_filter/style.css&quot; /&gt;

&lt;script type=&quot;text/javascript&quot;&gt;

	// scene_flags

	scene = [];
	scenes = [];
	scenes_name = [];
	interval = null;
	loaded = false;
	var aa = 1;
	var fast_dur = 300;
	var slow_dur = 1000;
	var ani_step = 3;


	touch_id = null;





&lt;/script&gt;

&lt;div class=&quot;important_box&quot;&gt;
  &lt;p&gt;The &lt;strong&gt;grid-based filter&lt;/strong&gt; approximates the Bayes filter by &lt;strong&gt;restricting&lt;/strong&gt; and &lt;strong&gt;discretizing&lt;/strong&gt; the state, input and observation space, to obtain &lt;strong&gt;finite&lt;/strong&gt; domains.&lt;/p&gt;
&lt;/div&gt;

&lt;h2 id=&quot;derivation&quot;&gt;Derivation&lt;/h2&gt;

&lt;p&gt;We will start the derivation directly from the recursive equations of the Bayes filter with the &lt;strong&gt;prediction step&lt;/strong&gt;&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;p(x_{t+1}|y_{0:t},u_{0:t}) = \int_{x_{t}} p(x_{t+1}|x_{t}, u_{t})p(x_{t}|y_{0:t},u_{0:t-1}) dx_{t}&lt;/script&gt;

&lt;p&gt;and the &lt;strong&gt;update step&lt;/strong&gt;&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;p(x_t|y_{0:t},u_{0:t-1}) = \frac{p(y_t|x_t)p(x_t|y_{0:t-1},u_{0:t-1})}{\int_{x_t}p(y_t|x_t)p(x_t|y_{0:t-1},u_{0:t-1}) \,dx_t} .&lt;/script&gt;

&lt;p&gt;The first and most important step in order to arrive at the equations of the grid-based filter is to discretize our system and observation model. Given a set of discretization points \((x^1,\ldots,x^X)\), \((y^1,\ldots,y^Y)\) and \((u^1,\ldots,u^U)\) the result of the discretization can be written as&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\hat{p}(x_{t+1}|x_{t}, u_{t}) = \frac{1}{Z}p(x_{t+1}|x_{t}, u_{t})\sum_{k=1}^X\sum_{l=1}^X \sum_{m=1}^U  \delta_{x^k}(x_{t+1})\delta_{x^l}(x_t)\delta_{u^m}(u_t)&lt;/script&gt;

&lt;p&gt;for the system model and&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\hat{p}(y_t|x_t) = \frac{1}{Z}p(y_{t}|x_{t})\sum_{k=1}^Y\sum_{l=1}^X  \delta_{y^k}(y_{t})\delta_{x^l}(x_t)&lt;/script&gt;

&lt;p&gt;for our observation model, where \(Z\) is a normalization factor.&lt;/p&gt;

&lt;div class=&quot;extra_box&quot;&gt;
  &lt;p&gt;These equations can look confusing and random. Especially if you are not familiar with the &lt;a href=&quot;https://en.wikipedia.org/wiki/Dirac_delta_function&quot;&gt;Dirac delta function&lt;/a&gt;. This box will give a short introduction to the Dirac delta function and provide the tools you will need. &lt;strong&gt;Warning:&lt;/strong&gt; The Dirac delta function is actually not a function, but a distribution or a measure!&lt;/p&gt;

  &lt;p&gt;The Dirac delta function \(\delta(x)\) can be &lt;em&gt;imagined&lt;/em&gt; as a function, that is &lt;em&gt;infinite&lt;/em&gt; at \(x=0\) and &lt;em&gt;zero&lt;/em&gt; at \(x \neq 0\) with the property&lt;/p&gt;

  &lt;script type=&quot;math/tex; mode=display&quot;&gt;\int_x \delta(x)\,dx = 1.&lt;/script&gt;

  &lt;p&gt;It is not possible to plot the Dirac delta function, but we can visualize it schematically by using an arrow pointing upwards, as shown in the figure below.&lt;/p&gt;
  &lt;div style=&quot;text-align:center; width:100%;display:inline-block;&quot;&gt;&lt;div id=&quot;dirac&quot; style=&quot;width:85%;display:inline-block;&quot;&gt;&lt;/div&gt;&lt;/div&gt;

  &lt;p&gt;The length of the line represents the area under the function. The expression \(\delta(x-y)\) is a shifted version of the Dirac delta function with its peak at \(y\).&lt;/p&gt;

  &lt;div style=&quot;text-align:center; width:100%;display:inline-block;&quot;&gt;&lt;div id=&quot;dirac_shift&quot; style=&quot;width:85%;display:inline-block;&quot;&gt;&lt;/div&gt;&lt;/div&gt;

  &lt;p&gt;To unclutter the notation, we will use the shorthand \(\delta_y(x)\) for \(\delta(x-y)\).&lt;/p&gt;

  &lt;p&gt;The &lt;em&gt;sifting property&lt;/em&gt;&lt;/p&gt;

  &lt;script type=&quot;math/tex; mode=display&quot;&gt;\int_x f(x)\delta_y(x)\,dx = f(y)&lt;/script&gt;

  &lt;p&gt;will play an important role in our derivation. Intuitively, it is sifting out the function value of \(f(x)\) at \(y\).&lt;/p&gt;

  &lt;p&gt;The multivariate Dirac delta function, which can be &lt;em&gt;loosely&lt;/em&gt; thought of as &lt;em&gt;infinite&lt;/em&gt; at \((x_1,\ldots,x_n)=(0,\ldots,0)\) and &lt;em&gt;zero&lt;/em&gt; at \((x_1,\ldots,x_n) \neq (0,\ldots,0)\) is defined as the product of several Dirac delta functions:&lt;/p&gt;

  &lt;script type=&quot;math/tex; mode=display&quot;&gt;\delta(x_1,\ldots,x_n) = \delta(x_1)* \ldots *\delta(x_n).&lt;/script&gt;

  &lt;p&gt;Several Dirac delta functions can also be combined to form a comb or grid, which is shown in the following figure.&lt;/p&gt;

  &lt;div style=&quot;text-align:center; width:100%;display:inline-block;&quot;&gt;&lt;div id=&quot;dirac_comb&quot; style=&quot;width:85%;display:inline-block;&quot;&gt;&lt;/div&gt;&lt;/div&gt;

  &lt;p&gt;To obtain such a grid, the Dirac delta functions are simply added together&lt;/p&gt;

  &lt;script type=&quot;math/tex; mode=display&quot;&gt;\sum_{i=1}^N\delta_{x_i}(x).&lt;/script&gt;

  &lt;p&gt;Finally, we can multiply the grid with a function \(f(x)\) :&lt;/p&gt;

  &lt;script type=&quot;math/tex; mode=display&quot;&gt;\sum_{i=1}^Nf(x)\delta_{x_i}(x).&lt;/script&gt;

  &lt;p&gt;The particular Dirac delta functions are weighted by the functional value at the corresponding point. This can be visualized as following.&lt;/p&gt;

  &lt;div style=&quot;text-align:center; width:100%;display:inline-block;&quot;&gt;&lt;div id=&quot;dirac_wcomb&quot; style=&quot;width:85%;display:inline-block;&quot;&gt;&lt;/div&gt;&lt;/div&gt;

  &lt;p&gt;Now that we have a better understanding of the Dirac delta function, let’s look again at our system and observation model. In our system model, we find a multivariate Dirac delta function&lt;/p&gt;

  &lt;script type=&quot;math/tex; mode=display&quot;&gt;\delta_{x^k}(x_{t+1})\delta_{x^l}(x_t)\delta_{u^m}(u_t),&lt;/script&gt;

  &lt;p&gt;where the particular Dirac delta functions could be multivariate as well. We also note, that the multivariate Dirac delta function is embedded in a triple sum over the corresponding discrete spaces. It describes, therefore, a grid of Dirac delta functions.
Finally, we multiply this grid with our system model. To obtain a proper probability distribution, we normalize our distribution with \(Z\).
The observation model can be treated likewise.&lt;/p&gt;

&lt;/div&gt;

&lt;p&gt;If we start the recursion with a discretized prior distribution&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\hat{p}(x_0) = \sum_{k=1}^X w^k \delta_{x^k}(x_0)&lt;/script&gt;

&lt;p&gt;all of our belief distributions will be discretized as well.
Therefore, the posterior will have the form&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\hat{p}(x_{t}|\cdot) = \sum_{k=1}^X w^k \delta_{x^k}(x_t).&lt;/script&gt;

&lt;h1 id=&quot;prediction-step&quot;&gt;Prediction step&lt;/h1&gt;

&lt;p&gt;Let’s see what happens, if we plug the discretized version of our system model into the equations of the prediction step:&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\hat{p}(x_{t+1}|y_{0:t},u_{0:t}) = \int_{x_{t}} \frac{1}{Z}p(x_{t+1}|x_{t}, u_{t})\sum_{k=1}^X\sum_{l=1}^X\sum_{m=1}^U \delta_{x^k}(x_{t+1})\delta_{x^l}(x_t)\delta_{u^m}(u_t)\sum_{n=1}^X w^n \delta_{x^n}(x_t) dx_{t}&lt;/script&gt;

&lt;p&gt;First of all, we know our current input is \(u^i\). To evaluate \(\hat{p}(x_{t+1}|y_{0:t},u_{0:t}) \) at \(u^i\), we simply have to compute \(\int_{u_t}\hat{p}(x_{t+1}|y_{0:t},u_{0:t})\delta_{u^i}(u_t)\,d_t \). As a result, we will obtain&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\hat{p}(x_{t+1}|y_{0:t},u_{0:t}) = \frac{1}{Z}\int_{x_{t}}p(x_{t+1}|x_{t}, u_t=u^m) \sum_{k=1}^X\sum_{l=1}^X  \delta_{x^k}(x_{t+1})\delta_{x^l}(x_t)\sum_{n=1}^X w^n \delta_{x^n}(x_t) dx_{t}&lt;/script&gt;

&lt;p&gt;The following expression&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\sum_{l=1}^X \delta_{x^l}(x_t)\sum_{n=1}^X w^n \delta_{x^n}(x_t)&lt;/script&gt;

&lt;p&gt;is not zero only if \(l = n\). Therefore, we can replace this expression with&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\sum_{n=1}^X w^n \delta_{x^n}(x_t)&lt;/script&gt;

&lt;p&gt;and obtain&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\hat{p}(x_{t+1}|y_{0:t},u_{0:t}) = \frac{1}{Z}\int_{x_{t}}p(x_{t+1}|x_{t}, u_t=u^m) \sum_{k=1}^X\sum_{n=1}^X  \delta_{x^k}(x_{t+1}) w^n \delta_{x^n}(x_t) dx_{t} .&lt;/script&gt;

&lt;p&gt;By rearranging the integral and sums we  obtain&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\hat{p}(x_{t+1}|y_{0:t},u_{0:t}) = \frac{1}{Z}\sum_{k=1}^X\delta_{x^k}(x_{t+1})\int_{x_{t}}p(x_{t+1}|x_{t}, u_t=u^m) \sum_{n=1}^X   w^n \delta_{x^n}(x_t) dx_{t}&lt;/script&gt;

&lt;p&gt;Using the sifting property we will arrive at&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\hat{p}(x_{t+1}|y_{0:t},u_{0:t}) = \frac{1}{Z}\sum_{k=1}^X\delta_{x^k}(x_{t+1})\sum_{n=1}^Xp(x_{t+1}|x_{t} = x^n, u_t=u^m)    w^n&lt;/script&gt;

&lt;h1 id=&quot;update-step&quot;&gt;Update step&lt;/h1&gt;

&lt;p&gt;Let’s start our treatment of the update step and by looking at the numerator. Again, we plug in our discretized distributions to obtain&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\hat{p}(y_t|x_t)\hat{p}(x_t|y_{0:t-1},u_{0:t-1}) = \frac{1}{Z}p(y_{t}|x_{t})\sum_{k=1}^Y\sum_{l=1}^X  \delta_{y^k}(y_{t})\delta_{x^l}(x_t)\sum_{m=1}^X w^m \delta_{x^m}(x_t).&lt;/script&gt;

&lt;p&gt;We know, that we have an observation \(y^k\), which we can plug in in the same way as the input above:&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\hat{p}(y_t|x_t)\hat{p}(x_t|y_{0:t-1},u_{0:t-1}) = \frac{1}{Z}p(y_{t}=y^k|x_{t})\sum_{m=1}^Xw^m\delta_{x^m}(x_t)&lt;/script&gt;

&lt;p&gt;The denominator is simply the integral over \(x_t\) of the expression above:&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\int_{x_t}\hat{p}(y_t|x_t)\hat{p}(x_t|y_{0:t-1},u_{0:t-1}) \,dx_t = \frac{1}{Z}\int_{x_t}p(y_{t}=y^k|x_{t})\sum_{m=1}^Xw^m\delta_{x^m}(x_t) \,dx_t.&lt;/script&gt;

&lt;p&gt;With help of the sifting property, we obtain the final expression&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\int_{x_t}\hat{p}(y_t|x_t)\hat{p}(x_t|y_{0:t-1},u_{0:t-1}) \,dx_t = \frac{1}{Z}\sum_{m=1}^Xw^mp(y_{t}=y^k|x_{t}=x^k)&lt;/script&gt;

&lt;p&gt;for the denominator.&lt;/p&gt;

&lt;p&gt;The full update step is then defined as&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\hat{p}(x_t|y_{0:t},u_{0:t-1}) = \frac{p(y_{t}=y^k|x_{t})\sum_{m=1}^Xw^m\delta_{x^m}(x_t)}{\sum_{l=1}^Xw^mp(y_{t}=y^k|x_{t}=x^k)} .&lt;/script&gt;

&lt;p&gt;Let’s summarize our results!&lt;/p&gt;

&lt;div class=&quot;important_box&quot;&gt;
  &lt;h1&gt;Grid-based filter&lt;/h1&gt;

  &lt;p&gt;The recursive formula for the grid-based filter in state space models consists of the &lt;strong&gt;prediction step&lt;/strong&gt;&lt;/p&gt;

  &lt;script type=&quot;math/tex; mode=display&quot;&gt;\hat{p}(x_{t+1}|y_{0:t},u_{0:t}) = \frac{1}{Z}\sum_{k=1}^X\delta_{x^k}(x_{t+1})\sum_{n=1}^Xp(x_{t+1}|x_{t} = x^n, u_t=u^m)    w^n&lt;/script&gt;

  &lt;p&gt;and the &lt;strong&gt;update step&lt;/strong&gt;&lt;/p&gt;

  &lt;script type=&quot;math/tex; mode=display&quot;&gt;\hat{p}(x_t|y_{0:t},u_{0:t-1}) = \frac{p(y_{t}=y^k|x_{t})\sum_{m=1}^Xw^m\delta_{x^m}(x_t)}{\sum_{l=1}^Xw^mp(y_{t}=y^k|x_{t}=x^k)} .&lt;/script&gt;

  &lt;p&gt;The recursion is started with a discrete prior distribution over the initial state \(\hat{p}(x_0)\).&lt;/p&gt;

&lt;/div&gt;

&lt;h1 id=&quot;discrete-probability-distribution&quot;&gt;Discrete probability distribution&lt;/h1&gt;

&lt;p&gt;Our discretized system and observation model is non-zero only at the points on the grid. Nonetheless, the model itself is still continuous: we can evaluate the function at points, which are not part of the grid. Then again, the posterior will always remain on the grid during the filtering process. Thus, we can represent our system as a discrete probability distribution&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;P(x_{t+1}=k|x_t=l,u=m) = \frac{1}{Z(l,m)} p(x_{t+1}=x^k|x_{t}=x^l, u_t=u^m)&lt;/script&gt;

&lt;p&gt;with the normalization factor \(Z(l,m) = \sum_{k=1}^X p(x_{t+1}=x^k|x_{t}=x^l, u_t=u^m) \).&lt;/p&gt;

&lt;p&gt;Similarly, the observation model can be represented by the discrete probability distribution&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;P(y_{t}=k|x_t=l) = \frac{1}{Z(l)} p(y_{t}=y^k|x_{t}=x^l)&lt;/script&gt;

&lt;p&gt;with the normalization factor \(Z(l) = \sum_{k=1}^X p(y_{t}=y^k|x_{t}=x^l) \). With this representation, we arrive at the Bayes filter for discrete probability distributions.&lt;/p&gt;

&lt;div class=&quot;important_box&quot;&gt;
  &lt;h1&gt;Discrete Bayes filter&lt;/h1&gt;

  &lt;p&gt;The recursive formula for the discrete Bayes filter in state space models consists of the &lt;strong&gt;prediction step&lt;/strong&gt;&lt;/p&gt;

  &lt;script type=&quot;math/tex; mode=display&quot;&gt;P(x_{t+1}|y_{0:t},u_{0:t}) = \sum_{x_{t}} p(x_{t+1}|x_{t}, u_{t})p(x_{t}|y_{0:t},u_{0:t-1})&lt;/script&gt;

  &lt;p&gt;and the &lt;strong&gt;update step&lt;/strong&gt;&lt;/p&gt;

  &lt;script type=&quot;math/tex; mode=display&quot;&gt;P(x_t|y_{0:t},u_{0:t-1}) = \frac{P(y_t|x_t)P(x_t|y_{0:t-1},u_{0:t-1})}{\sum_{x_t} P(y_t|x_t)P(x_t|y_{0:t-1},u_{0:t-1})} .&lt;/script&gt;

  &lt;p&gt;The recursion is started with a discrete prior distribution over the initial state \(P(x_0)\).&lt;/p&gt;

&lt;/div&gt;

&lt;h2 id=&quot;example&quot;&gt;Example&lt;/h2&gt;

&lt;p&gt;Enough of the dry theory! Let’s play around with the grid-based filter in our race track example.&lt;/p&gt;

&lt;svg id=&quot;race_track_mar_loc&quot; style=&quot;width:100%&quot; onclick=&quot;on_click()&quot;&gt;&lt;/svg&gt;
&lt;script&gt;


	n_scene = load_race_track(&quot;race_track_mar_loc&quot;,&quot;http://localhost:4000&quot;,400);
	n_scene.mode = 2;
	n_scene.filter = &quot;bayes&quot;;
	n_scene.dur=slow_dur;
	// define particle filter 

	n_scene.auto_start = false;

	n_scene.t = 1;

	n_scene.ids = [&quot;race_track_mar_loc_likelihood&quot;, &quot;race_track_mar_loc_update&quot;,&quot;race_track_mar_loc_timestep&quot;, &quot;race_track_mar_loc_predict&quot; ];

	n_scene.loaded = function(){
		//var ids = [&quot;race_track_mar_loc_likelihood&quot;, &quot;race_track_mar_loc_update&quot;,&quot;race_track_mar_loc_timestep&quot;, &quot;race_track_mar_loc_predict&quot; ];
		//for (var i=0; i&lt;ids.length;i++){

		//	document.getElementById(ids[i]).style.display=&quot;none&quot;;
		//}
		document.getElementById(&quot;race_track_mar_loc_likelihood&quot;).style.display=&quot;block&quot;;
		this.rt.hide_strip(&quot;inner&quot;);


		this.restart = function(){
			for (var i=0; i&lt;this.ids.length;i++){

				document.getElementById(this.ids[i]).style.display=&quot;none&quot;;
			}
			document.getElementById(&quot;race_track_mar_loc_likelihood&quot;).style.display=&quot;block&quot;;
			this.rc.reset();
			this.t = 1;
			this.bf.reset();
			this.rt.hide_strip(&quot;inner&quot;);
			this.rt.show_strip(&quot;outer&quot;);
			this.rt.update_strip(&quot;outer&quot;, normalize_vector(this.bf.posterior));
		}


		this.rt.set_restart_button(this.restart.bind(this))



	}.bind(n_scene)


	n_scene.step = function(){
		this.t++;
		for (var i=0; i&lt;this.ids.length;i++){

			document.getElementById(this.ids[i]).style.display=&quot;none&quot;;
		}
		//document.getElementById(ids[this.t%3]).style.display=&quot;block&quot;;


		if(this.t % 4 == 0){
			this.rc.step(this.rc.current_input);
			this.last_input = this.rc.current_input;
			document.getElementById(&quot;race_track_mar_loc_predict&quot;).style.display=&quot;block&quot;;
			this.rt.hide_strip(&quot;inner&quot;);
		}else if(this.t % 4 == 1){
			this.bf.predict(this.last_input);
			
			this.rt.update_strip(&quot;outer&quot;, normalize_vector(this.bf.posterior));
			document.getElementById(&quot;race_track_mar_loc_likelihood&quot;).style.display=&quot;block&quot;;
		}else if(this.t % 4 == 2){
			this.rt.show_strip(&quot;inner&quot;);
			this.output = scene.rc.output_dist_sample(0);
			this.rt.update_strip(&quot;inner&quot;, get_output_dist_normalized_from_distance(this.rc, this.rt, this.output));
			document.getElementById(&quot;race_track_mar_loc_update&quot;).style.display=&quot;block&quot;;
		}else if(this.t % 4 == 3){
			
	    	var y = scene.bf.cont_2_disc_output(this.output);
			this.bf.update(y);
			this.rt.update_strip(&quot;outer&quot;, normalize_vector(this.bf.posterior));
			document.getElementById(&quot;race_track_mar_loc_timestep&quot;).style.display=&quot;block&quot;;
		}



	}.bind(n_scene);

	scenes_name[&quot;race_track_mar_loc&quot;] = n_scene;
	scenes.push(n_scene);

&lt;/script&gt;

&lt;div style=&quot;float:right&quot; class=&quot;slidecontainer&quot;&gt;
  &lt;input type=&quot;range&quot; min=&quot;100&quot; max=&quot;700&quot; value=&quot;400&quot; class=&quot;slider&quot; id=&quot;myRange&quot; /&gt;
&lt;/div&gt;

&lt;div id=&quot;race_track_mar_loc_timestep&quot; class=&quot;button_set&quot;&gt;
&lt;div class=&quot;bt3 bt&quot; onclick=&quot;scenes_name['race_track_mar_loc'].rc.current_input=0;scenes_name['race_track_mar_loc'].step();&quot;&gt;Backward&lt;/div&gt;
&lt;div class=&quot;bt3 bt&quot; onclick=&quot;scenes_name['race_track_mar_loc'].rc.current_input=1;scenes_name['race_track_mar_loc'].step();&quot;&gt;No action&lt;/div&gt;
&lt;div class=&quot;bt3 bt&quot; onclick=&quot;scenes_name['race_track_mar_loc'].rc.current_input=2;scenes_name['race_track_mar_loc'].step();&quot;&gt;Forward&lt;/div&gt;
 &lt;span class=&quot;stretch&quot;&gt;&lt;/span&gt;
&lt;/div&gt;

&lt;div id=&quot;race_track_mar_loc_predict&quot; class=&quot;button_set&quot;&gt;
&lt;div class=&quot;bt1  bt&quot; onclick=&quot;scenes_name['race_track_mar_loc'].step();&quot;&gt;Predict step&lt;/div&gt;
  &lt;span class=&quot;stretch&quot;&gt;&lt;/span&gt;
&lt;/div&gt;

&lt;div id=&quot;race_track_mar_loc_likelihood&quot; class=&quot;button_set&quot;&gt;
&lt;div class=&quot;bt1  bt&quot; onclick=&quot;scenes_name['race_track_mar_loc'].step();&quot;&gt;Observe&lt;/div&gt;
  &lt;span class=&quot;stretch&quot;&gt;&lt;/span&gt;
&lt;/div&gt;

&lt;div id=&quot;race_track_mar_loc_update&quot; class=&quot;button_set&quot; onclick=&quot;scenes_name['race_track_mar_loc'].step();&quot;&gt;
&lt;div class=&quot;bt1  bt&quot;&gt;Update step&lt;/div&gt;
  &lt;span class=&quot;stretch&quot;&gt;&lt;/span&gt;
&lt;/div&gt;

&lt;p&gt;On the outside the race track, you will notice a blue colored strip. This strip represents our current posterior of the current position of the race car. At the beginning, we have no knowledge about the position of the race car and assign uniform probability over all positions. By pressing the &lt;strong&gt;OBSERVE&lt;/strong&gt; button two things will happen: first, we will take a measurement of the distance of the tree and second, we will display the likelihood for this observed distance on the brown strip inside the race track. By pressing the &lt;strong&gt;UPDATE STEP&lt;/strong&gt; button, we will perform our update step and show the resulting posterior at the outer strip. You will note, that both strips will have the same form after the update. The reason is simple: we just multiplied our likelihood with a constant vector and normalized afterward. Now we are ready for the next time step. Take an action, by pressing the corresponding button below the race track. After the step is performed, you have to update your posterior by pressing the &lt;strong&gt;PREDICT STEP&lt;/strong&gt; button. You will see that the outer strip will change accordingly. Now we finished one full cycle of the filtering process and are ready to start a new cycle by taking a measurement.&lt;/p&gt;

&lt;p&gt;With the slider below the race track, you can choose a grid size of the discrete probability models. If you want to reset the environment, just press the reset button in the bottom left corner.
As before you can control the car by using your keyboard: &lt;strong&gt;A&lt;/strong&gt; (Backward), &lt;strong&gt;S&lt;/strong&gt; (Stop),  &lt;strong&gt;D&lt;/strong&gt; (Forward) or the buttons below the race track.&lt;/p&gt;

&lt;script&gt;



var slider = document.getElementById(&quot;myRange&quot;);

slider.oninput = function() {

	scene = scenes_name['race_track_mar_loc'];

    // delete strips
    scene.rt.delete_strip(&quot;inner&quot;);
    scene.rt.delete_strip(&quot;outer&quot;);


    // set strip domain
    scene.rt.set_strip_domain(parseInt(this.value));


    // create new bayes filter
    scene.bf = init_bayes_filter(scene.rc, scene.rt);

	// create strips
    scene.rt.init_strip(&quot;inner&quot;,get_output_dist_normalized(scene.rc, scene.rt, scene.rc.state) , scene.rt.strip_color.inner, scene.rt.strip_width.inner)
    scene.rt.init_strip(&quot;outer&quot;, normalize_vector(scene.bf.posterior), scene.rt.strip_color.outer, scene.rt.strip_width.outer)
    scene.restart()
}
&lt;/script&gt;

&lt;p&gt;Still feeling hungry for Bayes filters? Then you should definitely check out the next part of the nonlinear filtering series covering the derivation of the &lt;a href=&quot;/jekyll/update/2018/10/31/nf-ekf.html&quot;&gt;extended Kalman filter&lt;/a&gt;. See you there!&lt;/p&gt;

&lt;h1 id=&quot;acknowledgement&quot;&gt;Acknowledgement&lt;/h1&gt;

&lt;p&gt;The vector graphics of the &lt;a href=&quot;https://www.freepik.com/free-photos-vectors/car&quot;&gt;car&lt;/a&gt; were created by &lt;a href=&quot;https://www.freepik.com/&quot;&gt;Freepik&lt;/a&gt;.&lt;/p&gt;

&lt;script&gt;


dirac_plot(&quot;#dirac&quot;,[{x:0,w:0.7,t:&quot;&quot;}], false, null);
dirac_plot(&quot;#dirac_shift&quot;,[{x:0.25,w:0.7,t:&quot;y&quot;}], true, null);

var nd = 17;
var grid = [...Array(nd)].map((e,i)=&gt;{return (i - (nd-1)/2)/(1.5*nd)});
comb = [...Array(nd)].map((e,i)=&gt;{return {x:grid[i], w:0.7, t:&quot;&quot;}})
dirac_plot(&quot;#dirac_comb&quot;,comb, true, null);

wcomb = [...Array(nd)].map((e,i)=&gt;{return {x:grid[i], w:0.1*gaussian(grid[i],0,0.15), t:&quot;&quot;}})

var np = 101;
gauss = [...Array(np)].map((e,i)=&gt;{return {x:(i - (np-1)/2)/(1.5*np), w:0.1*gaussian((i - (np-1)/2)/(1.5*np),0,0.15), t:&quot;&quot;};})

dirac_plot(&quot;#dirac_wcomb&quot;,wcomb, true, gauss);
&lt;/script&gt;</content><author><name></name></author><summary type="html">The process of Bayes filtering requires to solve integrals, that are in general intractable. One approach to circumvent this problem is the use of grid-based filtering. In this article, we will derive this method directly from the recursive equations of the Bayes filter.</summary></entry><entry><title type="html">Nonlinear filtering: Introduction</title><link href="http://localhost:4000/jekyll/update/2018/10/29/nf-intro.html" rel="alternate" type="text/html" title="Nonlinear filtering: Introduction" /><published>2018-10-29T18:04:07+09:00</published><updated>2018-10-29T18:04:07+09:00</updated><id>http://localhost:4000/jekyll/update/2018/10/29/nf-intro</id><content type="html" xml:base="http://localhost:4000/jekyll/update/2018/10/29/nf-intro.html">&lt;p&gt;This post will start a series of articles that will treat common nonlinear filtering methods that are based on the Bayes filter. The motivation is to provide an intuitive understanding of these methods by deriving them directly from the general Bayes filter. This derivation is done in steps, that are supposed to be as atomic as possible. Furthermore, each nonlinear filtering method will be shown in action by providing an interactive example to play around with. This series will require some basic knowledge in math. Especially in linear algebra and probability theory.&lt;/p&gt;

&lt;!--more--&gt;
&lt;script src=&quot;https://d3js.org/d3.v5.min.js&quot; charset=&quot;utf-8&quot;&gt;&lt;/script&gt;

&lt;script src=&quot;https://cdn.plot.ly/plotly-latest.min.js&quot;&gt;&lt;/script&gt;

&lt;script src=&quot;http://localhost:4000/assets/js/nonlinear_filter/particle_filter.js&quot;&gt;&lt;/script&gt;

&lt;script src=&quot;http://localhost:4000/assets/js/nonlinear_filter/race_car.js&quot;&gt;&lt;/script&gt;

&lt;script src=&quot;http://localhost:4000/assets/js/nonlinear_filter/race_track.js&quot;&gt;&lt;/script&gt;

&lt;script src=&quot;http://localhost:4000/assets/js/nonlinear_filter/util.js&quot;&gt;&lt;/script&gt;

&lt;script src=&quot;http://localhost:4000/assets/js/nonlinear_filter/plot.js&quot;&gt;&lt;/script&gt;

&lt;script src=&quot;http://localhost:4000/assets/js/nonlinear_filter/scene.js&quot;&gt;&lt;/script&gt;

&lt;script src=&quot;http://localhost:4000/assets/js/nonlinear_filter/discrete_bayes_filter.js&quot;&gt;&lt;/script&gt;

&lt;link href=&quot;https://fonts.googleapis.com/css?family=Roboto&quot; rel=&quot;stylesheet&quot; /&gt;

&lt;link rel=&quot;stylesheet&quot; type=&quot;text/css&quot; href=&quot;http://localhost:4000/assets/css/nonlinear_filter/style.css&quot; /&gt;

&lt;script type=&quot;text/javascript&quot;&gt;





function draw_ssm(svg){


      var radius = 30;
      var dist_x = 120;
      var dist_y = 120;
      var margin_x = 120;
      var margin_y = 50;
      var markersize = 10;

      var input_ns = [];
      var state_ns = [];
      var output_ns = [];
      var edges = [];
      var T = 4;

      for (var t = 0; t&lt;T;t++){


      	ind = &quot;t&quot;

      	if (t&lt;T-1) ind+=(t-T+1)


      	if (t&lt;T-1) input_ns.push({title: &quot;\\( u_{&quot; + ind + &quot;}\\)&quot;, type: &quot;prob&quot;, x: margin_x + dist_x*t , y: margin_y , fill:&quot;#e3e5feff&quot;});

      	statefill = &quot;#FFFFFF&quot;;
        state_ns.push({title: &quot;\\( x_{&quot; + ind + &quot;} \\)&quot;, type: &quot;prob&quot;, x: margin_x + dist_x*t , y: margin_y + dist_y, fill:statefill});
        output_ns.push({title: &quot;\\( y_{&quot; + ind + &quot;} \\)&quot;, type: &quot;prob&quot;, x: margin_x + dist_x*t , y: margin_y+ 2*dist_y, fill:&quot;#e3e5feff&quot;});



        edges.push({source: state_ns[t], target: output_ns[t], dash:&quot;&quot;})
        if (t&gt;0) {
        	edges.push({source: state_ns[t-1], target: state_ns[t], dash:&quot;&quot;})
        	edges.push({source: input_ns[t-1], target: state_ns[t], dash:&quot;&quot;})
        }
      }


    bstate_h = {x: state_ns[0].x - radius*4, y: state_ns[0].y}
    binput_h = {x: state_ns[0].x - 2*Math.sqrt(2)*radius, y: state_ns[0].y- 2*Math.sqrt(2)*radius}

    edges.push({source: bstate_h, target: state_ns[0], dash:&quot;5,5&quot;})
    edges.push({source: binput_h, target: state_ns[0], dash:&quot;5,5&quot;})


  	nodes = input_ns.concat(state_ns).concat(output_ns);

  	var svg_w = margin_x + dist_x*(T-1) + 50;
    var svg_h = 2*margin_y + 2*dist_y;

    create_graph(d3.select(svg), nodes, edges, radius, markersize, svg_w, svg_h);
    }



	// scene_flags

	scene = [];
	scenes = [];
	scenes_name = [];
	interval = null;
	loaded = false;
	var aa = 1;
	var fast_dur = 300;
	var slow_dur = 1000;
	var ani_step = 3;


	touch_id = null;





&lt;/script&gt;

&lt;h2 id=&quot;introduction&quot;&gt;Introduction&lt;/h2&gt;

&lt;p&gt;Recently, I wrote an article about the &lt;a href=&quot;/jekyll/update/2018/10/10/kalman_filter.html&quot;&gt;derivation of the Kalman filter&lt;/a&gt;. When we are using the Kalman filter we assume that our models are linear Gaussian state space models. In this scenario, we are lucky because we can compute everything analytically in closed form. But at some point in time, we have to face the cruel truth that the real world is normally anything but linear. With nonlinear models, it is not possible to compute the equation of the Bayes filter in closed form, anymore. Nonetheless, we are still lucky, because there are many methods that provide approximations of the Bayes filter. Unfortunately, learning about those methods can be quite frustrating, many resources simply state the corresponding equations and are not providing any further explanations and intuitions. This series of blog posts is an attempt to fix this and provide derivations of these methods directly from the equations of the Bayes filter. Furthermore, presenting merely concatenations of equations can be very frustrating and tiring as well. Thus, the derivations are enriched with figures and examples to obtain a better understanding of what we are actually doing.
The current plan is to write articles about the following methods:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;/jekyll/update/2018/10/29/nf-grid-based.html&quot;&gt;Grid-based filter&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;/jekyll/update/2018/10/31/nf-ekf.html&quot;&gt;Extended Kalman filter&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;Unscented Kalman filter&lt;/li&gt;
  &lt;li&gt;Particle filter&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;In this first post, I will take the chance to introduce the concept of the Bayes filter and to present the running example for the rest of this series.
Let’s get started!&lt;/p&gt;

&lt;h2 id=&quot;bayes-filter&quot;&gt;Bayes filter&lt;/h2&gt;

&lt;p&gt;Let’s try to state the main idea of the Bayes filter in a compact manner.&lt;/p&gt;

&lt;div class=&quot;important_box&quot;&gt;
  &lt;p&gt;The &lt;strong&gt;Bayes filter&lt;/strong&gt; is used to &lt;strong&gt;infer&lt;/strong&gt; the current state of a probabilistic state space model given all observations and inputs up to the current timestep and a prior distribution of the initial state.&lt;/p&gt;
&lt;/div&gt;

&lt;p&gt;We define our probabilistic state space model by&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{align}
x_{t+1} &amp;\sim p(x_{t+1}|x_{t}, u_{t}) \\

y_t &amp;\sim p(y_t|x_t) 
\end{align} %]]&gt;&lt;/script&gt;

&lt;p&gt;and an initial state distribution \(p(x_0)\). In the figure below, our model is visualized as a probabilistic graphical model.&lt;/p&gt;

&lt;svg class=&quot;pgm_centered&quot; onload=&quot;draw_ssm(this);&quot;&gt;&lt;/svg&gt;

&lt;p&gt;Knowledge about probabilistic graphical models is not required to be able to follow this series, but it can be quite helpful for understanding the dependencies between the state, input and output.&lt;/p&gt;

&lt;p&gt;Now that we have briefly introduced the state space model, we can formulate the objective of Bayes filters in a more rigorous way: We want to calculate \(p(x_t|y_{0:t},u_{0:t-1})\) given the prior initial distribution \(p(x_0)\), where the shorthand \(y_{n:m}\) stands for the set \(y_n,…,y_m\). With help of the basic rules of probability, we can find a way to calculate this expression in a recursive fashion. This recursion is composed of two distinct steps: the &lt;strong&gt;update&lt;/strong&gt; and &lt;strong&gt;predict&lt;/strong&gt; step.&lt;/p&gt;

&lt;div class=&quot;important_box&quot;&gt;
  &lt;h1&gt;Recursive formula of the Bayes filter&lt;/h1&gt;

  &lt;p&gt;The recursive formula for the Bayes filter in state space models consists of the &lt;strong&gt;prediction step&lt;/strong&gt;&lt;/p&gt;

  &lt;script type=&quot;math/tex; mode=display&quot;&gt;p(x_{t+1}|y_{0:t},u_{0:t}) = \int_{x_{t}} p(x_{t+1}|x_{t}, u_{t})p(x_{t}|y_{0:t},u_{0:t-1}) dx_{t}&lt;/script&gt;

  &lt;p&gt;and the &lt;strong&gt;update step&lt;/strong&gt;&lt;/p&gt;

  &lt;script type=&quot;math/tex; mode=display&quot;&gt;p(x_t|y_{0:t},u_{0:t-1}) = \frac{p(y_t|x_t)p(x_t|y_{0:t-1},u_{0:t-1})}{\int_{x_t}p(y_t|x_t)p(x_t|y_{0:t-1},u_{0:t-1}) \,dx_t} .&lt;/script&gt;

  &lt;p&gt;The recursion is initialized with a prior distribution over the initial state \(p(x_0)\).&lt;/p&gt;

&lt;/div&gt;

&lt;p&gt;We will use the definition above as our starting point for the derivations of the particular nonlinear filtering methods. But first, it’s time to introduce the example, that will stay with us for the rest of this series.&lt;/p&gt;

&lt;h2 id=&quot;interactive-example-race-track&quot;&gt;Interactive example: Race track&lt;/h2&gt;

&lt;p&gt;The example that will accompany us for the rest of this series, consists of a race car that can drive around a race track. The race car can be controlled by the discrete actions of &lt;em&gt;forward&lt;/em&gt;, &lt;em&gt;backward&lt;/em&gt; and &lt;em&gt;stop&lt;/em&gt;. After the action is taken some process noise is added. Therefore, we won’t know exactly where the race car will be after we have taken this action. Inside the race course is a tree, which serves as a natural landmark. The race car has a distance meter on board, which obtains noisy measurements of the distance to this tree. The following graphic shows the race car in action. Please use your keyboard to set the input of the race car: &lt;strong&gt;A&lt;/strong&gt; (Backward), &lt;strong&gt;S&lt;/strong&gt; (Stop),  &lt;strong&gt;D&lt;/strong&gt; (Forward). Alternatively, you can use the buttons below.&lt;/p&gt;

&lt;svg id=&quot;race_track_intro&quot; style=&quot;width:100%&quot; onclick=&quot;on_click()&quot;&gt;&lt;/svg&gt;

&lt;script&gt;
	// defines scenes
	n_scene = load_race_track(&quot;race_track_intro&quot;,&quot;http://localhost:4000&quot;);
	n_scene.mode = 0;
	n_scene.filter = null;
	n_scene.dur=fast_dur;
	n_scene.auto_start = true;

	n_scene.loaded = function(){
		document.getElementById(&quot;race_track_intro_input&quot;).style.display=&quot;block&quot;;
	}.bind(n_scene)

	n_scene.step= function(){
		this.rc.step(this.rc.current_input);
	}.bind(n_scene);

	n_scene.key_down = function(key){
		input = key_to_input(key);
		if(input&gt;=0 &amp;&amp; input &lt;=2){
			this.rc.current_input = input;
		}
	}.bind(n_scene)


	n_scene.on_click = function(key){
		ani(this);
	}.bind(n_scene)
	scenes_name['race_track_intro'] = n_scene;
	scenes.push(n_scene);
&lt;/script&gt;

&lt;div id=&quot;race_track_intro_input&quot; class=&quot;button_set&quot;&gt;
&lt;div class=&quot;bt3 bt&quot; onclick=&quot;scenes_name['race_track_intro'].rc.current_input=0&quot;&gt;Backward&lt;/div&gt;
&lt;div class=&quot;bt3 bt&quot; onclick=&quot;scenes_name['race_track_intro'].rc.current_input=1&quot;&gt;No action&lt;/div&gt;
&lt;div class=&quot;bt3 bt&quot; onclick=&quot;scenes_name['race_track_intro'].rc.current_input=2&quot;&gt;Forward&lt;/div&gt;
 &lt;span class=&quot;stretch&quot;&gt;&lt;/span&gt;
&lt;/div&gt;

&lt;p&gt;Now that we have a good idea how the model will behave, you have the choice of either going directly to the first post about the grid-based filter or to learn more about the model of the dynamic \(p(x_{t+1}|x_{t}, u_{t})\) and observation \(p(y_t|x_t)\) of the example in the following section.&lt;/p&gt;

&lt;h2 id=&quot;simulation-model&quot;&gt;Simulation model&lt;/h2&gt;

&lt;p&gt;If you want to apply Bayes filters to real-life scenarios, a mathematical model of your system is needed. In general, you will have to learn it from data or derive it directly from the laws of physics. In our case we are lucky, because we are the designer of the real model and simply will use this exact model. Let’s start by taking a closer look at the system dynamic.&lt;/p&gt;

&lt;h1 id=&quot;system-dynamic&quot;&gt;System dynamic&lt;/h1&gt;

&lt;p&gt;The state \(x_t\) of the system is the current position on the race track. It is defined as the path length from the start to the current position following the race track. Having only the position without the velocity as a state representation is not very realistic, because it is not possible to model momentum. But for the sake of simplicity and visualisation, we will go without it. The input \(u_t\) is either \(-1\), \(0\) or \(1\) for backward, stop and forward.&lt;/p&gt;

&lt;p&gt;Our system dynamics are defined by a Gaussian distribution&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;p(x_{t+1}|x_t,u_t) = \mathcal{N}(x_{t+1}|\mu_s(x_t, u_t) ,\sigma_s^2(x_t) )&lt;/script&gt;

&lt;p&gt;with nonlinear mean  \(\mu_s(x_t, u_t)\) and variance \(\sigma_s^2(x_t)\). To obtain the mean of the next state \(x_{t+1}\) the input \(u_t\), which is weighted by \(v\) and \(b(\kappa)\), is simply added to the current state \(x_t\):&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\mu_s(x_t, u_t) = x_t + b(\kappa)vu_t.&lt;/script&gt;

&lt;p&gt;The factor \(v\) is the velocity of the car, we will call it the step size. Intuitively, by multiplying \(u_t\) with the step size \(v\) you map the input from action space to the race track space. The weighting factor \(b(\kappa) = e^{- c\kappa}\), with the hand-tweaked parameter \(c\), is used to model a more realistic driving behavior that depends on the curvature&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\kappa(x_t) ={\frac {|L_x'(x_t)L_y''(x_t)-L_y'(x_t)L_x''(x_t)|}{\left(L_x'^2(x_t)+L_y'^2(x_t)\right)^{\frac {3}{2}}}}&lt;/script&gt;

&lt;p&gt;of the track at the current position \(x_t\). The function \(L(x_t)\) maps the current position of the car \(x_t\) to \((x,y)\) coordinates&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;L(x_t) =  \begin{pmatrix}
    L_x(x_t) \\
    L_y(x_t) \\
    \end{pmatrix}.&lt;/script&gt;

&lt;p&gt;Intuitively, if we are in a sharp curve the curvature is low and we drive faster. If we are on a more straight part of the track, the curvature is high and we drive faster.&lt;/p&gt;

&lt;p&gt;The variance of the next state \(x_{t+1}\) is defined by&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\sigma_s^2(x_t, u_t) = \left[db(\kappa)v\right]^2.&lt;/script&gt;

&lt;p&gt;The variance depends mainly on the curvature \(\kappa\) at the current position. If we have a low curvature, the mean of the next step will be larger. But if we take a larger step it is natural to assume, that we have a higher variance. The hand-tweaked parameter \(d\) and the step size \(v\) are fixed for the whole environment. Please be aware, that the variance is not depending on the input \(u_t\) itself, but only on the step size \(v\).&lt;/p&gt;

&lt;p&gt;If you move your mouse or your finger over the race track below, you will notice a small blue strip outside the race track. This is the probability density of our dynamic model \(p(x_{t+1}|x_t,u_t)\). Therefore, it shows the distribution over the next state \(x_{t+1}\) given the current state \(x_t\) and action \(u_t\). If you want to check out the distribution for other inputs, you can use again your keyboard or the buttons below the race track.&lt;/p&gt;

&lt;svg id=&quot;race_track_sys_dist&quot; style=&quot;width:100%&quot; onclick=&quot;on_click()&quot;&gt;&lt;/svg&gt;

&lt;script&gt;


	// defines scenes
	n_scene = load_race_track(&quot;race_track_sys_dist&quot;, &quot;http://localhost:4000&quot;);
	n_scene.mode = 3;
	n_scene.me_show_system = true;

	n_scene.me_show_observation_transposed = false;
	n_scene.me_show_observation = false;
	n_scene.filter = null;
	n_scene.dur=slow_dur;
	n_scene.auto_start = false;
	n_scene.rc.current_input = 0;

	n_scene.loaded = function(){
		document.getElementById(&quot;race_track_sys_dist_input&quot;).style.display=&quot;block&quot;;
		this.nearest = []
		this.nearest.pos = this.rc.state;
	}.bind(n_scene)


	n_scene.mouse_touch = function(coords){
		var min_dist = 100.0;
		this.nearest = this.rt.get_nearest_pos(coords);
		if(this.nearest.distance &lt; min_dist){
			this.rt.update_car(this.nearest.pos,this.dur, 0);
			this.rt.update_strip(&quot;outer&quot;, get_system_dist_normalized(this.rc, this.rt, this.nearest.pos, this.rc.current_input));
			this.rt.show_strip(&quot;outer&quot;);	
		}else{
			this.rt.hide_strip(&quot;outer&quot;);
		}

	}.bind(n_scene)

	n_scene.update_strip_sys = function(){
		if(this.rt.is_strip_visible(&quot;outer&quot;)){
			this.rt.update_strip(&quot;outer&quot;, get_system_dist_normalized(this.rc, this.rt, this.nearest.pos, this.rc.current_input));
		}
	}.bind(n_scene)


	n_scene.key_down = function(key){
		input = key_to_input(key);
		if(input&gt;=0 &amp;&amp; input &lt;=2){
			this.rc.current_input = input;
			this.update_strip_sys();
		}
		
		
	}.bind(n_scene)
	
	scenes_name['race_track_sys_dist'] = n_scene;
	scenes.push(n_scene);
&lt;/script&gt;

&lt;div id=&quot;race_track_sys_dist_input&quot; class=&quot;button_set&quot;&gt;
&lt;div class=&quot;bt3 bt&quot; onclick=&quot;scenes_name['race_track_sys_dist'].rc.current_input=0;scenes_name['race_track_sys_dist'].update_strip_sys()&quot;&gt;Backward&lt;/div&gt;
&lt;div class=&quot;bt3 bt&quot; onclick=&quot;scenes_name['race_track_sys_dist'].rc.current_input=1;scenes_name['race_track_sys_dist'].update_strip_sys()&quot;&gt;No action&lt;/div&gt;
&lt;div class=&quot;bt3 bt&quot; onclick=&quot;scenes_name['race_track_sys_dist'].rc.current_input=2;scenes_name['race_track_sys_dist'].update_strip_sys()&quot;&gt;Forward&lt;/div&gt;
 &lt;span class=&quot;stretch&quot;&gt;&lt;/span&gt;
&lt;/div&gt;

&lt;h1 id=&quot;observation-model&quot;&gt;Observation model&lt;/h1&gt;

&lt;p&gt;The race car has a distance meter on board, which will provide us with noisy measurements of the distance to the tree inside the race track, where the position of the tree in \((x,y)\) coordinates is defined as \(T = (T_x, T_y)\). As in the model of the system dynamics, we will model the uncertainty of the measurement with a Gaussian distribution&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;p(y_t|x_t) = \mathcal{N}(y_t| \mu_o(x_t), \sigma_o^2(x_t))&lt;/script&gt;

&lt;p&gt;with nonlinear mean  \(\mu_o(x_t)\) and variance \(\sigma_o^2(x_t)\).&lt;/p&gt;

&lt;p&gt;The mean of our observation is the exact distance to the tree&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\mu_o(x_t) = d(L(x_t),T),&lt;/script&gt;

&lt;p&gt;where \(d(\cdot,\cdot)\) is defined as the Euclidean distance.&lt;/p&gt;

&lt;p&gt;The variance of our measuring device&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\sigma_o^2(x_t) = \left[ad(L(x_t),T)\right]^2&lt;/script&gt;

&lt;p&gt;depends on the distance as well. The farther we are away from the tree, the more noise will be present in the signal. The parameter \(a\) is again hand-tweaked and constant.&lt;/p&gt;

&lt;p&gt;By moving with your mouse or finger over the race track below you will notice two things. Again, there appears a strip, this time inside the race track and in a brownish color. Furthermore, you will notice another light green strip at the trunk of the tree. Both strips are showing parts of our observation model \(p(y_t|x_t)\). The light green strip shows the probability of observing a distance measurement at our current position. Not surprisingly, we find the maximum probability density at the true distance of tree. Like stated above, the variance is varying depending on the distance to the tree. 
The brownish strip answers another question: Given the true distance \(d\) at our current position, what is the probability of obtaining this measurement \(d\) from another position on the race track. It represents  \(p(y_t=d|x_t)\) and is, therefore, a function of the race track \(x\). Please be aware, that this is not a proper probability density, because it is not integrating to 1.&lt;/p&gt;

&lt;svg id=&quot;race_track_obs_dist&quot; style=&quot;width:100%&quot; onclick=&quot;on_click()&quot;&gt;&lt;/svg&gt;

&lt;script&gt;

	// defines scenes
	n_scene = load_race_track(&quot;race_track_obs_dist&quot;, &quot;http://localhost:4000&quot;);
	n_scene.mode = 3;
	n_scene.me_show_system = false;
	n_scene.me_show_observation_transposed = true;
	n_scene.me_show_observation = true;
	n_scene.filter = null;
	n_scene.dur=slow_dur;
	n_scene.auto_start = false;
	// define particle filter 


	n_scene.mouse_touch = function(coords){
		var min_dist = 100.0;
		this.nearest = this.rt.get_nearest_pos(coords);
		if(this.nearest.distance &lt; min_dist){
			this.rt.update_car(this.nearest.pos,this.dur, 0);
			this.rt.update_strip(&quot;inner&quot;, get_output_dist_normalized(this.rc, this.rt, this.nearest.pos));
			this.rt.show_strip(&quot;inner&quot;);

			this.rt.update_dist_strip(normalize_vector(this.rc.output_dist_array(this.rt.dist_strip_domain, this.nearest.pos, 0)), this.nearest.pos, 0);
			this.rt.show_dist_strip();

		}else{
			this.rt.hide_strip(&quot;inner&quot;);
			this.rt.hide_dist_strip();
		}

	}.bind(n_scene)

	scenes.push(n_scene);
&lt;/script&gt;

&lt;p&gt;Now that we know the inner workings of our model, we are well prepared to start the series with the &lt;a href=&quot;/jekyll/update/2018/10/29/nf-grid-based.html&quot;&gt;grid-based filter&lt;/a&gt;.&lt;/p&gt;

&lt;h1 id=&quot;acknowledgement&quot;&gt;Acknowledgement&lt;/h1&gt;

&lt;p&gt;The vector graphics of the &lt;a href=&quot;https://www.freepik.com/free-photos-vectors/car&quot;&gt;car&lt;/a&gt; were created by &lt;a href=&quot;https://www.freepik.com/&quot;&gt;Freepik&lt;/a&gt;.&lt;/p&gt;

&lt;script src=&quot;http://localhost:4000/assets/js/d3_graphical_model.js&quot;&gt;&lt;/script&gt;

&lt;script type=&quot;text/javascript&quot; src=&quot;http://localhost:4000/assets/js/svg_mathjax.js&quot;&gt;&lt;/script&gt;

&lt;script type=&quot;text/javascript&quot; src=&quot;https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_SVG&quot;&gt;&lt;/script&gt;

&lt;script type=&quot;text/x-mathjax-config&quot;&gt;

var mq = window.matchMedia( &quot;(max-width: 570px)&quot; );
if (!mq.matches) {
    MathJax.Hub.Config({
	  CommonHTML: { linebreaks: { automatic: true } },
	  &quot;HTML-CSS&quot;: { linebreaks: { automatic: true } },
	         SVG: { linebreaks: { automatic: true } }
	}); 
} 

&lt;/script&gt;

&lt;script type=&quot;text/javascript&quot;&gt;new Svg_MathJax().install();&lt;/script&gt;</content><author><name></name></author><summary type="html">This post will start a series of articles that will treat common nonlinear filtering methods that are based on the Bayes filter. The motivation is to provide an intuitive understanding of these methods by deriving them directly from the general Bayes filter. This derivation is done in steps, that are supposed to be as atomic as possible. Furthermore, each nonlinear filtering method will be shown in action by providing an interactive example to play around with. This series will require some basic knowledge in math. Especially in linear algebra and probability theory.</summary></entry><entry><title type="html">The score-Fisher-information-KL connection</title><link href="http://localhost:4000/jekyll/update/2018/10/17/fisher.html" rel="alternate" type="text/html" title="The score-Fisher-information-KL connection" /><published>2018-10-17T18:04:07+09:00</published><updated>2018-10-17T18:04:07+09:00</updated><id>http://localhost:4000/jekyll/update/2018/10/17/fisher</id><content type="html" xml:base="http://localhost:4000/jekyll/update/2018/10/17/fisher.html">&lt;p&gt;This article is a brief summary of some relationships between the log-likelihood, score, Kullback-Leibler divergence and Fisher information. No explanations, just pure math.
&lt;!--more--&gt;&lt;/p&gt;

&lt;script src=&quot;https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js?config=TeX-AMS-MML_SVG&quot; type=&quot;text/javascript&quot;&gt;&lt;/script&gt;

&lt;link href=&quot;https://fonts.googleapis.com/css?family=Roboto&quot; rel=&quot;stylesheet&quot; /&gt;

&lt;script type=&quot;text/javascript&quot;&gt;

function getPosition(el) {
  var xPos = 0;
  var yPos = 0;
 
  while (el) {
    if (el.tagName == &quot;BODY&quot;) {
      // deal with browser quirks with body/window/document and page scroll
      var xScroll = el.scrollLeft || document.documentElement.scrollLeft;
      var yScroll = el.scrollTop || document.documentElement.scrollTop;
 
      xPos += (el.offsetLeft - xScroll + el.clientLeft);
      yPos += (el.offsetTop - yScroll + el.clientTop);
    } else {
      // for all other non-BODY elements
      xPos += (el.offsetLeft - el.scrollLeft + el.clientLeft);
      yPos += (el.offsetTop - el.scrollTop + el.clientTop);
    }
 
    el = el.offsetParent;
  }
  return {
    x: xPos,
    y: yPos
  };
}

function switch_tab(button){

    var p1 = getPosition(button)

	// get parent elements
	var bar = button.parentElement;
	var con = bar.parentElement;
	var tab_id = con.getAttribute(&quot;class&quot;).split(&quot; &quot;)[1];


	var c = bar.childNodes;
	var ci = 0;

	for (var i=0;i&lt;c.length;i++){

		if(c[i].tagName==&quot;H3&quot;){	
			if (c[i]===button){
				break;
			}
			ci++;
		}
	}
	// get tab id
	cons = document.querySelectorAll('.tab-container.' + tab_id);;

	for (var j=0;j&lt;cons.length;j++){

		// change bar
		var bar_j = cons[j].querySelector(&quot;.tab-bar&quot;);
		var buttons = bar_j.childNodes;
		var bi = 0;

		for (var i=0;i&lt;buttons.length;i++){
			if(buttons[i].tagName==&quot;H3&quot;){	
				if (bi == ci){
					buttons[i].className = &quot;tab-button-selected&quot;;
				}else{
					buttons[i].className = &quot;tab-button&quot;;
				}
				bi++;
			}
		}

		var bi = 0;

		for (var i=0;i&lt;cons[j].childNodes.length;i++){
			if(cons[j].childNodes[i].tagName==&quot;DIV&quot; &amp;&amp; cons[j].childNodes[i].className!=&quot;tab-bar&quot;){	
				if (bi == ci){
					cons[j].childNodes[i].className = &quot;tab-visible&quot;;
				}else{
					cons[j].childNodes[i].className = &quot;tab-invisible&quot;;
				}
				bi++;
			}
		}

	}

	span_cons = document.querySelectorAll('.span-container.' + tab_id );
	
	for (var j=0;j&lt;span_cons.length;j++){
		var bi = 0;
		for (var i=0;i&lt;span_cons[j].childNodes.length;i++){
			if(span_cons[j].childNodes[i].tagName==&quot;SPAN&quot;){	
				if (bi == ci){
					span_cons[j].childNodes[i].className = &quot;span-visible&quot;;
				}else{
					span_cons[j].childNodes[i].className = &quot;span-invisible&quot;;
				}
				bi++;
			}
		}
	}

	var p2 = getPosition(button)
	window.scrollBy(0,-p1.y+p2.y+15);





}

&lt;/script&gt;

&lt;style type=&quot;text/css&quot;&gt;


div.tab-container {

	width:100%;

	margin-bottom:15px;

}


div.tab-bar {
	display:inline-block;
	height:30px;

	border-bottom:solid 1px #ebebeb;
	border-left:solid 1px #ebebeb;
	border-right:solid 1px #ebebeb;
	padding:0;
	padding-bottom:2px;
	vertical-align: middle;
}


h3.tab-button-selected {
	height:100%;
	display:inline-block;
	max-width: 200px;
	padding-left:15px;
	padding-right:15px;
	border-top: 2px solid  #c90606;
	color:#c90606;
	border-bottom: 2px transparent;
	text-align:center;
	padding: 0 25px;
    line-height:30px;
    font-size:90%;
    font-weight: 500;
    text-transform: uppercase;
}

h3.tab-button {

	height:20px;
	display:inline-block;
	max-width: 200px;
	padding-left:15px;
	padding-right:15px;
	border-bottom: 2px transparent;
	border-top: 2px transparent;
	color:#757575;
	text-align:center;
	padding: 0 25px;
	line-height:0px;
	font-size:90%;
	font-weight: 500;
	font-family: 'Roboto', sans-serif;
	text-transform: uppercase;
}


div.tab-visible {

	width:100%;
	display:block;
	overflow: auto;
	background-color: #f7f7f7;
	border:solid 1px #ebebeb;

}

div.tab-invisible {

	width:100%;
	display:none;
	overflow: auto;
}

span.span-visible {
	display:inline-block;
}

span.span-invisible {
	display:none;
}

&lt;/style&gt;

&lt;h2 id=&quot;log-likelihood&quot;&gt;Log-likelihood&lt;/h2&gt;
&lt;p&gt;The log-likelihood is defined the logarithm of the likelihood&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\ell(x;\theta')  =  \log p(x|\theta').&lt;/script&gt;

&lt;p&gt;Let’s perform a &lt;strong&gt;Taylor approximation&lt;/strong&gt; of the log-likelihood \(\log p(x|\theta’)\) around the current estimate \(\theta\):&lt;/p&gt;

&lt;div class=&quot;tab-container scalar-vector&quot;&gt;&lt;div class=&quot;tab-visible&quot;&gt;
	$$\begin{align*}
 \log p(x|\theta') =&amp;amp; \log p(x|\theta')|_{\theta' =  \theta} +  \sum_i \left. \frac{\partial \log p(x|\theta')}{\partial \theta'_i} \right| _{\theta' = \theta}   (\theta'_i - \theta_i) \\ &amp;amp;+ \frac{1}{2}\sum_i\sum_j \left. \frac{\partial^2 \log p(x|\theta')}{\partial \theta'_i\partial \theta'_j}\right| _{\theta' = \theta}   (\theta'_i - \theta_i)(\theta'_j - \theta_j) + ...
\end{align*}$$
&lt;/div&gt;&lt;div class=&quot;tab-invisible&quot;&gt;
	$$\begin{align*}
\log p(x|\theta') =&amp;amp; \log p(x|\theta')|_{\theta' = \theta} + \left. \nabla_{\theta'} \log p(x|\theta')^T\right| _{\theta' = \theta} (\theta' - \theta) \\ &amp;amp;+ \frac{1}{2}\left. (\theta' - \theta)^T\nabla^2_{\theta'} \log p(x|\theta')\right| _{\theta' = \theta}(\theta' - \theta) + ...
\end{align*}$$
&lt;/div&gt;&lt;div class=&quot;tab-bar&quot;&gt;&lt;h3 class=&quot;tab-button-selected&quot; onclick=&quot;switch_tab(this)&quot;&gt;Scalar&lt;/h3&gt;&lt;h3 class=&quot;tab-button&quot; onclick=&quot;switch_tab(this)&quot;&gt;Vector&lt;/h3&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;The &lt;strong&gt;linear&lt;/strong&gt; term &lt;span class=&quot;span-container scalar-vector&quot;&gt;&lt;span class=&quot;span-visible&quot;&gt;\(\frac{\partial}{\partial \theta’_i} \log p(x|\theta’)\)&lt;/span&gt;&lt;span class=&quot;span-invisible&quot;&gt;\(\nabla_{\theta’} \log p(x|\theta’)\)&lt;/span&gt;&lt;/span&gt; in this decomposition can be written as&lt;/p&gt;

&lt;div class=&quot;tab-container scalar-vector&quot;&gt;&lt;div class=&quot;tab-visible&quot;&gt;
$$  \frac{\partial}{\partial \theta'_i} \log p(x|\theta') = \frac{1}{p(x|\theta')} \frac{\partial}{\partial \theta'_i} p(x|\theta') $$
&lt;/div&gt;&lt;div class=&quot;tab-invisible&quot;&gt;
$$ \nabla_{\theta'} \log p(x|\theta') = \frac{1}{p(x|\theta')}\nabla_{\theta'} p(x|\theta')  $$
&lt;/div&gt;&lt;div class=&quot;tab-bar&quot;&gt;&lt;h3 class=&quot;tab-button-selected&quot; onclick=&quot;switch_tab(this)&quot;&gt;Scalar&lt;/h3&gt;&lt;h3 class=&quot;tab-button&quot; onclick=&quot;switch_tab(this)&quot;&gt;Vector&lt;/h3&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;by using the &lt;em&gt;log derivative trick&lt;/em&gt;.&lt;/p&gt;

&lt;p&gt;Evaluated at \(  \theta’ = \theta \) you receive&lt;/p&gt;

&lt;div class=&quot;tab-container scalar-vector&quot;&gt;&lt;div class=&quot;tab-visible&quot;&gt;
$$ \left. \frac{\partial}{\partial \theta'_i} \log p(x|\theta') \right|_{\theta' = \theta} = \frac{1}{p(x|\theta)} \frac{\partial}{\partial \theta_i} p(x|\theta). $$
&lt;/div&gt;&lt;div class=&quot;tab-invisible&quot;&gt;
$$ \left. \nabla_{\theta'} \log p(x|\theta') \right|_{\theta' = \theta} = \frac{1}{p(x|\theta)}\nabla_{\theta} p(x|\theta).  $$
&lt;/div&gt;&lt;div class=&quot;tab-bar&quot;&gt;&lt;h3 class=&quot;tab-button-selected&quot; onclick=&quot;switch_tab(this)&quot;&gt;Scalar&lt;/h3&gt;&lt;h3 class=&quot;tab-button&quot; onclick=&quot;switch_tab(this)&quot;&gt;Vector&lt;/h3&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;The &lt;strong&gt;quadratic&lt;/strong&gt; term of the decomposition  &lt;span class=&quot;span-container scalar-vector&quot;&gt;&lt;span class=&quot;span-visible&quot;&gt;
\(\frac{\partial^2 \log p(x|\theta’)}{\partial \theta’_i\partial \theta’_j}\)
&lt;/span&gt;&lt;span class=&quot;span-invisible&quot;&gt;
\(\nabla^2_{\theta’} \log p(x|\theta’)\)
&lt;/span&gt;&lt;/span&gt; 
can be written as&lt;/p&gt;

&lt;div class=&quot;tab-container scalar-vector&quot;&gt;&lt;div class=&quot;tab-visible&quot;&gt;
$$
\begin{align*}
\frac{\partial^2 \log p(x|\theta')}{\partial \theta'_\partial \theta'_j} =&amp;amp; \frac{\partial }{\partial \theta'_j} \left( \frac{\partial}{\partial \theta'_i} \log p(x|\theta')\right) \\
=&amp;amp; \frac{\partial }{\partial \theta'_j} \left( \frac{1}{p(x|\theta')} \frac{\partial}{\partial \theta'_i} p(x|\theta')\right) \\
=&amp;amp; \frac{\partial }{\partial \theta'_j} \left( \frac{1}{p(x|\theta')}\right) \frac{\partial}{\partial \theta'_i} p(x|\theta') +    \frac{1}{p(x|\theta')} \frac{\partial }{\partial \theta'_j} \left(\frac{\partial}{\partial \theta'_i} p(x|\theta')\right)\\
=&amp;amp; \frac{\partial }{\partial \theta'_j} \left( \frac{1}{p(x|\theta')}\right) \frac{\partial}{\partial \theta'_i} p(x|\theta') +    \frac{1}{p(x|\theta')} \frac{\partial^2 p(x|\theta')}{\partial \theta'_\partial \theta'_j}  \\
=&amp;amp; - \frac{1}{p(x|\theta')^2} \frac{\partial}{\partial \theta'_j} p(x|\theta') \frac{\partial}{\partial \theta'_i} p(x|\theta') +    \frac{1}{p(x|\theta')} \frac{\partial^2 p(x|\theta')}{\partial \theta'_\partial \theta'_j}  \\
=&amp;amp; - \frac{\partial}{\partial \theta'_j} \log p(x|\theta') \frac{\partial}{\partial \theta'_i} \log p(x|\theta') +    \frac{1}{p(x|\theta')} \frac{\partial^2 p(x|\theta')}{\partial \theta'_\partial \theta'_j}  
\end{align*}
$$
&lt;/div&gt;&lt;div class=&quot;tab-invisible&quot;&gt;
$$
\begin{align*}
\nabla^2_{\theta'} \log p(x|\theta') =&amp;amp; \nabla_{\theta'} \nabla_{\theta'}^T \log p(x|\theta') \\
=&amp;amp; \nabla_{\theta'} \left(\frac{1}{p(x|\theta')}\nabla_{\theta'}^T p(x|\theta')\right) \\
=&amp;amp; \nabla_{\theta'} p(x|\theta')  \nabla_{\theta'}^T \left(\frac{1}{p(x|\theta')}\right) +  \frac{1}{p(x|\theta')}\nabla_{\theta'}^T\nabla_{\theta'} p(x|\theta') \\
=&amp;amp;- \frac{1}{p(x|\theta')^2} \nabla_{\theta'} p(x|\theta') \nabla_{\theta'} p(x|\theta') ^T  +  \frac{1}{p(x|\theta')}\nabla_{\theta'}^2 p(x|\theta') \\
=&amp;amp;- \nabla_{\theta'} \log p(x|\theta') \nabla_{\theta'} \log p(x|\theta') ^T  +  \frac{1}{p(x|\theta')}\nabla_{\theta'}^2 p(x|\theta')
\end{align*}
$$
&lt;/div&gt;&lt;div class=&quot;tab-bar&quot;&gt;&lt;h3 class=&quot;tab-button-selected&quot; onclick=&quot;switch_tab(this)&quot;&gt;Scalar&lt;/h3&gt;&lt;h3 class=&quot;tab-button&quot; onclick=&quot;switch_tab(this)&quot;&gt;Vector&lt;/h3&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Evaluated at \(  \theta’ = \theta \) you receive&lt;/p&gt;

&lt;div class=&quot;tab-container scalar-vector&quot;&gt;&lt;div class=&quot;tab-visible&quot;&gt;
$$
\begin{align*}
\left. \frac{\partial^2 \log p(x|\theta')}{\partial \theta'_\partial \theta'_j}\right|_{\theta' = \theta} =&amp;amp; - \frac{\partial}{\partial \theta_j} \log p(x|\theta) \frac{\partial}{\partial \theta_i} \log p(x|\theta) +    \frac{1}{p(x|\theta)} \frac{\partial^2 p(x|\theta)}{\partial \theta_\partial \theta_j}  
\end{align*}.
$$
&lt;/div&gt;&lt;div class=&quot;tab-invisible&quot;&gt;
$$
\begin{align*}
\left. \nabla^2_{\theta'} \log p(x|\theta')\right|_{\theta' = \theta} =&amp;amp;- \nabla_{\theta} \log p(x|\theta) \nabla_{\theta} \log p(x|\theta) ^T  +  \frac{1}{p(x|\theta)}\nabla_{\theta}^2 p(x|\theta)
\end{align*}.
$$
&lt;/div&gt;&lt;div class=&quot;tab-bar&quot;&gt;&lt;h3 class=&quot;tab-button-selected&quot; onclick=&quot;switch_tab(this)&quot;&gt;Scalar&lt;/h3&gt;&lt;h3 class=&quot;tab-button&quot; onclick=&quot;switch_tab(this)&quot;&gt;Vector&lt;/h3&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Finally, you can express the &lt;strong&gt;Taylor approximation&lt;/strong&gt; as&lt;/p&gt;

&lt;div class=&quot;tab-container scalar-vector&quot;&gt;&lt;div class=&quot;tab-visible&quot;&gt;
	$$\begin{align*}
 \log p(x|\theta') =&amp;amp; \log p(x|\theta) +  \sum_i \frac{1}{p(x|\theta)} \frac{\partial}{\partial \theta_i} p(x|\theta)   (\theta'_i - \theta_i) \\ &amp;amp;+ \frac{1}{2} \sum_i\sum_j \left(- \nabla_{\theta} \log p(x|\theta) \nabla_{\theta} \log p(x|\theta) ^T  +  \frac{1}{p(x|\theta)}\nabla_{\theta}^2 p(x|\theta)\right) (\theta'_i - \theta_i)(\theta'_j - \theta_j) + ...
\end{align*}$$
&lt;/div&gt;&lt;div class=&quot;tab-invisible&quot;&gt;
	$$\begin{align*}
\log p(x|\theta') =&amp;amp; \log p(x|\theta) + \left. \nabla_{\theta'} \log p(x|\theta')^T\right| _{\theta' = \theta} (\theta' - \theta) \\ &amp;amp;+ \left. \frac{1}{2} (\theta' - \theta)^T\nabla^2_{\theta'} \log p(x|\theta')\right| _{\theta' = \theta}(\theta' - \theta) + ...
\end{align*}$$
&lt;/div&gt;&lt;div class=&quot;tab-bar&quot;&gt;&lt;h3 class=&quot;tab-button-selected&quot; onclick=&quot;switch_tab(this)&quot;&gt;Scalar&lt;/h3&gt;&lt;h3 class=&quot;tab-button&quot; onclick=&quot;switch_tab(this)&quot;&gt;Vector&lt;/h3&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h1 id=&quot;mean&quot;&gt;Mean&lt;/h1&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{align*} 
 \mathbb{E}_{p(x|\theta^*)}[\log p(x|\theta')] &amp;=  \int \limits_{-\infty}^{\infty} p(x|\theta^*) \log p(x|\theta')dx \\
&amp;= -H(\theta^*,\theta') \\
 \end{align*} %]]&gt;&lt;/script&gt;

&lt;h1 id=&quot;variance&quot;&gt;Variance&lt;/h1&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{align*} \text{Var}(\log p(x|\theta')) &amp;=  \mathbb{E}_{p(x|\theta^*)}\left[\log p(x|\theta')-\mathbb{E}_{p(x|\theta^*)}[\log p(x|\theta')])^2\right] \\
&amp;=  \mathbb{E}_{p(x|\theta^*)}\left[(\log p(x|\theta'))^2\right]-\mathbb{E}_{p(x|\theta^*)}[\log p(x|\theta')]^2 \\
&amp;=  \mathbb{E}_{p(x|\theta^*)}\left[(\log p(x|\theta'))^2\right]+H(\theta^*,\theta')^2 \\

\end{align*} %]]&gt;&lt;/script&gt;

&lt;h2 id=&quot;score&quot;&gt;Score&lt;/h2&gt;

&lt;p&gt;The score is defined as the derivative of the log-likelihood&lt;/p&gt;

&lt;div class=&quot;tab-container scalar-vector&quot;&gt;&lt;div class=&quot;tab-visible&quot;&gt;
$$ V_i(x;\theta')  =  \frac{\partial}{\partial \theta'_i} \log p(x|\theta') $$
&lt;/div&gt;&lt;div class=&quot;tab-invisible&quot;&gt;
$$ V(x;\theta')  =  \nabla_{\theta'} \log p(x|\theta') $$
&lt;/div&gt;&lt;div class=&quot;tab-bar&quot;&gt;&lt;h3 class=&quot;tab-button-selected&quot; onclick=&quot;switch_tab(this)&quot;&gt;Scalar&lt;/h3&gt;&lt;h3 class=&quot;tab-button&quot; onclick=&quot;switch_tab(this)&quot;&gt;Vector&lt;/h3&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h1 id=&quot;mean-1&quot;&gt;Mean&lt;/h1&gt;

&lt;div class=&quot;tab-container scalar-vector&quot;&gt;&lt;div class=&quot;tab-visible&quot;&gt;
$$ \mathbb{E}_{p(x|\theta^*)}\left[\frac{\partial}{\partial \theta'_i} \log p(x|\theta')\right] =  \int \limits_{-\infty}^{\infty} p(x|\theta^*) \frac{\partial}{\partial \theta'_i} \log p(x|\theta')dx$$

&lt;/div&gt;&lt;div class=&quot;tab-invisible&quot;&gt;
$$ \mathbb{E}_{p(x|\theta^*)}\left[\nabla_{\theta'} \log p(x|\theta')\right] =  \int \limits_{-\infty}^{\infty} p(x|\theta^*) \nabla_{\theta'} \log p(x|\theta')dx$$

&lt;/div&gt;&lt;div class=&quot;tab-bar&quot;&gt;&lt;h3 class=&quot;tab-button-selected&quot; onclick=&quot;switch_tab(this)&quot;&gt;Scalar&lt;/h3&gt;&lt;h3 class=&quot;tab-button&quot; onclick=&quot;switch_tab(this)&quot;&gt;Vector&lt;/h3&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h1 id=&quot;variance-1&quot;&gt;Variance&lt;/h1&gt;

&lt;div class=&quot;tab-container scalar-vector&quot;&gt;&lt;div class=&quot;tab-visible&quot;&gt;
\begin{align*} \text{Var}\left(\frac{\partial}{\partial \theta'_i} \log p(x|\theta')\right) &amp;amp;=  \mathbb{E}_{p(x|\theta^*)}\left[\left(\frac{\partial}{\partial \theta'_i} \log p(x|\theta')-\mathbb{E}_{p(x|\theta^*)}\left[\frac{\partial}{\partial \theta'_i} \log p(x|\theta')\right]\right)^2\right] \\
&amp;amp;=  \mathbb{E}_{p(x|\theta^*)}\left[\frac{\partial}{\partial \theta'_i} \log p(x|\theta')\frac{\partial}{\partial \theta'_i} \log p(x|\theta')\right] +  \mathbb{E}_{p(x|\theta^*)}\left[\frac{\partial}{\partial \theta'_i} \log p(x|\theta')\right]^2 \\
\end{align*} 

&lt;/div&gt;&lt;div class=&quot;tab-invisible&quot;&gt;
\begin{align*} \text{Var}\left(\nabla_{\theta'} \log p(x|\theta')\right) &amp;amp;=  \mathbb{E}_{p(x|\theta^*)}\left[\left(\nabla_{\theta'}\log p(x|\theta')-\mathbb{E}_{p(x|\theta^*)}\left[\nabla_{\theta'} \log p(x|\theta')\right]\right)\left(\nabla_{\theta'}\log p(x|\theta')-\mathbb{E}_{p(x|\theta^*)}\left[\nabla_{\theta'} \log p(x|\theta')\right]\right)^T\right] \\
&amp;amp;=  \mathbb{E}_{p(x|\theta^*)}\left[\nabla_{\theta'} \log p(x|\theta')\nabla_{\theta'} \log p(x|\theta')^T\right] +  \mathbb{E}_{p(x|\theta^*)}\left[\nabla_{\theta'} \log p(x|\theta')\right]\mathbb{E}_{p(x|\theta^*)}\left[\nabla_{\theta'} \log p(x|\theta')\right]^T \\
\end{align*} 
&lt;/div&gt;&lt;div class=&quot;tab-bar&quot;&gt;&lt;h3 class=&quot;tab-button-selected&quot; onclick=&quot;switch_tab(this)&quot;&gt;Scalar&lt;/h3&gt;&lt;h3 class=&quot;tab-button&quot; onclick=&quot;switch_tab(this)&quot;&gt;Vector&lt;/h3&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h2 id=&quot;kullback-leibler-divergence&quot;&gt;Kullback-Leibler divergence&lt;/h2&gt;

&lt;p&gt;The Kullback-Leibler divergence is defined as&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;D_\textrm{KL}(\theta||\theta') = \int \limits_{-\infty}^{\infty} p(x|\theta) \log \frac{p(x|\theta)}{p(x|\theta')} dx .&lt;/script&gt;

&lt;p&gt;Let’s perform a &lt;strong&gt;Taylor approximation&lt;/strong&gt; around the current estimate \(\theta\):&lt;/p&gt;

&lt;div class=&quot;tab-container scalar-vector&quot;&gt;&lt;div class=&quot;tab-visible&quot;&gt;
$$
\begin{align*}
D_\textrm{KL}(\theta||\theta') =&amp;amp; D_\textrm{KL}(\theta||\theta')|_{\theta' = \theta} +  \sum_i \left.\frac{\partial D_\textrm{KL}(\theta||\theta')}{\partial \theta'_i}\right|_{\theta' = \theta}   (\theta'_i - \theta_i)  \\ &amp;amp;+  \frac{1}{2}\sum_i\sum_j \left.\frac{\partial^2 D_\textrm{KL}(\theta||\theta')}{\partial \theta'_i\partial \theta'_j}\right|_{\theta' = \theta}  (\theta'_i - \theta_i) (\theta'_j - \theta_j) + ...
\end{align*}
$$
&lt;/div&gt;&lt;div class=&quot;tab-invisible&quot;&gt;
$$
\begin{align*}
D_\textrm{KL}(\theta||\theta') =&amp;amp; D_\textrm{KL}(\theta||\theta')|_{\theta' = \theta} + \left. \nabla_{\theta'}D_\textrm{KL}(\theta||\theta')^T\right|_{\theta' = \theta}(\theta' - \theta) \\
&amp;amp; +  \frac{1}{2}\left. (\theta' - \theta)^T\nabla^2_{\theta'}D_\textrm{KL}(\theta||\theta')\right|_{\theta' = \theta}(\theta' - \theta) + ...
\end{align*}
$$
&lt;/div&gt;&lt;div class=&quot;tab-bar&quot;&gt;&lt;h3 class=&quot;tab-button-selected&quot; onclick=&quot;switch_tab(this)&quot;&gt;Scalar&lt;/h3&gt;&lt;h3 class=&quot;tab-button&quot; onclick=&quot;switch_tab(this)&quot;&gt;Vector&lt;/h3&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;The &lt;strong&gt;constant&lt;/strong&gt; term can be written as&lt;/p&gt;

&lt;div class=&quot;tab-container scalar-vector&quot;&gt;&lt;div class=&quot;tab-visible&quot;&gt;
$$
\begin{align*}
D_\textrm{KL}(\theta||\theta')|_{\theta' = \theta} =&amp;amp; 0.
\end{align*}
$$
&lt;/div&gt;&lt;div class=&quot;tab-invisible&quot;&gt;
$$
\begin{align*}
D_\textrm{KL}(\theta||\theta')|_{\theta' = \theta} =&amp;amp;  0.
\end{align*}
$$
&lt;/div&gt;&lt;div class=&quot;tab-bar&quot;&gt;&lt;h3 class=&quot;tab-button-selected&quot; onclick=&quot;switch_tab(this)&quot;&gt;Scalar&lt;/h3&gt;&lt;h3 class=&quot;tab-button&quot; onclick=&quot;switch_tab(this)&quot;&gt;Vector&lt;/h3&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;The &lt;strong&gt;linear&lt;/strong&gt; term &lt;span class=&quot;span-container scalar-vector&quot;&gt;&lt;span class=&quot;span-visible&quot;&gt;
\(\frac{\partial D_\textrm{KL}(\theta||\theta’)}{\partial \theta’_i}\)
&lt;/span&gt;&lt;span class=&quot;span-invisible&quot;&gt;
\(\nabla_{\theta’}D_\textrm{KL}(\theta||\theta’)\)
&lt;/span&gt;&lt;/span&gt; in this decomposition can be written as&lt;/p&gt;

&lt;div class=&quot;tab-container scalar-vector&quot;&gt;&lt;div class=&quot;tab-visible&quot;&gt;
$$
\begin{align*}
\frac{\partial D_\textrm{KL}(\theta||\theta')}{\partial \theta'_i} =&amp;amp; \frac{\partial}{\partial \theta'_i}\left(\int \limits_{-\infty}^{\infty} p(x|\theta) \log p(x|\theta) dx -\int \limits_{-\infty}^{\infty} p(x|\theta) \log p(x|\theta') dx\right) \\
=&amp;amp; -\int \limits_{-\infty}^{\infty} p(x|\theta) \frac{\partial}{\partial \theta'_i}\log p(x|\theta') dx\\
=&amp;amp;  -\int \limits_{-\infty}^{\infty} p(x|\theta)\frac{1}{p(x|\theta')}\frac{\partial}{\partial \theta'_i} p(x|\theta') dx \\
=&amp;amp; - \mathbb{E}_{p(x|\theta)}\left[\frac{\partial}{\partial \theta'_i} \log p(x|\theta')\right]\\
=&amp;amp; - \mathbb{E}_{p(x|\theta)}\left[\frac{1}{p(x|\theta')}\frac{\partial}{\partial \theta'_i} p(x|\theta')\right].
\end{align*}
$$
&lt;/div&gt;&lt;div class=&quot;tab-invisible&quot;&gt;
$$
\begin{align*}
\nabla_{\theta'}D_\textrm{KL}(\theta||\theta') =&amp;amp;  \nabla_{\theta'}\left(\int \limits_{-\infty}^{\infty} p(x|\theta) \log p(x|\theta) dx -\int \limits_{-\infty}^{\infty} p(x|\theta) \log p(x|\theta') dx\right) \\
=&amp;amp;  -\int \limits_{-\infty}^{\infty} p(x|\theta)\nabla_{\theta'} \log p(x|\theta') dx \\
=&amp;amp;  -\int \limits_{-\infty}^{\infty} p(x|\theta)\frac{1}{p(x|\theta')}\nabla_{\theta'} p(x|\theta') dx \\
=&amp;amp; - \mathbb{E}_{p(x|\theta)}\left[\nabla_{\theta'} \log p(x|\theta')\right]\\
=&amp;amp; - \mathbb{E}_{p(x|\theta)}\left[\frac{1}{p(x|\theta')}\nabla_{\theta'} p(x|\theta')\right].
\end{align*}
$$
&lt;/div&gt;&lt;div class=&quot;tab-bar&quot;&gt;&lt;h3 class=&quot;tab-button-selected&quot; onclick=&quot;switch_tab(this)&quot;&gt;Scalar&lt;/h3&gt;&lt;h3 class=&quot;tab-button&quot; onclick=&quot;switch_tab(this)&quot;&gt;Vector&lt;/h3&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Evaluated at \(  \theta’ = \theta \) you receive&lt;/p&gt;

&lt;div class=&quot;tab-container scalar-vector&quot;&gt;&lt;div class=&quot;tab-visible&quot;&gt;
$$
\begin{align*}
\left. \frac{\partial D_\textrm{KL}(\theta||\theta')}{\partial \theta'_i} \right|_{\theta' = \theta} =&amp;amp; - \mathbb{E}_{p(x|\theta)}\left[\frac{1}{p(x|\theta)}\frac{\partial}{\partial \theta_i} p(x|\theta)\right] \\
=&amp;amp; \int \limits_{-\infty}^{\infty} p(x|\theta) \frac{1}{p(x|\theta)}\frac{\partial}{\partial \theta_i}p(x|\theta) dx \\
=&amp;amp; \int \limits_{-\infty}^{\infty} \frac{\partial}{\partial \theta_i} p(x|\theta) dx \\
=&amp;amp;  \frac{\partial}{\partial \theta_i}\int \limits_{-\infty}^{\infty} p(x|\theta) dx \\
=&amp;amp;  \frac{\partial}{\partial \theta_i} 1 \\
=&amp;amp; 0 
\end{align*}
$$
&lt;/div&gt;&lt;div class=&quot;tab-invisible&quot;&gt;
$$
\begin{align*}
\left. \nabla_{\theta'}D_\textrm{KL}(\theta||\theta') \right|_{\theta' = \theta} =&amp;amp;   - \mathbb{E}_{p(x|\theta)}\left[\frac{1}{p(x|\theta)}\nabla_{\theta} p(x|\theta)\right] \\
=&amp;amp; \int \limits_{-\infty}^{\infty} p(x|\theta) \frac{1}{p(x|\theta)}\nabla_{\theta} p(x|\theta) dx \\
=&amp;amp; \int \limits_{-\infty}^{\infty} \nabla_{\theta} p(x|\theta) dx \\
=&amp;amp;  \nabla_{\theta}\int \limits_{-\infty}^{\infty} p(x|\theta) dx \\
=&amp;amp;  \nabla_{\theta} 1 \\
=&amp;amp; 0 
\end{align*}
$$
&lt;/div&gt;&lt;div class=&quot;tab-bar&quot;&gt;&lt;h3 class=&quot;tab-button-selected&quot; onclick=&quot;switch_tab(this)&quot;&gt;Scalar&lt;/h3&gt;&lt;h3 class=&quot;tab-button&quot; onclick=&quot;switch_tab(this)&quot;&gt;Vector&lt;/h3&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;The &lt;strong&gt;quadratic&lt;/strong&gt; term &lt;span class=&quot;span-container scalar-vector&quot;&gt;&lt;span class=&quot;span-visible&quot;&gt;
\(\frac{\partial^2 D_\textrm{KL}(\theta||\theta’)}{\partial \theta’_i\partial \theta’_j}\)
&lt;/span&gt;&lt;span class=&quot;span-invisible&quot;&gt;
\(\nabla^2_ {\theta’}D_\textrm{KL}(\theta’||\theta’)\)
&lt;/span&gt;&lt;/span&gt; in this decomposition can be written as&lt;/p&gt;

&lt;div class=&quot;tab-container scalar-vector&quot;&gt;&lt;div class=&quot;tab-visible&quot;&gt;
$$
\begin{align*}
\frac{\partial^2 D_\textrm{KL}(\theta||\theta')}{\partial \theta'_i\partial \theta'_j} =&amp;amp; \frac{\partial }{\partial \theta'_j} \left( \frac{\partial}{\partial \theta'_i} D_\textrm{KL}(\theta||\theta')\right) \\
=&amp;amp; -\frac{\partial }{\partial \theta'_j} \left( \int \limits_{-\infty}^{\infty} p(x|\theta)\frac{\partial}{\partial \theta'_i} \log p(x|\theta') dx \right) \\
=&amp;amp; - \int \limits_{-\infty}^{\infty} p(x|\theta)\frac{\partial^2  \log p(x|\theta')}{\partial \theta'_i  \partial \theta'_j}   dx \\
=&amp;amp; -\mathbb{E}_{p(x|\theta)}\left[\frac{\partial^2  \log p(x|\theta')}{\partial \theta'_i  \partial \theta'_j}\right]
\end{align*}$$
&lt;/div&gt;&lt;div class=&quot;tab-invisible&quot;&gt;
$$
\begin{align*}
\nabla^2_{\theta'}D_\textrm{KL}(\theta||\theta') =&amp;amp; \nabla_{\theta'} \nabla_{\theta'}^T D_\textrm{KL}(\theta||\theta') \\
=&amp;amp; -\nabla_{\theta'} \left( \int \limits_{-\infty}^{\infty} p(x|\theta)\nabla_{\theta'}^T \log p(x|\theta') dx \right) \\
=&amp;amp; - \int \limits_{-\infty}^{\infty} p(x|\theta)\nabla_{\theta'}^2 \log p(x|\theta') dx \\
=&amp;amp; -\mathbb{E}_{p(x|\theta)}\left[\nabla_{\theta'}^2 \log p(x|\theta')\right]\\
\end{align*}$$
&lt;/div&gt;&lt;div class=&quot;tab-bar&quot;&gt;&lt;h3 class=&quot;tab-button-selected&quot; onclick=&quot;switch_tab(this)&quot;&gt;Scalar&lt;/h3&gt;&lt;h3 class=&quot;tab-button&quot; onclick=&quot;switch_tab(this)&quot;&gt;Vector&lt;/h3&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Evaluated at \(  \theta’ = \theta \) you receive&lt;/p&gt;

&lt;div class=&quot;tab-container scalar-vector&quot;&gt;&lt;div class=&quot;tab-visible&quot;&gt;
$$
\begin{align*}
\left. \frac{\partial^2 D_\textrm{KL}(\theta||\theta')}{\partial \theta'_i\partial \theta'_j} \right|_{\theta' = \theta} =&amp;amp;  -\mathbb{E}_{p(x|\theta)}\left[\frac{\partial^2  \log p(x|\theta)}{\partial \theta_i  \partial \theta_j}\right]
\end{align*}$$
&lt;/div&gt;&lt;div class=&quot;tab-invisible&quot;&gt;
$$
\begin{align*}
\left. \nabla^2_{\theta'}D_\textrm{KL}(\theta||\theta') \right|_{\theta' = \theta} =&amp;amp;  -\mathbb{E}_{p(x|\theta)}\left[\nabla_{\theta}^2 \log p(x|\theta)\right]\\
\end{align*}$$
&lt;/div&gt;&lt;div class=&quot;tab-bar&quot;&gt;&lt;h3 class=&quot;tab-button-selected&quot; onclick=&quot;switch_tab(this)&quot;&gt;Scalar&lt;/h3&gt;&lt;h3 class=&quot;tab-button&quot; onclick=&quot;switch_tab(this)&quot;&gt;Vector&lt;/h3&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Finally, you can express the &lt;strong&gt;Taylor approximation&lt;/strong&gt; as&lt;/p&gt;

&lt;div class=&quot;tab-container scalar-vector&quot;&gt;&lt;div class=&quot;tab-visible&quot;&gt;
$$
\begin{align*}
D_\textrm{KL}(\theta||\theta') =&amp;amp; -\frac{1}{2}\sum_i\sum_j  \mathbb{E}_{p(x|\theta)}\left[\frac{\partial^2  \log p(x|\theta)}{\partial \theta_i  \partial \theta_j} \right]  (\theta'_i - \theta_i) (\theta'_j - \theta_j) + ...
\end{align*}
$$
&lt;/div&gt;&lt;div class=&quot;tab-invisible&quot;&gt;
$$
\begin{align*}
D_\textrm{KL}(\theta||\theta') =&amp;amp; -\frac{1}{2} (\theta' - \theta)^T\mathbb{E}_{p(x|\theta)}\left[\nabla_{\theta}^2 \log p(x|\theta)\right](\theta' - \theta) + ...
\end{align*}
$$
&lt;/div&gt;&lt;div class=&quot;tab-bar&quot;&gt;&lt;h3 class=&quot;tab-button-selected&quot; onclick=&quot;switch_tab(this)&quot;&gt;Scalar&lt;/h3&gt;&lt;h3 class=&quot;tab-button&quot; onclick=&quot;switch_tab(this)&quot;&gt;Vector&lt;/h3&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h2 id=&quot;cross-entropy&quot;&gt;Cross entropy&lt;/h2&gt;

&lt;p&gt;The cross entropy is defined as&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;H(\theta,\theta') = -\int \limits_{-\infty}^{\infty} p(x|\theta) \log p(x|\theta') dx .&lt;/script&gt;

&lt;p&gt;The cross entropy and the Kullback-Leibler differ only by the constant entropy \(H(\theta\). Therefore, the linear and quadratic terms of those are the same.&lt;/p&gt;

&lt;h2 id=&quot;fisher-information&quot;&gt;Fisher Information&lt;/h2&gt;
&lt;h1 id=&quot;the-fisher-definition-can-be-defined-as-&quot;&gt;The fisher definition can be defined as …&lt;/h1&gt;

&lt;h1 id=&quot;-expectation-of-the-squared-score&quot;&gt;… expectation of the squared score&lt;/h1&gt;

&lt;div class=&quot;tab-container scalar-vector&quot;&gt;&lt;div class=&quot;tab-visible&quot;&gt;
$$ \left[\mathcal{I(\theta)}\right]_{ij} =  \mathbb{E}_{p(x|\theta)}\left[\frac{\partial}{\partial \theta_j} \log p(x|\theta) \frac{\partial}{\partial \theta_i} \log p(x|\theta)\right] $$
&lt;/div&gt;&lt;div class=&quot;tab-invisible&quot;&gt;
$$ \mathcal{I(\theta)} =  \mathbb{E}_{p(x|\theta)}\left[\nabla_{\theta} \log p(x|\theta) \nabla_{\theta} \log p(x|\theta)^T\right] $$
&lt;/div&gt;&lt;div class=&quot;tab-bar&quot;&gt;&lt;h3 class=&quot;tab-button-selected&quot; onclick=&quot;switch_tab(this)&quot;&gt;Scalar&lt;/h3&gt;&lt;h3 class=&quot;tab-button&quot; onclick=&quot;switch_tab(this)&quot;&gt;Vector&lt;/h3&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h1 id=&quot;-variance-of-the-score&quot;&gt;… variance of the score&lt;/h1&gt;

&lt;div class=&quot;tab-container scalar-vector&quot;&gt;&lt;div class=&quot;tab-visible&quot;&gt;
$$
\begin{align*}
 \left[\mathcal{I(\theta)}\right]_{ij} &amp;amp;=  \text{Var}\left(\frac{\partial}{\partial \theta_i} \log p(x|\theta)\right) \\
 &amp;amp;=  \mathbb{E}_{p(x|\theta)}\left[\frac{\partial}{\partial \theta_i} \log p(x|\theta)\frac{\partial}{\partial \theta_i} \log p(x|\theta)\right] +  \mathbb{E}_{p(x|\theta)}\left[\frac{\partial}{\partial \theta_i} \log p(x|\theta)\right]^2 \\
\end{align*} 
 $$
&lt;/div&gt;&lt;div class=&quot;tab-invisible&quot;&gt;
$$ 
\begin{align*}
\mathcal{I(\theta)} &amp;amp;=  \text{Var}\left(\nabla_{\theta'} \log p(x|\theta')\right) \\
&amp;amp;=  \mathbb{E}_{p(x|\theta)}\left[\nabla_{\theta'} \log p(x|\theta')\nabla_{\theta'} \log p(x|\theta')^T\right] +  \mathbb{E}_{p(x|\theta)}\left[\nabla_{\theta'} \log p(x|\theta')\right]\mathbb{E}_{p(x|\theta)}\left[\nabla_{\theta'} \log p(x|\theta')\right]^T \\
\end{align*} 
 $$
&lt;/div&gt;&lt;div class=&quot;tab-bar&quot;&gt;&lt;h3 class=&quot;tab-button-selected&quot; onclick=&quot;switch_tab(this)&quot;&gt;Scalar&lt;/h3&gt;&lt;h3 class=&quot;tab-button&quot; onclick=&quot;switch_tab(this)&quot;&gt;Vector&lt;/h3&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;With&lt;/p&gt;

&lt;div class=&quot;tab-container scalar-vector&quot;&gt;&lt;div class=&quot;tab-visible&quot;&gt;
$$
\begin{align*} \mathbb{E}_{p(x|\theta)}\left[\frac{\partial}{\partial \theta_i} \log p(x|\theta)\right] =&amp;amp; \mathbb{E}_{p(x|\theta)}\left[\frac{1}{p(x|\theta)}\frac{\partial}{\partial \theta_i} p(x|\theta)\right] \\
=&amp;amp; \int \limits_{-\infty}^{\infty} p(x|\theta) \frac{1}{p(x|\theta)}\frac{\partial}{\partial \theta_i}p(x|\theta) dx \\
=&amp;amp; \int \limits_{-\infty}^{\infty} \frac{\partial}{\partial \theta_i} p(x|\theta) dx \\
=&amp;amp;  \frac{\partial}{\partial \theta_i}\int \limits_{-\infty}^{\infty} p(x|\theta) dx \\
=&amp;amp;  \frac{\partial}{\partial \theta_i} 1 \\
=&amp;amp; 0 
\end{align*}$$
&lt;/div&gt;&lt;div class=&quot;tab-invisible&quot;&gt;
$$
\begin{align*} \mathbb{E}_{p(x|\theta)}\left[\nabla_{\theta} \log p(x|\theta)\right] =&amp;amp; \mathbb{E}_{p(x|\theta)}\left[\frac{1}{p(x|\theta)}\nabla_{\theta} p(x|\theta)\right] \\
=&amp;amp; \int \limits_{-\infty}^{\infty} p(x|\theta) \frac{1}{p(x|\theta)}\nabla_{\theta} p(x|\theta) dx \\
=&amp;amp; \int \limits_{-\infty}^{\infty} \nabla_{\theta} p(x|\theta) dx \\
=&amp;amp;  \nabla_{\theta}\int \limits_{-\infty}^{\infty} p(x|\theta) dx \\
=&amp;amp;  \nabla_{\theta} 1 \\
=&amp;amp; 0 
\end{align*}$$
&lt;/div&gt;&lt;div class=&quot;tab-bar&quot;&gt;&lt;h3 class=&quot;tab-button-selected&quot; onclick=&quot;switch_tab(this)&quot;&gt;Scalar&lt;/h3&gt;&lt;h3 class=&quot;tab-button&quot; onclick=&quot;switch_tab(this)&quot;&gt;Vector&lt;/h3&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;follows&lt;/p&gt;

&lt;div class=&quot;tab-container scalar-vector&quot;&gt;&lt;div class=&quot;tab-visible&quot;&gt;
$$ \left[\mathcal{I(\theta)}\right]_{ij} =  \mathbb{E}_{p(x|\theta)}\left[\frac{\partial}{\partial \theta_j} \log p(x|\theta) \frac{\partial}{\partial \theta_i} \log p(x|\theta)\right] $$
&lt;/div&gt;&lt;div class=&quot;tab-invisible&quot;&gt;
$$ \mathcal{I(\theta)} =  \mathbb{E}_{p(x|\theta)}\left[\nabla_{\theta} \log p(x|\theta) \nabla_{\theta} \log p(x|\theta)^T\right] $$
&lt;/div&gt;&lt;div class=&quot;tab-bar&quot;&gt;&lt;h3 class=&quot;tab-button-selected&quot; onclick=&quot;switch_tab(this)&quot;&gt;Scalar&lt;/h3&gt;&lt;h3 class=&quot;tab-button&quot; onclick=&quot;switch_tab(this)&quot;&gt;Vector&lt;/h3&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h1 id=&quot;-curvature-of-the-kl-divergence&quot;&gt;… curvature of the KL-divergence&lt;/h1&gt;

&lt;div class=&quot;tab-container scalar-vector&quot;&gt;&lt;div class=&quot;tab-visible&quot;&gt;
$$
\begin{align*}
 \left[\mathcal{I(\theta)}\right]_{ij} =&amp;amp;\left. \frac{\partial^2 D_\textrm{KL}(\theta||\theta')}{\partial \theta_i\partial \theta_j} \right|_{\theta' = \theta}\\
 =&amp;amp;  -\mathbb{E}_{p(x|\theta)}\left[\frac{\partial^2  \log p(x|\theta)}{\partial \theta_i  \partial \theta_j}\right] \\
=&amp;amp; - \mathbb{E}_{p(x|\theta)}\left[-\frac{\partial}{\partial \theta_j} \log p(x|\theta) \frac{\partial}{\partial \theta_i} \log p(x|\theta) +    \frac{1}{p(x|\theta)} \frac{\partial^2 p(x|\theta)}{\partial \theta_i\partial \theta_j}\right] \\
=&amp;amp; \mathbb{E}_{p(x|\theta)}\left[\frac{\partial}{\partial \theta_j} \log p(x|\theta) \frac{\partial}{\partial \theta_i} \log p(x|\theta)\right] -    \mathbb{E}_{p(x|\theta)}\left[\frac{1}{p(x|\theta)} \frac{\partial^2 p(x|\theta)}{\partial \theta_\partial \theta_j}\right]\\
\end{align*}$$
&lt;/div&gt;&lt;div class=&quot;tab-invisible&quot;&gt;
$$
\begin{align*}
\mathcal{I(\theta)} =&amp;amp;\left. \nabla^2_{\theta}D_\textrm{KL}(\theta||\theta) \right|_{\theta = \theta}\\
 =&amp;amp;  -\mathbb{E}_{p(x|\theta)}\left[\nabla_{\theta}^2 \log p(x|\theta)\right]\\
 =&amp;amp; - \mathbb{E}_{p(x|\theta)}\left[-\nabla_{\theta} \log p(x|\theta) \nabla_{\theta} \log p(x|\theta)^T +    \frac{1}{p(x|\theta)} \nabla^2_{\theta} \log p(x|\theta)\right] \\
=&amp;amp; \mathbb{E}_{p(x|\theta)}\left[\nabla_{\theta} \log p(x|\theta) \nabla_{\theta} \log p(x|\theta)^T\right] -    \mathbb{E}_{p(x|\theta)}\left[\frac{1}{p(x|\theta)} \nabla^2_{\theta} \log p(x|\theta)\right]\\
\end{align*}$$
&lt;/div&gt;&lt;div class=&quot;tab-bar&quot;&gt;&lt;h3 class=&quot;tab-button-selected&quot; onclick=&quot;switch_tab(this)&quot;&gt;Scalar&lt;/h3&gt;&lt;h3 class=&quot;tab-button&quot; onclick=&quot;switch_tab(this)&quot;&gt;Vector&lt;/h3&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;With&lt;/p&gt;

&lt;div class=&quot;tab-container scalar-vector&quot;&gt;&lt;div class=&quot;tab-visible&quot;&gt;
$$
\begin{align*}
\mathbb{E}_{p(x|\theta)}\left[\frac{1}{p(x|\theta)} \frac{\partial^2 p(x|\theta)}{\partial \theta_\partial \theta_j}\right]=&amp;amp; \int \limits_{-\infty}^{\infty} p(x|\theta) \frac{1}{p(x|\theta)} \frac{\partial^2 p(x|\theta)}{\partial \theta_i\partial \theta_j} dx  \\
=&amp;amp; \int \limits_{-\infty}^{\infty}  \frac{\partial^2 p(x|\theta)}{\partial \theta_i\partial \theta_j} dx  \\
=&amp;amp;  \frac{\partial^2 }{\partial \theta_i\partial \theta_j}\int \limits_{-\infty}^{\infty} p(x|\theta)  dx  \\
=&amp;amp;  \frac{\partial^2 }{\partial \theta_i\partial \theta_j}1  \\
=&amp;amp; 0 .
\end{align*}
$$
&lt;/div&gt;&lt;div class=&quot;tab-invisible&quot;&gt;
$$
\begin{align*} 
\mathbb{E}_{p(x|\theta)}\left[\frac{1}{p(x|\theta)} \nabla^2_{\theta} \log p(x|\theta)\right]=&amp;amp;  \int \limits_{-\infty}^{\infty} p(x|\theta) \frac{1}{p(x|\theta)} \nabla^2_{\theta} \log p(x|\theta) dx  \\
=&amp;amp;  \int \limits_{-\infty}^{\infty}  \nabla^2_{\theta} \log p(x|\theta) dx  \\
=&amp;amp;  \nabla^2_{\theta}\int \limits_{-\infty}^{\infty} p(x|\theta)  dx  \\
=&amp;amp;  \nabla^2_{\theta}1   \\
=&amp;amp;0
\end{align*}$$
&lt;/div&gt;&lt;div class=&quot;tab-bar&quot;&gt;&lt;h3 class=&quot;tab-button-selected&quot; onclick=&quot;switch_tab(this)&quot;&gt;Scalar&lt;/h3&gt;&lt;h3 class=&quot;tab-button&quot; onclick=&quot;switch_tab(this)&quot;&gt;Vector&lt;/h3&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;follows&lt;/p&gt;

&lt;div class=&quot;tab-container scalar-vector&quot;&gt;&lt;div class=&quot;tab-visible&quot;&gt;
$$ \left[\mathcal{I(\theta)}\right]_{ij} =  \mathbb{E}_{p(x|\theta)}\left[\frac{\partial}{\partial \theta_j} \log p(x|\theta) \frac{\partial}{\partial \theta_i} \log p(x|\theta)\right] $$
&lt;/div&gt;&lt;div class=&quot;tab-invisible&quot;&gt;
$$ \mathcal{I(\theta)} =  \mathbb{E}_{p(x|\theta)}\left[\nabla_{\theta} \log p(x|\theta) \nabla_{\theta} \log p(x|\theta)^T\right] $$
&lt;/div&gt;&lt;div class=&quot;tab-bar&quot;&gt;&lt;h3 class=&quot;tab-button-selected&quot; onclick=&quot;switch_tab(this)&quot;&gt;Scalar&lt;/h3&gt;&lt;h3 class=&quot;tab-button&quot; onclick=&quot;switch_tab(this)&quot;&gt;Vector&lt;/h3&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h1 id=&quot;-curvature-of-the-cross-entropy&quot;&gt;… curvature of the cross entropy&lt;/h1&gt;

&lt;p&gt;Cross entropy and Kullback-Leibler divergence only differ by constant additive term. Therefore, curvature has to be identical.&lt;/p&gt;

&lt;h1 id=&quot;-expected-negative-curvature-of-log-likelihood&quot;&gt;… expected negative curvature of log-likelihood&lt;/h1&gt;

&lt;div class=&quot;tab-container scalar-vector&quot;&gt;&lt;div class=&quot;tab-visible&quot;&gt;
$$
\begin{align*}
 \left[\mathcal{I(\theta)}\right]_{ij}  =&amp;amp;  -\mathbb{E}_{p(x|\theta)}\left[\frac{\partial^2  \log p(x|\theta)}{\partial \theta_i  \partial \theta_j}\right] \\
\end{align*}$$
&lt;/div&gt;&lt;div class=&quot;tab-invisible&quot;&gt;
$$
\begin{align*}
\mathcal{I(\theta)} =&amp;amp;  -\mathbb{E}_{p(x|\theta)}\left[\nabla_{\theta}^2 \log p(x|\theta)\right]\\
\end{align*}$$
&lt;/div&gt;&lt;div class=&quot;tab-bar&quot;&gt;&lt;h3 class=&quot;tab-button-selected&quot; onclick=&quot;switch_tab(this)&quot;&gt;Scalar&lt;/h3&gt;&lt;h3 class=&quot;tab-button&quot; onclick=&quot;switch_tab(this)&quot;&gt;Vector&lt;/h3&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;See &lt;em&gt;curvature of the KL-divergence&lt;/em&gt;.&lt;/p&gt;

&lt;h1 id=&quot;-expected-value-of-the-observed-information&quot;&gt;… expected value of the observed information&lt;/h1&gt;

&lt;div class=&quot;tab-container scalar-vector&quot;&gt;&lt;div class=&quot;tab-visible&quot;&gt;
$$ \left[\mathcal{I(\theta)}\right]_{ij} =  \mathbb{E}_{p(x|\theta)}\left[\left[\mathcal{J(\theta)}\right]_{ij}\right] $$
&lt;/div&gt;&lt;div class=&quot;tab-invisible&quot;&gt;
$$ \mathcal{I(\theta)} =  \mathbb{E}_{p(x|\theta)}\left[\mathcal{J(\theta)}\right] $$
&lt;/div&gt;&lt;div class=&quot;tab-bar&quot;&gt;&lt;h3 class=&quot;tab-button-selected&quot; onclick=&quot;switch_tab(this)&quot;&gt;Scalar&lt;/h3&gt;&lt;h3 class=&quot;tab-button&quot; onclick=&quot;switch_tab(this)&quot;&gt;Vector&lt;/h3&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;where the observed information \(\mathcal{J(\theta)}\) is defined as&lt;/p&gt;

&lt;div class=&quot;tab-container scalar-vector&quot;&gt;&lt;div class=&quot;tab-visible&quot;&gt;
$$ \left[\mathcal{J(\theta)}\right]_{ij} =  -\frac{\partial^2  \log p(x|\theta)}{\partial \theta_i  \partial \theta_j} $$
&lt;/div&gt;&lt;div class=&quot;tab-invisible&quot;&gt;
$$ \mathcal{J(\theta)} =  -\nabla_{\theta}^2 \log p(x|\theta) $$
&lt;/div&gt;&lt;div class=&quot;tab-bar&quot;&gt;&lt;h3 class=&quot;tab-button-selected&quot; onclick=&quot;switch_tab(this)&quot;&gt;Scalar&lt;/h3&gt;&lt;h3 class=&quot;tab-button&quot; onclick=&quot;switch_tab(this)&quot;&gt;Vector&lt;/h3&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;We note that this case has the same form as the curvature of the KL-divergence.&lt;/p&gt;</content><author><name></name></author><summary type="html">This article is a brief summary of some relationships between the log-likelihood, score, Kullback-Leibler divergence and Fisher information. No explanations, just pure math.</summary></entry><entry><title type="html">Derivation of the Kalman filter</title><link href="http://localhost:4000/jekyll/update/2018/10/10/kalman_filter.html" rel="alternate" type="text/html" title="Derivation of the Kalman filter" /><published>2018-10-10T19:35:07+09:00</published><updated>2018-10-10T19:35:07+09:00</updated><id>http://localhost:4000/jekyll/update/2018/10/10/kalman_filter</id><content type="html" xml:base="http://localhost:4000/jekyll/update/2018/10/10/kalman_filter.html">&lt;p&gt;The concept and the equations of the &lt;a href=&quot;https://en.wikipedia.org/wiki/Kalman_filter&quot;&gt;Kalman filter&lt;/a&gt; can be quite confusing at the beginning. Often the assumptions are not stated clearly and the equations are just falling from the sky. This post is an attempt to derive the equations of the Kalman filter in a systematic and hopefully understandable way using &lt;a href=&quot;https://en.wikipedia.org/wiki/Bayesian_inference&quot;&gt;Bayesian inference&lt;/a&gt;. It addresses everyone, who wants to get a deeper understanding of the Kalman filter and is equipped with basic knowledge of linear algebra and probability theory.
&lt;!--more--&gt;&lt;/p&gt;

&lt;script type=&quot;text/javascript&quot;&gt;
    function draw_ssm(svg){


      var radius = 30;
      var dist_x = 120;
      var dist_y = 120;
      var margin_x = 50;
      var margin_y = 50;
      var markersize = 10;

      var input_ns = [];
      var state_ns = [];
      var output_ns = [];
      var edges = [];
      var T = 5;

      for (var t = 0; t&lt;T;t++){


      	if (t&lt;T-1) input_ns.push({title: &quot;\\( u_&quot; + t + &quot; \\)&quot;, type: &quot;prob&quot;, x: margin_x + dist_x*t , y: margin_y , fill:&quot;#e3e5feff&quot;});
        state_ns.push({title: &quot;\\( x_&quot; + t +&quot; \\)&quot;, type: &quot;prob&quot;, x: margin_x + dist_x*t , y: margin_y + dist_y, fill:&quot;#FFFFFF&quot;});
        output_ns.push({title: &quot;\\( y_&quot; + t + &quot; \\)&quot;, type: &quot;prob&quot;, x: margin_x + dist_x*t , y: margin_y+ 2*dist_y, fill:&quot;#e3e5feff&quot;});


        edges.push({source: state_ns[t], target: output_ns[t], dash:&quot;&quot;})
        if (t&gt;0) {
        	edges.push({source: state_ns[t-1], target: state_ns[t], dash:&quot;&quot;})
        	edges.push({source: input_ns[t-1], target: state_ns[t], dash:&quot;&quot;})
        }
      }

    var svg_w = 2*margin_x + dist_x*(T-1);
    var svg_h = 2*margin_y + 2*dist_y;

  	nodes = input_ns.concat(state_ns).concat(output_ns);
    create_graph(d3.select(svg), nodes, edges, radius, markersize, svg_w, svg_h);
    }

    function draw_ssm_ind(svg){


      var radius = 30;
      var dist_x = 120;
      var dist_y = 120;
      var margin_x = 120;
      var margin_y = 50;
      var markersize = 10;

      var input_ns = [];
      var state_ns = [];
      var output_ns = [];
      var edges = [];
      var T = 4;

      for (var t = 0; t&lt;T;t++){


      	ind = &quot;t&quot;

      	if (t&lt;T-1) ind+=(t-T+1)


      	if (t&lt;T-1) input_ns.push({title: &quot;\\( u_{&quot; + ind + &quot;}\\)&quot;, type: &quot;prob&quot;, x: margin_x + dist_x*t , y: margin_y , fill:&quot;#e3e5feff&quot;});

      	statefill = (t==T-1) ? &quot;#e3e5feff&quot; :statefill = &quot;#FFFFFF&quot;;
        state_ns.push({title: &quot;\\( x_{&quot; + ind + &quot;} \\)&quot;, type: &quot;prob&quot;, x: margin_x + dist_x*t , y: margin_y + dist_y, fill:statefill});
        output_ns.push({title: &quot;\\( y_{&quot; + ind + &quot;} \\)&quot;, type: &quot;prob&quot;, x: margin_x + dist_x*t , y: margin_y+ 2*dist_y, fill:&quot;#e3e5feff&quot;});



        edges.push({source: state_ns[t], target: output_ns[t], dash:&quot;&quot;})
        if (t&gt;0) {
        	edges.push({source: state_ns[t-1], target: state_ns[t], dash:&quot;&quot;})
        	edges.push({source: input_ns[t-1], target: state_ns[t], dash:&quot;&quot;})
        }
      }


    bstate_h = {x: state_ns[0].x - radius*4, y: state_ns[0].y}
    binput_h = {x: state_ns[0].x - 2*Math.sqrt(2)*radius, y: state_ns[0].y- 2*Math.sqrt(2)*radius}

    edges.push({source: bstate_h, target: state_ns[0], dash:&quot;5,5&quot;})
    edges.push({source: binput_h, target: state_ns[0], dash:&quot;5,5&quot;})


  	nodes = input_ns.concat(state_ns).concat(output_ns);

  	var svg_w = margin_x + dist_x*(T-1) + 50;
    var svg_h = 2*margin_y + 2*dist_y;

    create_graph(d3.select(svg), nodes, edges, radius, markersize, svg_w, svg_h);
    }

    function draw_ssm_indi(svg){

      var radius = 30;
      var dist_x = 120;
      var dist_y = 120;
      var margin_x = 100;
      var margin_y = 50;
      var markersize = 10;

      var input_ns = [];
      var state_ns = [];
      var output_ns = [];
      var edges = [];
      var T = 5;

      for (var t = 0; t&lt;T;t++){


      	ind = &quot;t&quot;

      	if (t&lt;2) ind+=(t-2)
      	if (t&gt;2) ind+=&quot;+&quot;+(t-2)


      	input_ns.push({title: &quot;\\( u_{&quot; + ind + &quot;}\\)&quot;, type: &quot;prob&quot;, x: margin_x + dist_x*t , y: margin_y , fill:&quot;#e3e5feff&quot;});

      	statefill = (t==2) ? &quot;#e3e5feff&quot; :statefill = &quot;#FFFFFF&quot;;
        state_ns.push({title: &quot;\\( x_{&quot; + ind + &quot;} \\)&quot;, type: &quot;prob&quot;, x: margin_x + dist_x*t , y: margin_y + dist_y, fill:statefill});
        output_ns.push({title: &quot;\\( y_{&quot; + ind + &quot;} \\)&quot;, type: &quot;prob&quot;, x: margin_x + dist_x*t , y: margin_y+ 2*dist_y, fill:&quot;#e3e5feff&quot;});



        edges.push({source: state_ns[t], target: output_ns[t], dash:&quot;&quot;})
        if (t&gt;0) {
        	edges.push({source: state_ns[t-1], target: state_ns[t], dash:&quot;&quot;})
        	edges.push({source: input_ns[t-1], target: state_ns[t], dash:&quot;&quot;})
        }
      }

    estate_h = {x: state_ns[T-1].x + radius*4, y: state_ns[T-1].y}
    bstate_h = {x: state_ns[0].x - radius*4, y: state_ns[0].y}
    einput_h = {x: input_ns[T-1].x + 2*Math.sqrt(2)*radius, y: input_ns[T-1].y+ 2*Math.sqrt(2)*radius}
    binput_h = {x: state_ns[0].x - 2*Math.sqrt(2)*radius, y: state_ns[0].y- 2*Math.sqrt(2)*radius}


    edges.push({source: state_ns[T-1], target: estate_h, dash:&quot;5,5&quot;})
    edges.push({source: bstate_h, target: state_ns[0], dash:&quot;5,5&quot;})
    edges.push({source: input_ns[T-1], target: einput_h, dash:&quot;5,5&quot;})
    edges.push({source: binput_h, target: state_ns[0], dash:&quot;5,5&quot;})


  	nodes = input_ns.concat(state_ns).concat(output_ns);
    var svg_w = 2*margin_x + dist_x*(T-1);
    var svg_h = 2*margin_y + 2*dist_y;

    create_graph(d3.select(svg), nodes, edges, radius, markersize, svg_w, svg_h);
    }

	function draw_ssm_obs(svg){


      var radius = 30;
      var dist_x = 120;
      var dist_y = 120;
      var margin_x = 50;
      var margin_y = 50;
      var markersize = 10;

      var input_ns = [];
      var state_ns = [];
      var output_ns = [];
      var edges = [];
      var T = 5;

      for (var t = 0; t&lt;T;t++){


      	if (t&lt;T-1) input_ns.push({title: &quot;\\( u_&quot; + t + &quot; \\)&quot;, type: &quot;prob&quot;, x: margin_x + dist_x*t , y: margin_y , fill:&quot;#e3e5feff&quot;});
        state_ns.push({title: &quot;\\( x_&quot; + t +&quot; \\)&quot;, type: &quot;prob&quot;, x: margin_x + dist_x*t , y: margin_y + dist_y, fill:&quot;#FFFFFF&quot;});

        if (t==0||t==4) output_ns.push({title: &quot;\\( y_&quot; + t + &quot; \\)&quot;, type: &quot;prob&quot;, x: margin_x + dist_x*t , y: margin_y+ 2*dist_y, fill:&quot;#e3e5feff&quot;});
        if (t==2) {
        	output_ns.push({title: &quot;\\( z_&quot; + t + &quot; \\)&quot;, type: &quot;prob&quot;, x: margin_x + dist_x*(t+0.5) , y: margin_y+ 2*dist_y, fill:&quot;#e3e5feff&quot;});
			output_ns.push({title: &quot;\\( y_&quot; + t + &quot; \\)&quot;, type: &quot;prob&quot;, x: margin_x + dist_x*(t-0.5) , y: margin_y+ 2*dist_y, fill:&quot;#e3e5feff&quot;});
        }
        



        if (t&gt;0) {
        	edges.push({source: state_ns[t-1], target: state_ns[t], dash:&quot;&quot;})
        	edges.push({source: input_ns[t-1], target: state_ns[t], dash:&quot;&quot;})
        }
      }

      edges.push({source: state_ns[0], target: output_ns[0], dash:&quot;&quot;})
      edges.push({source: state_ns[2], target: output_ns[1], dash:&quot;&quot;})
      edges.push({source: state_ns[2], target: output_ns[2], dash:&quot;&quot;})
      edges.push({source: state_ns[4], target: output_ns[3], dash:&quot;&quot;})

  	nodes = input_ns.concat(state_ns).concat(output_ns);

    var svg_w = 2*margin_x + dist_x*(T-1);
    var svg_h = 2*margin_y + 2*dist_y;

    create_graph(d3.select(svg), nodes, edges, radius, markersize, svg_w, svg_h);

    }
 &lt;/script&gt;

&lt;script src=&quot;//d3js.org/d3.v3.js&quot; charset=&quot;utf-8&quot;&gt;&lt;/script&gt;

&lt;p&gt;First of all, let’s try to formulate the main idea of Kalman filtering in one sentence:&lt;/p&gt;

&lt;div class=&quot;important_box&quot;&gt;
  &lt;p&gt;The &lt;strong&gt;Kalman filter&lt;/strong&gt; is used to &lt;strong&gt;infer&lt;/strong&gt; the current state of a &lt;strong&gt;linear Gaussian state space model&lt;/strong&gt; given all observations and inputs up to the current timestep and a Gaussian prior distribution of the initial state.&lt;/p&gt;
&lt;/div&gt;

&lt;p&gt;Indeed, the process of Kalman filtering is simply Bayesian inference in the domain of linear Gaussian state space models. The information encoded in our formulation is sufficient to uniquely define what the Kalman filter should output. But it doesn’t tell us anything about how to compute it. In this article, we will find an efficient recursive method that will lead us to the familiar equations.&lt;/p&gt;

&lt;p&gt;Let’s get started with the derivation by defining &lt;em&gt;linear Gaussian state space models&lt;/em&gt; and &lt;em&gt;Bayesian inference&lt;/em&gt;.&lt;/p&gt;

&lt;h2 id=&quot;linear-gaussian-state-space-models&quot;&gt;Linear Gaussian state space models&lt;/h2&gt;

&lt;p&gt;A linear Gaussian state space model is defined by&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{align}x_{t+1} &amp;= A_tx_t + B_t u_t + w_t \\ 
y_t &amp;= C_tx_t + v_t \end{align} %]]&gt;&lt;/script&gt;

&lt;p&gt;with state \(x_t\), output \(y_t\), input \(u_t\), system matrix \(A_t\), input matrix \(B_t\), output matrix \(C_t\), Gaussian process noise \( w_t \sim \mathcal{N}(w_t|0, Q_t) \) and Gaussian observation noise \( v_t \sim \mathcal{N}(v_t|0, R_t) \).&lt;/p&gt;

&lt;p&gt;Alternatively, we can use the probability density functions&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{align}x_{t+1} &amp;\sim \mathcal{N}(x_{t+1}|A_tx_t + B_t u_t, Q_t)\\ 
 y_t &amp;\sim \mathcal{N}(y_t|C_tx_t, R_t)\end{align} %]]&gt;&lt;/script&gt;

&lt;p&gt;to describe the system in a more compact fashion.&lt;/p&gt;

&lt;p&gt;Linear Gaussian state space models can also be described in the language of &lt;a href=&quot;https://en.wikipedia.org/wiki/Graphical_model&quot;&gt;probabilistic graphical models&lt;/a&gt; (or more precisely in the language of &lt;a href=&quot;https://en.wikipedia.org/wiki/Bayesian_network&quot;&gt;Bayesian networks&lt;/a&gt;). The figure below shows such a model up to time \(T = 4\).&lt;/p&gt;

&lt;svg class=&quot;pgm_centered&quot; onload=&quot;draw_ssm(this);&quot;&gt;&lt;/svg&gt;

&lt;p&gt;Every node represents a random variable and the edges are representing conditional dependencies between the respective nodes. Random variables, that are observed (or given) are shaded in light blue. In our case this is the output \(y_t\) and the input \(u_t\). The state \(x_t\) is not observed (or latent).&lt;/p&gt;

&lt;h2 id=&quot;bayesian-inference&quot;&gt;Bayesian inference&lt;/h2&gt;

&lt;p&gt;In simplest terms Bayesian inference tries to update a hypothesis/belief of something, that is not directly observable, in the face of new information by using &lt;a href=&quot;https://en.wikipedia.org/wiki/Bayes%27_theorem&quot;&gt;Bayes’ rule&lt;/a&gt;. A bit more formal: The goal is to update the prior distribution \(p(x)\) given new data \(\mathcal{D}\) to obtain the posterior distribution \(p(x|\mathcal{D})\) with help of Bayes rule&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;p(x|\mathcal{D}) = \frac{p(\mathcal{D}|x)p(x)}{p(\mathcal{D})}&lt;/script&gt;

&lt;p&gt;with likelihood \(p(\mathcal{D}|x)\) and evidence \(p(\mathcal{D})\).&lt;/p&gt;

&lt;p&gt;This idea is very general and can be applied to dynamical models quite easily. The most common inference tasks in dynamical models are filtering, smoothing and prediction. These methods differ only in the form of the posterior distribution.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Filtering&lt;/strong&gt;: What is my belief about the &lt;strong&gt;current state&lt;/strong&gt; \(x_t\) given all observations and inputs?&lt;/li&gt;
&lt;/ul&gt;

&lt;div class=&quot;big_eq&quot;&gt; 	$$ p(x_t|y_0,...,y_t,u_0,...,u_{t-1})  $$ &lt;/div&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Smoothing&lt;/strong&gt;: What is my belief about &lt;strong&gt;all states&lt;/strong&gt; \(x_t, … ,x_0\) given all observations and inputs?&lt;/li&gt;
&lt;/ul&gt;

&lt;div class=&quot;big_eq&quot;&gt; $$ p(x_t,...,x_0|y_0,...,y_t,u_0,...,u_{t-1}) $$ &lt;/div&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Prediction&lt;/strong&gt;: What is my belief about the &lt;strong&gt;next state&lt;/strong&gt; \(x_{t+1}\) given all observations and inputs?&lt;/li&gt;
&lt;/ul&gt;

&lt;div class=&quot;big_eq&quot;&gt; $$ p(x_{t+1}|y_0,...,y_t,u_0,...,u_{t-1}) $$ &lt;/div&gt;

&lt;p&gt;The name Kalman &lt;em&gt;filter&lt;/em&gt; reveals, that we will be interested in the filtering problem. Therefore, we want to infer the current state \(x_t\) based on all recent observations \(y_0,…,y_t\) and inputs \(u_0,…,u_{t-1}\).
Now that we have defined what we are looking for, let’s try to find a way to efficiently calculate it. We will start by finding a recursive method for &lt;em&gt;general&lt;/em&gt; dynamical models defined by the probabilistic graphical model above.&lt;/p&gt;

&lt;h2 id=&quot;bayes-filter-for-state-space-models&quot;&gt;Bayes filter for state space models&lt;/h2&gt;

&lt;p&gt;We have the task to calculate \( p(x_{t}|y_0,…,y_t,u_0,…,u_{t-1}) \). For this purpose only the structure of the graphical model will matter: it governs the conditional dependencies.
To unclutter the notation we will use \(\Box_{n:m}\) for \(\Box_n,…,\Box_m\).&lt;/p&gt;

&lt;p&gt;With help of &lt;strong&gt;Bayes’ rule&lt;/strong&gt; we can rewrite the formula as&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;p(x_t|y_{0:t},u_{0:t-1}) = \frac{p(y_t|x_t,y_{0:t-1},u_{0:t-1})p(x_t|y_{0:t-1},u_{0:t-1})}{p(y_t|y_{0:t-1},u_{0:t-1})}.&lt;/script&gt;

&lt;div class=&quot;extra_box&quot;&gt;
  &lt;p&gt;If you are not very familiar with Bayes’ rule this can be quite confusing. There are much more moving parts than in the very simple definition. Nonetheless, there is an intuitive explanation.
It is Bayes’ rule applied in a world, where we already observed \(\mathcal{W}\) in the past (every term is conditioned on \(\mathcal{W}\)):&lt;/p&gt;

  &lt;script type=&quot;math/tex; mode=display&quot;&gt;p(x|\mathcal{D},\mathcal{W}) = \frac{p(\mathcal{D}|x,\mathcal{W})p(x|\mathcal{W})}{p(\mathcal{D}|\mathcal{W})}.&lt;/script&gt;

  &lt;p&gt;In our case \(x:=x_t \), \(\mathcal{D}:=y_t \) and \(\mathcal{W}:=(y_{0:t-1},u_{0:t-1}) \).&lt;/p&gt;

&lt;/div&gt;
&lt;p&gt;We note that \(y_t\) is independent of \(y_{0:t-1}\) and  \(u_{0:t-1}\) given \(x_t\). It follows&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;p(x_t|y_{0:t},u_{0:t-1}) = \frac{p(y_t|x_t)p(x_t|y_{0:t-1},u_{0:t-1})}{p(y_t|y_{0:t-1},u_{0:t-1})}.&lt;/script&gt;

&lt;div class=&quot;extra_box&quot;&gt;
  &lt;p&gt;This conditional independence property is not obvious as well. When it comes to conditional dependencies, it is always a good idea to look at the graphical model.&lt;/p&gt;

  &lt;svg class=&quot;pgm_centered&quot; onload=&quot;draw_ssm_ind(this);&quot;&gt;&lt;/svg&gt;
  &lt;p&gt;In the figure above we notice that the node \(x_t\) is shaded (observed). This node blocks the way of \(y_{0:t-1}\) and  \(u_{0:t-1}\) to \(y_t\). We have proven the conditional independence &lt;em&gt;visually&lt;/em&gt;. You can learn more about conditional independence in probabilistic graphical models in &lt;a href=&quot;https://www.microsoft.com/en-us/research/people/cmbishop/#!prml-book&quot;&gt;Pattern Recognition and Machine Learning&lt;/a&gt; (Chapter 8.2).&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;The denominator is simply the integral of the numerator&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;p(y_t|y_{0:t-1},u_{0:t-1}) = \int_{x_t} p(y_t|x_t)p(x_t|y_{0:t-1},u_{0:t-1}) dx_t .&lt;/script&gt;

&lt;p&gt;Great! We successfully expressed our equation in simpler terms. In return, we obtained the new expression \(p(x_t|y_{0:t-1},u_{0:t-1})\), which we have to calculate as well. Using marginalization we can express it as&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;p(x_t|y_{0:t-1},u_{0:t-1}) = \int_{x_{t-1}} p(x_t,x_{t-1}|y_{0:t-1},u_{0:t-1}) dx_{t-1}.&lt;/script&gt;

&lt;p&gt;We can split the expression in the integral with product rule, which leads to&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;p(x_t|y_{0:t-1},u_{0:t-1}) = \int_{x_{t-1}} p(x_t|x_{t-1},y_{0:t-1},u_{0:t-1})p(x_{t-1}|y_{0:t-1},u_{0:t-1}) dx_{t-1}.&lt;/script&gt;

&lt;p&gt;Note that \(x_t\) is independent of \(y_{0:t-1}\) and \(u_{0:t-2}\) given \(x_{t-1}\). Furthermore, \(x_{t-1}\) is independent of \(u_{t-1}\). We obtain&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;p(x_t|y_{0:t-1},u_{0:t-1}) = \int_{x_{t-1}} p(x_t|x_{t-1}, u_{t-1})p(x_{t-1}|y_{0:t-1},u_{0:t-2}) dx_{t-1}.&lt;/script&gt;

&lt;p&gt;We note that \(p(x_{t-1}|y_{0:t-1},u_{0:t-2})\) has the same form as our expression we started from only shifted by one time step. Our recursive formula is complete!&lt;/p&gt;

&lt;p&gt;Let’s summarize our results!&lt;/p&gt;

&lt;div class=&quot;important_box&quot;&gt;
  &lt;h1&gt;Bayes filter for state space models&lt;/h1&gt;

  &lt;p&gt;The recursive formula for the Bayes filter in state space models consists of the &lt;strong&gt;prediction step&lt;/strong&gt;&lt;/p&gt;

  &lt;script type=&quot;math/tex; mode=display&quot;&gt;p(x_{t+1}|y_{0:t},u_{0:t}) = \int_{x_{t}} p(x_{t+1}|x_{t}, u_{t})p(x_{t}|y_{0:t},u_{0:t-1}) dx_{t}&lt;/script&gt;

  &lt;p&gt;and the &lt;strong&gt;update step&lt;/strong&gt;&lt;/p&gt;

  &lt;script type=&quot;math/tex; mode=display&quot;&gt;p(x_t|y_{0:t},u_{0:t-1}) = \frac{p(y_t|x_t)p(x_t|y_{0:t-1},u_{0:t-1})}{p(y_t|y_{0:t-1},u_{0:t-1})} .&lt;/script&gt;

  &lt;p&gt;The recursion is started with the prior distribution over the initial state \(p(x_0)\).&lt;/p&gt;

&lt;/div&gt;

&lt;p&gt;Up to this point, we assumed that we obtain exactly one observation at every timestep. This rather limiting assumption is violated in many real-life scenarios. Multiple or even no observations per timestep are possible. This behavior is exemplified in the probabilistic graphical model below.&lt;/p&gt;

&lt;svg class=&quot;pgm_centered&quot; onload=&quot;draw_ssm_obs(this);&quot;&gt;&lt;/svg&gt;

&lt;p&gt;Fortunately, handling these cases is very simple. For every observation we make, we calculate the update step with the newest estimate available. Furthermore, it is not necessary that the observations are coming from the same output function (illustrated by the outputs \(y_2\) and \(z_2\) at \(t=2\)). &lt;a href=&quot;https://en.wikipedia.org/wiki/Information_integration&quot;&gt;Information integration/fusion&lt;/a&gt; is very natural in Bayesian inference.&lt;/p&gt;

&lt;p&gt;Nice! We just derived the equations of the Bayes filter for general state space models!
Now let’s translate this into the linear state space scenario.&lt;/p&gt;

&lt;h2 id=&quot;bayes-filter-in-linear-gaussian-state-space-models&quot;&gt;Bayes filter in linear Gaussian state space models&lt;/h2&gt;

&lt;p&gt;Let’s start by identifying the probability distributions we already know:&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{align}
p(x_{t+1}|x_{t}, u_{t})  &amp;= \mathcal{N}(x_{t+1}|A_tx_t + B_t u_t, Q_t) \\
p(y_t|x_t) &amp;=  \mathcal{N}(y_t|C_tx_t, R_t). 
 \end{align} %]]&gt;&lt;/script&gt;

&lt;p&gt;Furthermore, we assume that the prior distribution of the initial state is Gaussian as well. All probability distributions in our model are Gaussian. Therefore, the distributions \(p(x_t|y_{0:t-1},u_{0:t-1})\) and \(p(x_t|y_{0:t},u_{0:t-1})\) will also be in form of Gaussian distributions, because our recursive formula is only using marginalization and Bayes’ rule, which are closed under Gaussian distributions. In the context of Kalman filtering, these are normally defined by&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{align}
p(x_t|y_{0:t},u_{0:t-1}) &amp;:= \mathcal{N}(x_{t}|\hat x_{t|t}, P_{t|t}) \\
p(x_t|y_{0:t-1},u_{0:t-1}) &amp;:= \mathcal{N}(x_{t}|\hat x_{t|t-1}, P_{t|t-1}) .
 \end{align} %]]&gt;&lt;/script&gt;

&lt;p&gt;Please note, that these distributions are still implicitly dependent on the inputs and outputs. The mean and the covariance are a &lt;em&gt;sufficient statistic&lt;/em&gt; of the in- and outputs.&lt;/p&gt;

&lt;p&gt;The index \(\Box_{n|m}\) of the parameters indicates that the state at time \(n\) is estimated, based on the outputs upto time \(m\).
The expression \(\hat x_{t|t}\) is called the &lt;em&gt;updated&lt;/em&gt; state estimate and \( P_{t|t}\) the &lt;em&gt;updated&lt;/em&gt; error covariance. Moreover, \(\hat x_{t|t-1}\) is called the &lt;em&gt;predicted&lt;/em&gt; state estimate and \( P_{t|t-1}\) the &lt;em&gt;predicted&lt;/em&gt; error covariance.&lt;/p&gt;

&lt;p&gt;In summary, these are the equations for the Bayes filter in linear Gaussian state space models:&lt;/p&gt;
&lt;div class=&quot;important_box&quot;&gt;

  &lt;p&gt;&lt;strong&gt;Prediction step&lt;/strong&gt;&lt;/p&gt;

  &lt;script type=&quot;math/tex; mode=display&quot;&gt;\mathcal{N}(x_{t+1}|\hat x_{t+1|t}, P_{t+1|t})  = \int_{x_t}\mathcal{N}(x_{t+1}|A_tx_t + B_t u_t, Q_t)\mathcal{N}(x_t|\hat x_{t|t}, P_{t|t}) dx_t.&lt;/script&gt;

  &lt;p&gt;&lt;strong&gt;Update step&lt;/strong&gt;&lt;/p&gt;

  &lt;script type=&quot;math/tex; mode=display&quot;&gt;\mathcal{N}(x_{t}|\hat x_{t|{t}}, P_{t|t} ) = \frac{\mathcal{N}(y_{t}|C_tx_{t}, R_t )\mathcal{N}(x_{t}|\hat x_{t|t-1}, P_{t|t-1})}{\int_{x_{t}}\mathcal{N}(y_{t}|C_tx_{t}, R_t )\mathcal{N}(x_{t}|\hat x_{t|t-1}, P_{t|t-1}) dx_{t}}&lt;/script&gt;

&lt;/div&gt;

&lt;p&gt;Let’s try to simplify these equations!&lt;/p&gt;

&lt;h3 id=&quot;prediction-step&quot;&gt;Prediction step&lt;/h3&gt;

&lt;p&gt;We will start with the prediction step&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\mathcal{N}(x_{t+1}|\hat x_{t+1|t}, P_{t+1|t})  = \int_{x_t}\mathcal{N}(x_{t+1}|A_tx_t + B_t u_t, Q_t)\mathcal{N}(x_t|\hat x_{t|t}, P_{t|t}) dx_t.&lt;/script&gt;

&lt;p&gt;In order to find a closed form solution of this integral, we could simply plug in the corresponding expressions of the Gaussian distributions and solve the integral. Fortunately, Marc Toussaint already gathered the most important &lt;a href=&quot;https://ipvs.informatik.uni-stuttgart.de/mlr/marc/notes/gaussians.pdf&quot;&gt;Gaussian identities&lt;/a&gt;, which will lighten our workload a lot.  To find an expression for our prediction step we can simply use the &lt;em&gt;propagation&lt;/em&gt; formula (Formula 37, Toussaint)&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\int_{y}\mathcal{N}(x|a + Fy, A)\mathcal{N}(y|b,B) dy = \mathcal{N}(x|a + Fb, A + FBF^T ).&lt;/script&gt;

&lt;p&gt;By comparison with our expression, we see that&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{align}
\hat x_{t+1|t} &amp;=  A_t \hat x_{t|t} + B_tu_t \\
P_{t+1|t} &amp;= Q_t + A_t P_{t|t} A_t^T.
\end{align} %]]&gt;&lt;/script&gt;

&lt;h3 id=&quot;update-step&quot;&gt;Update step&lt;/h3&gt;

&lt;p&gt;We will start to simplify the update step&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\mathcal{N}(x_{t}|\hat x_{t|{t}}, P_{t|t} ) = \frac{\mathcal{N}(y_{t}|C_tx_{t}, R_t )\mathcal{N}(x_{t}|\hat x_{t|t-1}, P_{t|t-1})}{\int_{x_{t}}\mathcal{N}(y_{t}|C_tx_{t}, R_t )\mathcal{N}(x_{t}|\hat x_{t|t-1}, P_{t|t-1}) dx_{t}}&lt;/script&gt;

&lt;p&gt;by focussing on the numerator first. We notice that we can rewrite it as a joint distribution (Formula 39, Toussaint)&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\mathcal{N}(x|a,A)\mathcal{N}(y|b + Fx,B) = \mathcal{N}\left(\begin{matrix}x \\y\end{matrix}\middle|\begin{matrix}a\\b + Fa \end{matrix},\begin{matrix}A &amp; A^TF^T\\FA &amp; B + FA^TF^T\end{matrix}\right) . %]]&gt;&lt;/script&gt;

&lt;p&gt;Then again, this joint distribution can be rewritten as&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\mathcal{N}\left(\begin{matrix}x \\y\end{matrix}\middle|\begin{matrix}d\\e \end{matrix},\begin{matrix}D &amp; F\\F^T &amp; E\end{matrix}\right) = \mathcal{N}(y|e,E)\mathcal{N}(x|d + F^TE^{-1}(y-e),D - F^T E^{-1}F) . %]]&gt;&lt;/script&gt;

&lt;p&gt;We can combine the two previous equations to the following expression&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\mathcal{N}(x|a,A)\mathcal{N}(y|b + Fx,B) = \mathcal{N}(y|b + Fa,B + FA^TF^T) \mathcal{N}(x|a + A^TF^T(B + FA^TF^T)^{-1}(y-b -Fa),A - A^TF^T (B + FA^TF^T)^{-1}FA) .&lt;/script&gt;

&lt;p&gt;By comparison with the numerator of our update step, we obtain&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\mathcal{N}(x_{t}|\hat x_{t|t-1}, P_{t|t-1})\mathcal{N}(y_{t}|C_tx_{t}, R_t ) = \mathcal{N}(y_{t}|C_t\hat x_{t|t},R_t + C_tP_{t|t-1}C_t^T)  \mathcal{N}(x_{t}|\hat x_{t|t-1} + P_{t|t-1}C_t^T(R_t + C_tP_{t|t-1}C_t^T)^{-1}(y_{t}-C_t\hat x_{t|t-1}),  P_{t|t-1} - P_{t|t-1}C_t^T (R_t + C_tP_{t|t-1}C_t^T)^{-1}C_tP_{t|t-1}).&lt;/script&gt;

&lt;p&gt;At a first glance, this is not looking like a simplification at all. Conceptually, we only transformed&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\frac{p(y|x)p(x)}{p(y)} \to \frac{p(y,x)}{p(y)} \to \frac{p(x|y)p(y)}{p(y)}.&lt;/script&gt;

&lt;p&gt;If we look closely at the final expression, we see that \(p(y)\) is canceling out. Therefore, the result is simply the remaining part&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\mathcal{N}(x_{t}|\hat x_{t|{t}}, P_{t|t} ) = \mathcal{N}(x_{t}|\hat x_{t|t-1} + P_{t|t-1}C_t^T(R_t + C_tP_{t|t-1}C_t^T)^{-1}(y_{t}-C_t\hat x_{t|t-1}),P_{t|t-1} - P_{t|t-1}C_t^T (R_t + C_tP_{t|t-1}C_t^T)^{-1}C_tP_{t|t-1}).&lt;/script&gt;

&lt;p&gt;If our reasoning is correct the denominator should be equal to \(\mathcal{N}(y_{t}|C_t\hat x_{t|t},R_t + C_tP_{t|t-1}C_t^T)\), which was canceled out. The denominator can be simplified with the &lt;em&gt;propagation&lt;/em&gt; formula (Formula 37, Toussaint)&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\int_{x_{t}}\mathcal{N}(y_{t}|C_tx_{t}, R_t )\mathcal{N}(x_{t}|\hat x_{t|t-1}, P_{t|t-1}) dx_{t} =  \mathcal{N}({y_{t}}|C_t\hat x_{t|t-1}, R_t + C_tP_{t|t-1}C_t^T ).&lt;/script&gt;

&lt;p&gt;Yay! We see, that the denominator is exactly the same as the canceled factor in the numerator.&lt;/p&gt;

&lt;p&gt;Let’s summarize our results:&lt;/p&gt;

&lt;div class=&quot;important_box&quot;&gt;
  &lt;h1&gt;Bayes filter in linear Gaussian state space models&lt;/h1&gt;

  &lt;p&gt;The recursive formula for the Bayes filter in linear Gaussian state space models consists of the &lt;strong&gt;prediction step&lt;/strong&gt;&lt;/p&gt;

  &lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{align}\hat x_{t+1|t} &amp;=  A_t \hat x_{t|t} + B_tu_t \\ 
P_{t+1|t} &amp;= Q_t + A_t P_{t|t} A_t^T  \end{align} %]]&gt;&lt;/script&gt;

  &lt;p&gt;and the &lt;strong&gt;update step&lt;/strong&gt;&lt;/p&gt;

  &lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{align}\hat x_{t|t} &amp;= \hat x_{t|t-1} + P_{t|t-1}C_t^T(R_t + C_tP_{t|t-1}C_t^T)^{-1}(y_{t}-C_t\hat x_{t|t-1}) \\ 
P_{t|t} &amp;= P_{t|t-1} - P_{t|t-1}C_t^T (R_t + C_tP_{t|t-1}C_t^T)^{-1}C_tP_{t|t-1}.  \end{align} %]]&gt;&lt;/script&gt;

&lt;/div&gt;
&lt;p&gt;That’s it! We derived the equations of the Bayes filter in linear Gaussian state space models, which is nothing else but the good old Kalman filter.
In the next section, we will split these equations up to finally obtain the formulation normally used for the Kalman filter.&lt;/p&gt;

&lt;h2 id=&quot;kalman-filter&quot;&gt;Kalman filter&lt;/h2&gt;

&lt;p&gt;In order to obtain the familiar equations of the Kalman filter we have to define&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Innovation&lt;/strong&gt;&lt;/p&gt;

    &lt;script type=&quot;math/tex; mode=display&quot;&gt;z_t = y_{t}-C_t\hat x_{t|t-1}&lt;/script&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Innovation covariance&lt;/strong&gt;&lt;/p&gt;

    &lt;script type=&quot;math/tex; mode=display&quot;&gt;S_t = R_t + C_tP_{t|t-1}C_t^T&lt;/script&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Optimal Kalman gain&lt;/strong&gt;&lt;/p&gt;

    &lt;script type=&quot;math/tex; mode=display&quot;&gt;K_t = P_{t|t-1}C_t^TS_t^{-1}&lt;/script&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;div class=&quot;extra_box&quot;&gt;

  &lt;p&gt;&lt;strong&gt;What is the meaning of \(z_t\) and \(S_t\)?&lt;/strong&gt;&lt;/p&gt;

  &lt;p&gt;The denominator of the update step is&lt;/p&gt;

  &lt;script type=&quot;math/tex; mode=display&quot;&gt;\mathcal{N}(y_{t}|C_t\hat x_{t|t-1},R_t + C_tP_{t|t-1}^TC_t^T)&lt;/script&gt;

  &lt;p&gt;and can be transformed by (Formula 34, Toussaint)&lt;/p&gt;

  &lt;script type=&quot;math/tex; mode=display&quot;&gt;\mathcal{N}(x|a,A) = \mathcal{N}(x+f|a+f,A)&lt;/script&gt;

  &lt;p&gt;to obtain the expression&lt;/p&gt;

  &lt;script type=&quot;math/tex; mode=display&quot;&gt;\mathcal{N}(y_{t} - C_t\hat x_{t|t-1}|0,R_t + C_tP_{t|t-1}^TC_t^T) = \mathcal{N}(z_t|0,S_t).&lt;/script&gt;

  &lt;p&gt;Therefore, the innovation \(z_t\) is the deviation of the expected output and the observed output.
The random variable \(z_t\) has a Gaussian distribution with zero mean and variance \(S_t\).&lt;/p&gt;
&lt;/div&gt;

&lt;p&gt;Let’s plug these definitions into the equations of our update step&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\hat x_{t|t} = \hat x_{t|t-1} + \underbrace{P_{t|t-1}C_t^T(\underbrace{R_t + C_tP_{t|t-1}C_t^T}_{S_t})^{-1}}_{K_t}(\underbrace{y_{t}-C_t\hat x_{t|t-1}}_{z_t})&lt;/script&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;P_{t|t} = P_{t|t-1} - \underbrace{P_{t|t-1}C_t^T(\underbrace{R_t + C_tP_{t|t-1}C_t^T}_{S_t})^{-1}}_{K_t}P_{t|t-1} .&lt;/script&gt;

&lt;p&gt;This leads us to the final equations of the Kalman filter.&lt;/p&gt;

&lt;div class=&quot;important_box&quot;&gt;
  &lt;h1&gt;Equations of the Kalman filter&lt;/h1&gt;

  &lt;p&gt;The recursive formula for the Kalman filter consists of the &lt;strong&gt;prediction step&lt;/strong&gt;&lt;/p&gt;

  &lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{align}\hat x_{t+1|t} &amp;=  A_t \hat x_{t|t} + B_tu_t \\ 
P_{t+1|t} &amp;= Q_t + A_t P_{t|t} A_t^T \end{align} %]]&gt;&lt;/script&gt;

  &lt;p&gt;and the &lt;strong&gt;update step&lt;/strong&gt;&lt;/p&gt;

  &lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{align}
z_t &amp;= y_{t}-C_t\hat x_{t|t-1}\\
S_t &amp;= R_t + C_tP_{t|t-1}C_t^T\\
K_t &amp;= P_{t|t-1}C_t^TS_t^{-1} \\
\hat x_{t|t} &amp;= \hat x_{t|t-1} + K_t z_t\\
P_{t|t} &amp;= (I - K_tC_t)P_{t|t-1}.
\end{align} %]]&gt;&lt;/script&gt;

&lt;/div&gt;

&lt;h2 id=&quot;summary&quot;&gt;Summary&lt;/h2&gt;

&lt;p&gt;This article presented the derivation of the Kalman filter from first principles using Bayesian inference. The goal was to derive the Kalman filter in a clear and straightforward fashion. The steps were designed to be as atomic as possible, in order to be comprehensible for readers, who are not so familiar with the tools we used. Summarized, the derivation was performed in the following four subsequent steps:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;We realized, that we have to calculate \( p(x_{t}|y_0,…,y_t,u_0,…,u_{t-1}) \).&lt;/li&gt;
  &lt;li&gt;Derived the recursive equations of the Bayes filter to efficiently calculate this distribution.&lt;/li&gt;
  &lt;li&gt;Inserted the corresponding distributions of the linear Gaussian state space model.&lt;/li&gt;
  &lt;li&gt;Added some “sugar” to obtain the usual equations of the Kalman filter.&lt;/li&gt;
&lt;/ol&gt;

&lt;script src=&quot;http://localhost:4000/assets/js/d3_graphical_model.js&quot;&gt;&lt;/script&gt;

&lt;script type=&quot;text/javascript&quot; src=&quot;http://localhost:4000/assets/js/svg_mathjax.js&quot;&gt;&lt;/script&gt;

&lt;script type=&quot;text/javascript&quot; src=&quot;https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_SVG&quot;&gt;&lt;/script&gt;

&lt;script type=&quot;text/x-mathjax-config&quot;&gt;

var mq = window.matchMedia( &quot;(max-width: 570px)&quot; );
if (!mq.matches) {
    MathJax.Hub.Config({
	  CommonHTML: { linebreaks: { automatic: true } },
	  &quot;HTML-CSS&quot;: { linebreaks: { automatic: true } },
	         SVG: { linebreaks: { automatic: true } }
	}); 
} 

&lt;/script&gt;

&lt;script type=&quot;text/javascript&quot;&gt;new Svg_MathJax().install();&lt;/script&gt;</content><author><name></name></author><summary type="html">The concept and the equations of the Kalman filter can be quite confusing at the beginning. Often the assumptions are not stated clearly and the equations are just falling from the sky. This post is an attempt to derive the equations of the Kalman filter in a systematic and hopefully understandable way using Bayesian inference. It addresses everyone, who wants to get a deeper understanding of the Kalman filter and is equipped with basic knowledge of linear algebra and probability theory.</summary></entry></feed>