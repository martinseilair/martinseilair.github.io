<!DOCTYPE html>
<html lang="en"><head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1"><!-- Begin Jekyll SEO tag v2.4.0 -->
<title>Optimal Control | Your awesome title</title>
<meta name="generator" content="Jekyll v3.8.0" />
<meta property="og:title" content="Optimal Control" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="Write an awesome description for your new site here. You can edit this line in _config.yml. It will appear in your document head meta (for Google search results) and in your feed.xml site description." />
<meta property="og:description" content="Write an awesome description for your new site here. You can edit this line in _config.yml. It will appear in your document head meta (for Google search results) and in your feed.xml site description." />
<link rel="canonical" href="http://localhost:4000/jekyll/update/2018/05/01/optimal_control.html" />
<meta property="og:url" content="http://localhost:4000/jekyll/update/2018/05/01/optimal_control.html" />
<meta property="og:site_name" content="Your awesome title" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2018-05-01T18:04:07+09:00" />
<script type="application/ld+json">
{"description":"Write an awesome description for your new site here. You can edit this line in _config.yml. It will appear in your document head meta (for Google search results) and in your feed.xml site description.","@type":"BlogPosting","url":"http://localhost:4000/jekyll/update/2018/05/01/optimal_control.html","headline":"Optimal Control","dateModified":"2018-05-01T18:04:07+09:00","datePublished":"2018-05-01T18:04:07+09:00","mainEntityOfPage":{"@type":"WebPage","@id":"http://localhost:4000/jekyll/update/2018/05/01/optimal_control.html"},"@context":"http://schema.org"}</script>
<!-- End Jekyll SEO tag -->
<link rel="stylesheet" href="/assets/main.css"><link type="application/atom+xml" rel="alternate" href="http://localhost:4000/feed.xml" title="Your awesome title" /></head>
<body><header class="site-header" role="banner">

  <div class="wrapper"><a class="site-title" rel="author" href="/">Your awesome title</a><nav class="site-nav">
        <input type="checkbox" id="nav-trigger" class="nav-trigger" />
        <label for="nav-trigger">
          <span class="menu-icon">
            <svg viewBox="0 0 18 15" width="18px" height="15px">
              <path d="M18,1.484c0,0.82-0.665,1.484-1.484,1.484H1.484C0.665,2.969,0,2.304,0,1.484l0,0C0,0.665,0.665,0,1.484,0 h15.032C17.335,0,18,0.665,18,1.484L18,1.484z M18,7.516C18,8.335,17.335,9,16.516,9H1.484C0.665,9,0,8.335,0,7.516l0,0 c0-0.82,0.665-1.484,1.484-1.484h15.032C17.335,6.031,18,6.696,18,7.516L18,7.516z M18,13.516C18,14.335,17.335,15,16.516,15H1.484 C0.665,15,0,14.335,0,13.516l0,0c0-0.82,0.665-1.483,1.484-1.483h15.032C17.335,12.031,18,12.695,18,13.516L18,13.516z"/>
            </svg>
          </span>
        </label>

        <div class="trigger"><a class="page-link" href="/about/">About</a></div>
      </nav></div>
</header>
<main class="page-content" aria-label="Content">
      <div class="wrapper">
        <article class="post h-entry" itemscope itemtype="http://schema.org/BlogPosting">

  <header class="post-header">
    <h1 class="post-title p-name" itemprop="name headline">Optimal Control</h1>
    <p class="post-meta">
      <time class="dt-published" datetime="2018-05-01T18:04:07+09:00" itemprop="datePublished">May 1, 2018
      </time></p>
  </header>

  <div class="post-content e-content" itemprop="articleBody">
    <script src="https://d3js.org/d3.v4.min.js"></script>

<script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js?config=TeX-AMS-MML_HTMLorMML" type="text/javascript"></script>

<p>In this post I want to connect the dots between terms in optimal control.</p>

<p>Hamilton-Jacobi-Bellman equation
Bellman equation
Riccati Equation
Pontryagin’s Maximum Principle 
Control Hamiltonian
Costate Equation
Lagrange Multiplier
Dynamic Programming
Message passing
LQR
Global/trajectory optimal
Backward induction
Open/closed loop</p>

<p>An optimal control problem can be characterized by several properties.</p>
<ul>
  <li>Deterministic/stochastic</li>
  <li>Discrete/continuous time</li>
  <li>Constrained/unconstrained</li>
  <li>Discrete/continuous states</li>
  <li>Discrete/constinuous actions</li>
  <li>Fully/partially observable</li>
  <li>Known/Unknown dynamics</li>
</ul>

<h1 id="hamilton-jacobi-bellman-equation">Hamilton-Jacobi-Bellman equation</h1>

<ul>
  <li>Is a partial differential equation.</li>
  <li>Solution of the HJB is  the value function, which gives minimum cost.</li>
  <li>The Bellman equation is the time discrete version of the Hamilton-Jacobi-Bellman equation.  https://en.wikipedia.org/wiki/Hamilton%E2%80%93Jacobi%E2%80%93Bellman_equation</li>
  <li>When solved
    <ul>
      <li>Locally: HJB is a necessary condition</li>
      <li>Globally: necessary and sufficicent condition for an optimum</li>
      <li><span style="color:red">What does it mean, to solve locally or globally?</span></li>
    </ul>
  </li>
  <li>can be generalized to stoachstic systems</li>
</ul>

<p>For optimal control problem</p>

<script type="math/tex; mode=display">V(x(0),0) = \min_u \left\{\int_0^T C(x(t),u(t))dt + D(x(T)) \right\}</script>

<p>with the constraint</p>

<script type="math/tex; mode=display">\dot{x}(t) = F(x(t),u(t))</script>

<p>the HJB equation is</p>

<script type="math/tex; mode=display">\dot{V}(x,t) + \min_u \left\{\nabla V(x,t) F(x,u) + C(x,u) \right\}= 0</script>

<p>with the terminal condition</p>

<script type="math/tex; mode=display">V(x,T) = D(x).</script>

<p>\( V(x,t) \) is the value function.</p>

<p>The formula can be derived with the help of the principle of optimality:</p>

<p><script type="math/tex">V(x(t),t) = \min_u \left\{V(x(t + dt), t + dt) + \int_t^{t+dt} C(x(t),u(t))dt \right\}</script>.</p>

<p>The variable \(dt\) is not infinitesimal yet.</p>

<p>The value function at time \(t\) is defined recursively as: Every control signal \(u\) is leading to another state and is connected with a cost. For all possible control signals, add the corresponding cost and the value function of the state. Choose the control signal, for which this sum is minimized.</p>

<p>Taylor expansion of \( V(x(t + dt), t + dt)\) leads to</p>

<script type="math/tex; mode=display">V(x(t + dt), t + dt) = V(x(t),t) + \dot{V}(x(t),t)dt + \nabla V(x(t),t)\dot{x}(t)dt + o(dt^2).</script>

<p>Derivation:</p>

<p>Given the function \(V(x(t), t)\) you choose the operating point \(t\) and new variable \(dt\).</p>

<script type="math/tex; mode=display">f(dt) = V(x(t),t) + \frac{dV(x(t),t)}{d t}\|_{t = t} (t + dt - t) + o(dt^2)</script>

<script type="math/tex; mode=display">f(dt) = V(x(t),t) + \frac{(\frac{\partial V}{\partial x}\frac{\partial x}{\partial t} + \frac{\partial V}{\partial t})dt}{d t}\|_{t = t} dt + o(dt^2)</script>

<script type="math/tex; mode=display">f(dt) = V(x(t),t) + \frac{\partial V}{\partial x}\frac{\partial x}{\partial t}dt + \frac{\partial V}{\partial t}dt + o(dt^2)</script>

<script type="math/tex; mode=display">f(dt) = V(x(t),t) + \nabla V(x(t),t)\dot{x}(t)dt + \dot{V}(x(t),t)dt + o(dt^2)</script>

<p>Insert the result in the optimality equation</p>

<script type="math/tex; mode=display">V(x(t),t) = \min_u \left\{V(x(t),t) + \nabla V(x(t),t)\dot{x}(t)dt + \dot{V}(x(t),t)dt + o(dt^2) + \int_t^{t+dt} C(x(t),u(t))dt \right\}.</script>

<p>\(V(x(t),t)\) is cancled out.</p>

<script type="math/tex; mode=display">0 = \min_u \left\{\nabla V(x(t),t)\dot{x}(t)dt + \dot{V}(x(t),t)dt + o(dt^2) + \int_t^{t+dt} C(x(t),u(t))dt \right\}.</script>

<p>Divided by \(dt\)</p>

<script type="math/tex; mode=display">0 = \min_u \left\{\nabla V(x(t),t)\dot{x}(t) + \dot{V}(x(t),t) + o(dt) + \frac{1}{dt}\int_t^{t+dt} C(x(t),u(t))dt \right\}.</script>

<p>Take the limit as \(dt\) apporaches zero.</p>

<p><script type="math/tex">0 = \min_u \left\{\nabla V(x(t),t)\dot{x}(t) + \dot{V}(x(t),t) + C(x(t),u(t)) \right\}.</script>
<span style="color:red">Why can you take \(\dot{V}(x(t),t)\) out of the min but not \(\nabla V(x(t),t)\dot{x}(t)\) </span>  <span style="color:green">Because \(\dot{V}(x(t),t)\)  is independent of the the control signal?</span></p>

<h1 id="linear-quadratic-gaussian-lqg-control">Linear-quadratic-Gaussian (LQG) control</h1>

<ul>
  <li>Combination of
    <ul>
      <li>Kalman Filter (linear-quadratic estimator LQE)</li>
      <li>Linear-quadratic regulator (LQR)</li>
    </ul>
  </li>
  <li>LQE and LQR can be computed independently because of the separation principle.</li>
  <li>Applies in LTI and LTV</li>
</ul>

<h1 id="linear-quadratic-regulator-lqr">Linear-quadratic regulator (LQR)</h1>

<h1 id="sepration-principle">Sepration principle</h1>

<ul>
  <li>Known as principle of separation of estimation and control.</li>
  <li>Does not hold for non-linear systems</li>
</ul>

<h1 id="kalman-filter-or-linear-quadratic-estimator-lqe">Kalman filter or linear-quadratic estimator (LQE)</h1>

<p>Assume you have a system</p>

<script type="math/tex; mode=display">x_{t+1} = A_tx_t + B_t u_t + w_t</script>

<script type="math/tex; mode=display">y_t = C_tx_t + v_t</script>

<p>with process noise \( w_t \sim \mathcal{N}(0, Q_t) \) and observation noise \( v_t \sim \mathcal{N}(0, R_t) \).
The posteriori state estimate is denoted as \(\hat x_{t|t}\) and the posteriori error covariance as \( P_{t|t}\). The posteriori is therefore defined as \( \mathcal{N}(\hat x_{t|t}, P_{t|t}) \).</p>

<p>In the <em>predict step</em> the current estimate is transformed by the system dynamics (marginalization of \(x_t\)):</p>

<script type="math/tex; mode=display">\mathcal{N}(x_{t+1}|\hat x_{t+1|t}, P_{t+1|t})  = \int_{x_t}\mathcal{N}(x_{t+1}|A_tx_t + B_t u_t, Q_t)\mathcal{N}(x_t|\hat x_{t|t}, P_{t|t}) dx_t.</script>

<p>With the <em>propagation</em> formula (37, Toussaint)</p>

<script type="math/tex; mode=display">\int_{y}\mathcal{N}(x|a + Fy, A)\mathcal{N}(y|b,B) dx_t = \mathcal{N}(x|a + Fb, A + FBF^T )</script>

<p>it follows</p>

<script type="math/tex; mode=display">\hat x_{t+1|t} =  A_t \hat x_{t|t} + B_tu_t</script>

<script type="math/tex; mode=display">P_{t+1|t} = Q_t + A_t P_{t|t} A_t^T  .</script>

<p>The <em>update step</em> updates the estimate according to observations \(y_t\). This step is simply Bayes rule applied.</p>

<script type="math/tex; mode=display">p(x|y) = \frac{p(y|x)p(x)}{p(y)}</script>

<script type="math/tex; mode=display">\mathcal{N}(x_{t+1}|\hat x_{t+1|t}, P_{t+1|t+1} ) = \frac{\mathcal{N}(y_{t+1}|C_tx_{t+1}, R_t )\mathcal{N}(x_{t+1}|\hat x_{t+1|t}, P_{t+1|t})}{\int_{x_{t+1}}\mathcal{N}(y_{t+1}|C_tx_{t+1}, R_t )\mathcal{N}(x_{t+1}|\hat x_{t+1|t}, P_{t+1|t}) dx_{t+1}}</script>

<p>The numerator can be rewritten as a joint distribution (39, Toussaint)</p>

<script type="math/tex; mode=display">% <![CDATA[
\mathcal{N}(x|a,A)\mathcal{N}(y|b + Fx,B) = \mathcal{N}\left(\begin{matrix}x \\y\end{matrix}\middle|\begin{matrix}a\\b + Fa \end{matrix},\begin{matrix}A & A^TF^T\\FA & B + FA^TF^T\end{matrix}\right) %]]></script>

<p>This joint distribution can be rewritten as</p>

<script type="math/tex; mode=display">% <![CDATA[
\mathcal{N}\left(\begin{matrix}x \\y\end{matrix}\middle|\begin{matrix}a\\b \end{matrix},\begin{matrix}A & C\\C^T & B\end{matrix}\right) = \mathcal{N}(y|b,B)\mathcal{N}(x|a + C^TB^{-1}(y-b),A - C^T B^{-1}C) %]]></script>

<p>In total this gives</p>

<script type="math/tex; mode=display">\mathcal{N}(x|a,A)\mathcal{N}(y|b + Fx,B) = \mathcal{N}(y|b + Fa,B + FA^TF^T)\mathcal{N}(x|a + A^TF^T(B + FA^TF^T)^{-1}(y-b -Fa),A - A^TF^T (B + FA^TF^T)^{-1}FA)</script>

<p>It follows</p>

<script type="math/tex; mode=display">\mathcal{N}(x_{t+1}|\hat x_{t+1|t}, P_{t+1|t})\mathcal{N}(y_{t+1}|C_tx_{t+1}, R_t ) = \mathcal{N}(y_{t+1}|C_t\hat x_{t+1|t},R_t + C_tP_{t+1|t}^TC_t^T)\mathcal{N}(x_{t+1}|\hat x_{t+1|t} + P_{t+1|t}^TC_t^T(R_t + C_tP_{t+1|t}^TC_t^T)^{-1}(y_{t+1}-C_t\hat x_{t+1}),P_{t+1|t} - P_{t+1|t}^TC_t^T (R_t + C_tP_{t+1|t}^TC_t^T)^{-1}C_tP_{t+1|t}).</script>

<p>The denominator can be further simplified also with the <em>propagation</em> formula (37, Toussaint)</p>

<script type="math/tex; mode=display">\int_{x_{t+1}}\mathcal{N}(y_{t+1}|C_tx_{t+1}, R_t )\mathcal{N}(x_{t+1}|\hat x_{t+1|t}, P_{t+1|t}) dx_{t+1} =  \int_{x_{t+1}}\mathcal{N}(x|C_ty, A)\mathcal{N}(y|b,B) dx_t = \mathcal{N}({y_{t+1}}|C_t\hat x_{t+1|t}, R_t + C_tP_{t+1|t}C_t^T ).</script>

<p>Therefore,</p>

<script type="math/tex; mode=display">\mathcal{N}(x_{t+1}|\hat x_{t+1|t}, P_{t+1|t+1} ) = \frac{\mathcal{N}(y_{t+1}|C_t\hat x_{t+1|t},R_t + C_tP_{t+1|t}^TC_t^T)\mathcal{N}(x_{t+1}|\hat x_{t+1|t} + P_{t+1|t}^TC_t^T(R_t + C_tP_{t+1|t}^TC_t^T)^{-1}(y_{t+1}-C_t\hat x_{t+1}),P_{t+1|t} - P_{t+1|t}^TC_t^T (R_t + C_tP_{t+1|t}^TC_t^T)^{-1}C_tP_{t+1|t})}{\mathcal{N}({y_{t+1}}|C_t\hat x_{t+1|t}, R_t + C_tP_{t+1|t}C_t^T )}</script>

<p>becomes</p>

<script type="math/tex; mode=display">\mathcal{N}(x_{t+1}|\hat x_{t+1|t}, P_{t+1|t+1} ) = \mathcal{N}(x_{t+1}|\hat x_{t+1|t} + P_{t+1|t}^TC_t^T(R_t + C_tP_{t+1|t}^TC_t^T)^{-1}(y_{t+1}-C_t\hat x_{t+1}),P_{t+1|t} - P_{t+1|t}^TC_t^T (R_t + C_tP_{t+1|t}^TC_t^T)^{-1}C_tP_{t+1|t}) .</script>

<script type="math/tex; mode=display">\hat x_{t+1|t+1} = \hat x_{t+1|t} + P_{t+1|t}^TC_t^T(R_t + C_tP_{t+1|t}^TC_t^T)^{-1}(y_{t+1}-C_t\hat x_{t+1})</script>

<script type="math/tex; mode=display">P_{t+1|t+1} = P_{t+1|t} - P_{t+1|t}^TC_t^T (R_t + C_tP_{t+1|t}^TC_t^T)^{-1}C_tP_{t+1|t}</script>

<p>Define \(S_t = R_t + C_tP_{t+1|t}C_t^T\), \(K_t = P_{t+1|t}C_t^TS_t^{-1} \) and \( z_t = y_{t+1}-C_t\hat x_{t+1|t}\).</p>

<script type="math/tex; mode=display">\hat x_{t+1|t+1} = \hat x_{t+1|t} + K_t z_t</script>

<script type="math/tex; mode=display">P_{t+1|t+1} = (I - P_{t+1|t}^TC_t^T (R_t + C_tP_{t+1|t}^TC_t^T)^{-1}C_t)P_{t+1|t} = (I - K_tC_t)P_{t+1|t}</script>

<p>Predict and summary step together:</p>

<p>Define \(S_t = R_t + C_t(Q_t + A_t P_{t|t} A_t^T)C_t^T\), \(K_t = (Q_t + A_t P_{t|t} A_t^T)C_t^TS_t^{-1} \) and \( z_t = y_{t+1}-C_t(A_t \hat x_{t|t} + B_tu_t))\).</p>

<script type="math/tex; mode=display">\hat x_{t+1|t+1} = \hat x_{t+1|t}  + K_t (y_{t+1}-C_t\hat x_{t+1|t}) = (I - K_tC_t)x_{t+1|t} + K_ty_{t+1} = (I - K_tC_t)(A_t \hat x_{t|t} + B_tu_t) + K_ty_{t+1} =  (I - K_tC_t)A_t \hat x_{t|t} + (I - K_tC_t)B_tu_t + K_ty_{t+1}</script>

<script type="math/tex; mode=display">P_{t+1|t+1} = (I - K_tC_t)(Q_t + A_t P_{t|t} A_t^T)</script>

<p>What is the meaning of \(z_t\) and \(S_t\)? The denominator of the update step is</p>

<script type="math/tex; mode=display">\mathcal{N}(y_{t+1}|C_t\hat x_{t+1|t},R_t + C_tP_{t+1|t}^TC_t^T)</script>

<p>and can be transformed by (34, Toussaint)</p>

<script type="math/tex; mode=display">\mathcal{N}(x|a,A) = \mathcal{N}(x+f|a+f,A)</script>

<p>to</p>

<script type="math/tex; mode=display">\mathcal{N}(y_{t+1} - C_t\hat x_{t+1|t}|0,R_t + C_tP_{t+1|t}^TC_t^T).</script>

<p>Therefore, \(z_t\) gives you the derivation of the expected observation and the real observation.
The random variable \(z_t\) has therefore zero mean. \(S_t\) is simply the variance of the expected output.</p>

<p>How does the formulas of the estimator degrade, if you assume a deterministic system (zero variance).</p>

<script type="math/tex; mode=display">S_t = C_tP_{t+1|t} C_t^T</script>

<script type="math/tex; mode=display">K_t = P_{t+1|t} C_t^T(C_tP_{t+1|t} C_t^T)^{-1}</script>

<script type="math/tex; mode=display">(I - K_tC_t)(A_t \hat x_{t|t} + B_tu_t) + K_ty_{t+1}</script>

<script type="math/tex; mode=display">(I - K_tC_t)(A_t \hat x_{t|t} + B_tu_t) + K_t C_t x_{t+1}</script>

<script type="math/tex; mode=display">(I - P_{t+1|t} C_t^T(C_tP_{t+1|t} C_t^T)^{-1}C_t)\hat x_{t|t+1} + P_{t+1|t} C_t^T(C_tP_{t+1|t} C_t^T)^{-1} y_{t+1}</script>

<p>IST WAHRSCHEINLICH FALSCH!</p>

<p>WEIGHTED NULLSPACE PROJECTION!!!!!  If not, it’s a weighting of old and new. Special cases :</p>

<p>If \(P_{t+1|t}\) is zero: Old estimate is preserved.</p>

<ul>
  <li>\(P_{t+1|t}\) is diagonal.
    <ul>
      <li>If \(P_{t+1|t}^{ii}\) is inifinity: If this dimension is in the nullspace of C, than this value will be solely based on the observation. If not it will be zero.</li>
      <li>If \(P_{t+1|t}^{ii}\) is 1: If this dimension is in the nullspace of C, the estimate of the observation will be taken over. Otherwise it will be the old estimate.</li>
      <li>If \(P_{t+1|t}^{ii}\) is less than 1: Compromise between old and new estimate. More weight for the old estimate.</li>
      <li>If \(P_{t+1|t}^{ii}\) is greather than 1: Compromise between old and new estimate. More weight for the new estimate.</li>
    </ul>
  </li>
  <li>\(P_{t+1|t}\) is not diagonal. Even if a dimension is not in the nullspace of C, through the coupling you can also update the other dimensions. Effectively this could be treated as a transformation of C. You make an LDL transformation of \(P_{t+1|t} = L_{t+1|t} D_{t+1|t}L_{t+1|t}^T\). Then \(\tilde C_{t+1|t} = C_{t+1|t}L_t\) is the transformed (whitened?) observation matrix. The function becomes</li>
</ul>

<script type="math/tex; mode=display">(I - L_{t+1|t} D_{t+1|t} \tilde C_t^T(\tilde C_tD_{t+1|t} \tilde C_t^T)^{-1})\hat x_{t|t+1} + L_{t+1|t} D_{t+1|t} \tilde C_t^T(\tilde C_tD_{t+1|t} \tilde C_t^T)^{-1} x_{t+1}</script>

<h1 id="bayes-rule-for-deterministic-linear-dynamical-system-but-unknown-initial-state">Bayes rule for deterministic linear dynamical system, but unknown initial state.</h1>

<script type="math/tex; mode=display">p(x|y) = \frac{p(y|x)p(x)}{p(y)}</script>

<script type="math/tex; mode=display">\mathcal{N}(x|\hat a, \hat A ) = \frac{\mathcal{N}(y|b + Fx,B)\mathcal{N}(x|a,A)}{\int_{x}\mathcal{N}(y|b + Fx,B)\mathcal{N}(x|a,A) dx}</script>

<p>The numerator can be rewritten as a joint distribution (39, Toussaint)</p>

<script type="math/tex; mode=display">% <![CDATA[
\mathcal{N}(y|b + Fx,B)\mathcal{N}(x|a,A) = \mathcal{N}\left(\begin{matrix}x \\y\end{matrix}\middle|\begin{matrix}a\\b + Fa \end{matrix},\begin{matrix}A & A^TF^T\\FA & B + FA^TF^T\end{matrix}\right) %]]></script>

<p>This joint distribution can be rewritten as</p>

<script type="math/tex; mode=display">% <![CDATA[
\mathcal{N}\left(\begin{matrix}x \\y\end{matrix}\middle|\begin{matrix}a\\b \end{matrix},\begin{matrix}A & C\\C^T & B\end{matrix}\right) = \mathcal{N}(y|b,B)\mathcal{N}(x|a + C^TB^{-1}(y-b),A - C^T B^{-1}C) %]]></script>

<p>In total this gives</p>

<script type="math/tex; mode=display">\mathcal{N}(y|b + Fx,B)\mathcal{N}(x|a,A) = \mathcal{N}(y|b + Fa,B + FA^TF^T)\mathcal{N}(x|a + A^TF^T(B + FA^TF^T)^{-1}(y-b -Fa),A - A^TF^T (B + FA^TF^T)^{-1}FA)</script>

<p>The denominator can be further simplified also with the <em>propagation</em> formula (37, Toussaint)</p>

<script type="math/tex; mode=display">\int_x \mathcal{N}(y|b + Fx,B)\mathcal{N}(x|a,A) dx  = \mathcal{N}(y|Fa + b, B + FAF^T)</script>

<p>The whole Bayesian expression will be</p>

<script type="math/tex; mode=display">\mathcal{N}(x|\hat a, \hat A ) = \mathcal{N}(x|a + A^TF^T(B + FA^TF^T)^{-1}(y-b -Fa),A - A^TF^T (B + FA^TF^T)^{-1}FA)</script>

<p>Now assume deterministic observation without offset</p>

<script type="math/tex; mode=display">\mathcal{N}(x|\hat a, \hat A ) = \mathcal{N}(x|a + A^TF^T(FA^TF^T)^{-1}(y-Fa),A - A^TF^T (FA^TF^T)^{-1}FA)</script>

<script type="math/tex; mode=display">\hat a = a + A^TF^T(FA^TF^T)^{-1}(y-Fa) = (I - A^TF^T(FA^TF^T)^{-1}F)a + A^TF^T(FA^TF^T)^{-1}y</script>

<script type="math/tex; mode=display">\hat A = (I - A^TF^T (FA^TF^T)^{-1}F)A + (A^TF^T (FA^TF^T)^{-1}F) 0</script>

<h1 id="information-step">Information step</h1>

<p>If I take an action this will update my estimate of the belief of the observation. Certain observations are giving more information than others. I should try to increase the probability of these observations.
For control problem: Only those observations should have higher probability, which are important for my policy.</p>

<script type="math/tex; mode=display">a_t^* = \mathrm{argmax}_{a_t} \mathbb{E}_{p(o_{t+1}|a_t)}[ D_{KL}(b(s_t)\|b(s_{t+1}|o_{t+1}, a_t))]</script>

<script type="math/tex; mode=display">b(s_{t+1}|o_{t+1}, a_t) = \frac{p(o_{t+1}|s_{t+1})\int_{s_t}p(s_{t+1}|s_t,a_t)b(s_t)ds_t}{p(o_{t+1}|a_t)}</script>

<p>with</p>

<script type="math/tex; mode=display">p(o_{t+1}|a_t) = \int_{s_{t+1}} p(o_{t+1}|s_{t+1})\int_{s_t}p(s_{t+1}|s_t,a_t)b(s_t)ds_t ds_{t+1} .</script>

<p>The distributions depend on \(s_t\) and \(s_{t+1}\). Is this a reasonable approach? Or should I just try to minimize the entropy of the new state?</p>

<script type="math/tex; mode=display">a_t^* = \mathrm{argmax}_{a_t} \mathbb{E}_{p(o_{t+1}|a_t)}[ -H(b(s_{t+1}|o_{t+1}, a_t))]</script>

<script type="math/tex; mode=display">-H(b(s_{t+1}|o_{t+1}, a_t)) = \int_{s_{t+1}} b(s_{t+1}|o_{t+1}, a_t) \log(b(s_{t+1}|o_{t+1}, a_t))  d_{s_{t+1}}</script>

<script type="math/tex; mode=display">-H(b(s_{t+1}|o_{t+1}, a_t)) = \int_{s_{t+1}} \frac{p(o_{t+1}|s_{t+1})\int_{s_t}p(s_{t+1}|s_t,a_t)b(s_t)ds_t}{p(o_{t+1}|a_t)} \log\left(\frac{p(o_{t+1}|s_{t+1})\int_{s_t}p(s_{t+1}|s_t,a_t)b(s_t)ds_t}{p(o_{t+1}|a_t)}\right)  d_{s_{t+1}}</script>

<script type="math/tex; mode=display">-H(b(s_{t+1}|o_{t+1}, a_t)) = \frac{1}{p(o_{t+1}|a_t)}\int_{s_{t+1}} p(o_{t+1}|s_{t+1})\int_{s_t}p(s_{t+1}|s_t,a_t)b(s_t)ds_t \log\left(\frac{p(o_{t+1}|s_{t+1})\int_{s_t}p(s_{t+1}|s_t,a_t)b(s_t)ds_t}{p(o_{t+1}|a_t)}\right)  d_{s_{t+1}}</script>

<script type="math/tex; mode=display">-H(b(s_{t+1}|o_{t+1}, a_t)) = \frac{1}{p(o_{t+1}|a_t)} D_{KL}\left(p(o_{t+1}|s_{t+1})\int_{s_t}p(s_{t+1}|s_t,a_t)b(s_t)ds_t\|p(o_{t+1}|a_t)\right)</script>

<script type="math/tex; mode=display">-H(b(s_{t+1}|o_{t+1}, a_t)) = \frac{1}{p(o_{t+1}|a_t)}\int_{s_{t+1}} p(o_{t+1}|s_{t+1})\int_{s_t}p(s_{t+1}|s_t,a_t)b(s_t)ds_t \left(\log\left(p(o_{t+1}|s_{t+1})\int_{s_t}p(s_{t+1}|s_t,a_t)b(s_t)ds_t\right) + \log\left(p(o_{t+1}|a_t)\right)\right)  d_{s_{t+1}}</script>

<script type="math/tex; mode=display">-H(b(s_{t+1}|o_{t+1}, a_t)) = \frac{1}{p(o_{t+1}|a_t)}\int_{s_{t+1}} p(o_{t+1}|s_{t+1})\int_{s_t}p(s_{t+1}|s_t,a_t)b(s_t)ds_t \log\left(p(o_{t+1}|s_{t+1})\int_{s_t}p(s_{t+1}|s_t,a_t)b(s_t)ds_t\right)  d_{s_{t+1}} + \frac{1}{p(o_{t+1}|a_t)}\int_{s_{t+1}} p(o_{t+1}|s_{t+1})\int_{s_t}p(s_{t+1}|s_t,a_t)b(s_t)ds_t \log\left(p(o_{t+1}|a_t)\right)  d_{s_{t+1}}</script>

<script type="math/tex; mode=display">-H(b(s_{t+1}|o_{t+1}, a_t)) = \frac{1}{p(o_{t+1}|a_t)}\int_{s_{t+1}} p(o_{t+1}|s_{t+1})\int_{s_t}p(s_{t+1}|s_t,a_t)b(s_t)ds_t \log\left(p(o_{t+1}|s_{t+1})\int_{s_t}p(s_{t+1}|s_t,a_t)b(s_t)ds_t\right)  d_{s_{t+1}} + \frac{\log\left(p(o_{t+1}|a_t)\right)}{p(o_{t+1}|a_t)}\underbrace{\int_{s_{t+1}} p(o_{t+1}|s_{t+1})\int_{s_t}p(s_{t+1}|s_t,a_t)b(s_t)ds_t   d_{s_{t+1}}}_{p(o_{t+1}|a_t)}</script>

<script type="math/tex; mode=display">-H(b(s_{t+1}|o_{t+1}, a_t)) = \frac{1}{p(o_{t+1}|a_t)}\int_{s_{t+1}} p(o_{t+1}|s_{t+1})\int_{s_t}p(s_{t+1}|s_t,a_t)b(s_t)ds_t \log\left(p(o_{t+1}|s_{t+1})\int_{s_t}p(s_{t+1}|s_t,a_t)b(s_t)ds_t\right)  d_{s_{t+1}} + \log\left(p(o_{t+1}|a_t)\right)</script>

<script type="math/tex; mode=display">\mathbb{E}_{p(o_{t+1}|a_t)}[ -H(b(s_{t+1}|o_{t+1}, a_t))] = \int_{o_{t+1}} p(o_{t+1}|a_t)\left[\frac{1}{p(o_{t+1}|a_t)}\int_{s_{t+1}} p(o_{t+1}|s_{t+1})\int_{s_t}p(s_{t+1}|s_t,a_t)b(s_t)ds_t \log\left(p(o_{t+1}|s_{t+1})\int_{s_t}p(s_{t+1}|s_t,a_t)b(s_t)ds_t\right)  d_{s_{t+1}} + \log\left(p(o_{t+1}|a_t)\right) \right] do_{t+1}</script>

<script type="math/tex; mode=display">\mathbb{E}_{p(o_{t+1}|a_t)}[ -H(b(s_{t+1}|o_{t+1}, a_t))] = \int_{o_{t+1}} \int_{s_{t+1}} p(o_{t+1}|s_{t+1})\int_{s_t}p(s_{t+1}|s_t,a_t)b(s_t)ds_t \log\left(p(o_{t+1}|s_{t+1})\int_{s_t}p(s_{t+1}|s_t,a_t)b(s_t)ds_t\right)  d_{s_{t+1}} + p(o_{t+1}|a_t)\log\left(p(o_{t+1}|a_t)\right)  do_{t+1}</script>

<script type="math/tex; mode=display">\mathbb{E}_{p(o_{t+1}|a_t)}[ -H(b(s_{t+1}|o_{t+1}, a_t))] =  \int_{s_{t+1}} \int_{s_t}p(s_{t+1}|s_t,a_t)b(s_t)ds_t \int_{o_{t+1}}p(o_{t+1}|s_{t+1}) \log\left(p(o_{t+1}|s_{t+1})\int_{s_t}p(s_{t+1}|s_t,a_t)b(s_t)ds_t\right)  do_{t+1}d_{s_{t+1}} + \int_{o_{t+1}}p(o_{t+1}|a_t)\log\left(p(o_{t+1}|a_t)\right)  do_{t+1}</script>

<script type="math/tex; mode=display">\mathbb{E}_{p(o_{t+1}|a_t)}[ -H(b(s_{t+1}|o_{t+1}, a_t))] =  \int_{s_{t+1}} \int_{s_t}p(s_{t+1}|s_t,a_t)b(s_t)ds_t \int_{o_{t+1}}p(o_{t+1}|s_{t+1}) \left(\log\left(p(o_{t+1}|s_{t+1})\right) + \log\left(\int_{s_t}p(s_{t+1}|s_t,a_t)b(s_t)ds_t \right) \right) do_{t+1}d_{s_{t+1}} + \int_{o_{t+1}}p(o_{t+1}|a_t)\log\left(p(o_{t+1}|a_t)\right)  do_{t+1}</script>

<script type="math/tex; mode=display">\mathbb{E}_{p(o_{t+1}|a_t)}[ -H(b(s_{t+1}|o_{t+1}, a_t))] =  \int_{s_{t+1}} \int_{s_t}p(s_{t+1}|s_t,a_t)b(s_t)ds_t \int_{o_{t+1}}p(o_{t+1}|s_{t+1}) \log\left(p(o_{t+1}|s_{t+1})\right)  do_{t+1}d_{s_{t+1}} + \int_{s_{t+1}} \int_{s_t}p(s_{t+1}|s_t,a_t)b(s_t)ds_t \int_{o_{t+1}}p(o_{t+1}|s_{t+1}) \log\left(\int_{s_t}p(s_{t+1}|s_t,a_t)b(s_t)ds_t \right) do_{t+1}d_{s_{t+1}} + \int_{o_{t+1}}p(o_{t+1}|a_t)\log\left(p(o_{t+1}|a_t)\right)  do_{t+1}</script>

<script type="math/tex; mode=display">\mathbb{E}_{p(o_{t+1}|a_t)}[ -H(b(s_{t+1}|o_{t+1}, a_t))] =  \int_{s_{t+1}} \int_{s_t}p(s_{t+1}|s_t,a_t)b(s_t)ds_t \int_{o_{t+1}}p(o_{t+1}|s_{t+1}) \log\left(p(o_{t+1}|s_{t+1})\right)  do_{t+1}d_{s_{t+1}} + \int_{s_{t+1}} \int_{s_t}p(s_{t+1}|s_t,a_t)b(s_t)ds_t \log\left(\int_{s_t}p(s_{t+1}|s_t,a_t)b(s_t)ds_t \right) \underbrace{\int_{o_{t+1}}p(o_{t+1}|s_{t+1})  do_{t+1}}_{=1}d_{s_{t+1}} + \int_{o_{t+1}}p(o_{t+1}|a_t)\log\left(p(o_{t+1}|a_t)\right)  do_{t+1}</script>

<script type="math/tex; mode=display">\mathbb{E}_{p(o_{t+1}|a_t)}[ -H(b(s_{t+1}|o_{t+1}, a_t))] =  -\int_{s_{t+1}} \int_{s_t}p(s_{t+1}|s_t,a_t)b(s_t)ds_t H[p(o_{t+1}|s_{t+1})]d_{s_{t+1}} - H[\int_{s_t}p(s_{t+1}|s_t,a_t)b(s_t)ds_t] - H[p(o_{t+1}|a_t)]</script>

<script type="math/tex; mode=display">\mathbb{E}_{p(o_{t+1}|a_t)}[ -H(b(s_{t+1}|o_{t+1}, a_t))] =  -\int_{s_{t+1}} p(s_{t+1}|a_t) H[o_{t+1}|s_{t+1}]d_{s_{t+1}} - H[s_{t+1}|a_t] - H[o_{t+1}|a_t]</script>

<p>Assume Linear model from Kalman Filter:</p>

<script type="math/tex; mode=display">H(b(s_{t+1}|o_{t+1}, a_t)) = \frac{1}{2}\log \det (2\pi e P_{t+1|t+1})</script>

<script type="math/tex; mode=display">H(b(s_{t+1}|o_{t+1}, a_t)) = \frac{1}{2}\log \det (2\pi e (I - P_{t+1|t}^TC_t^T (R_t + C_tP_{t+1|t}^TC_t^T)^{-1}C_t)P_{t+1|t} ))</script>

<p>Entropy of belief state is independent of observation and action! Actions are not used for getting better information. There is no trade off between an reward maximizing step and information step. Every action gives you the same amount of information. Separation principle: Actions are just for reducing controller cost, only the mean of the information state is used, it does not depend on the variance.</p>

<h1 id="kalman-filter-for-continuous-time-systems">Kalman-Filter for continuous-time systems</h1>

<h1 id="bayes-filter-for-general-continuous-time-systems">Bayes-Filter for general continuous-time systems</h1>

<h1 id="observability-in-general-continuous-time-systems">Observability in general continuous-time systems</h1>

<h1 id="linear-dynamical-system-with-arbitrary-state-distribution">Linear dynamical system with arbitrary state distribution</h1>

<h1 id="observability-in-discrete-linear-dynamical-systems">Observability in discrete linear dynamical systems</h1>

<p>The Kalman filter is only updating the current state. But with the new information also old states can be updated.</p>

<p>In order to update past states you have to send messages backwards. These messages are again calculated locally:</p>

<script type="math/tex; mode=display">m(x_{t};d_t, D_t) = \int_{x_{t+1}} \mathcal{N}(x_{t+1}|Ax_t + B u_t, Q_t) m(x_{t+1};d_{t+1}, D_{t+1})  dx_{t+1}  \mathcal{N}(y_{t}|C_tx_{t}, R_t)</script>

<p>The first message is</p>

<script type="math/tex; mode=display">m(x_T;d_T, D_T) = \frac{\mathcal{N}(y_T|C_Tx_T, R_T)\mathcal{N}(x_T|a, \infty)}{\int_{x_T}\mathcal{N}(y_T|C_Tx_T, R_T)\mathcal{N}(x_T|a, \infty)d_{x_T}} = \mathcal{N}(x|a + \infty^TC_T^T(R_T + C_T\infty^TC_T^T)^{-1}(y_T-C_Ta),\infty - \infty^TC_T^T (R_T + C_T\infty^TC_T^T)^{-1}C_T\infty)</script>

<script type="math/tex; mode=display">d_T = a + \infty^TC_T^T(R_T + C_T\infty^TC_T^T)^{-1}(y_T-C_Ta) = a + IC_T^T(\frac{1}{\infty}R_T + C_TIC_T^T)^{-1}(y_T-C_Ta) = a + C_T^T(C_TC_T^T)^{-1}(y_T-C_Ta) =  C_T^T(C_TC_T^T)^{-1}y_T</script>

<script type="math/tex; mode=display">D_T = \infty - \infty^TC_T^T (R_T + C_T\infty^TC_T^T)^{-1}C_T\infty = \infty - \infty^TC_T^T (R_T + C_T\infty^TC_T^T)^{-1}C_T\infty</script>


  </div><a class="u-url" href="/jekyll/update/2018/05/01/optimal_control.html" hidden></a>
</article>

      </div>
    </main><footer class="site-footer h-card">
  <data class="u-url" href="/"></data>

  <div class="wrapper">

    <h2 class="footer-heading">Your awesome title</h2>

    <div class="footer-col-wrapper">
      <div class="footer-col footer-col-1">
        <ul class="contact-list">
          <li class="p-name">Your awesome title</li><li><a class="u-email" href="mailto:your-email@example.com">your-email@example.com</a></li></ul>
      </div>

      <div class="footer-col footer-col-2"><ul class="social-media-list"><li><a href="https://github.com/jekyll"><svg class="svg-icon"><use xlink:href="/assets/minima-social-icons.svg#github"></use></svg> <span class="username">jekyll</span></a></li><li><a href="https://www.twitter.com/jekyllrb"><svg class="svg-icon"><use xlink:href="/assets/minima-social-icons.svg#twitter"></use></svg> <span class="username">jekyllrb</span></a></li></ul>
</div>

      <div class="footer-col footer-col-3">
        <p>Write an awesome description for your new site here. You can edit this line in _config.yml. It will appear in your document head meta (for Google search results) and in your feed.xml site description.</p>
      </div>
    </div>

  </div>

</footer>
</body>

</html>
