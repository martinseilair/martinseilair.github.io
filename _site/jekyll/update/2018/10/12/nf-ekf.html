<!DOCTYPE html>
<html lang="en"><head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1"><!-- Begin Jekyll SEO tag v2.5.0 -->
<title>Nonlinear filtering: Extended Kalman filter | Ikigai</title>
<meta name="generator" content="Jekyll v3.8.4" />
<meta property="og:title" content="Nonlinear filtering: Extended Kalman filter" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="Intro" />
<meta property="og:description" content="Intro" />
<link rel="canonical" href="http://localhost:4000/jekyll/update/2018/10/12/nf-ekf.html" />
<meta property="og:url" content="http://localhost:4000/jekyll/update/2018/10/12/nf-ekf.html" />
<meta property="og:site_name" content="Ikigai" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2018-10-12T18:04:07+09:00" />
<script type="application/ld+json">
{"description":"Intro","@type":"BlogPosting","url":"http://localhost:4000/jekyll/update/2018/10/12/nf-ekf.html","headline":"Nonlinear filtering: Extended Kalman filter","dateModified":"2018-10-12T18:04:07+09:00","datePublished":"2018-10-12T18:04:07+09:00","mainEntityOfPage":{"@type":"WebPage","@id":"http://localhost:4000/jekyll/update/2018/10/12/nf-ekf.html"},"@context":"http://schema.org"}</script>
<!-- End Jekyll SEO tag -->
<link rel="stylesheet" href="/assets/main.css?1540825046723367958"><link type="application/atom+xml" rel="alternate" href="http://localhost:4000/feed.xml" title="Ikigai" /></head>
<body><header class="site-header" role="banner">

  <div class="wrapper"><a class="site-title" rel="author" href="/">Ikigai</a><a class="git-header" href="https://github.com/martinseilair"><svg class="svg-icon"><use xlink:href="/assets/minima-social-icons.svg#github"></use></svg> <span class="username">martinseilair</span></a></div>
</header>
<main class="page-content" aria-label="Content">
      <div class="wrapper">
        <article class="post h-entry" itemscope itemtype="http://schema.org/BlogPosting">

  <header class="post-header">
    <h1 class="post-title p-name" itemprop="name headline">Nonlinear filtering: Extended Kalman filter</h1>
    <p class="post-meta">
      <time class="dt-published" datetime="2018-10-12T18:04:07+09:00" itemprop="datePublished">Oct 12, 2018
      </time></p>
  </header>

  <div class="post-content e-content" itemprop="articleBody">
    <p>Intro
<!--more-->
<script src="https://d3js.org/d3.v5.min.js" charset="utf-8"></script></p>

<script src="https://cdn.plot.ly/plotly-latest.min.js"></script>

<script src="http://localhost:4000/assets/js/nonlinear_filter/particle_filter.js"></script>

<script src="http://localhost:4000/assets/js/nonlinear_filter/race_car.js"></script>

<script src="http://localhost:4000/assets/js/nonlinear_filter/race_track.js"></script>

<script src="http://localhost:4000/assets/js/nonlinear_filter/util.js"></script>

<script src="http://localhost:4000/assets/js/nonlinear_filter/plot.js"></script>

<script src="http://localhost:4000/assets/js/nonlinear_filter/scene.js"></script>

<script src="http://localhost:4000/assets/js/nonlinear_filter/discrete_bayes_filter.js"></script>

<link href="https://fonts.googleapis.com/css?family=Roboto" rel="stylesheet" />

<link rel="stylesheet" type="text/css" href="http://localhost:4000/assets/css/nonlinear_filter/style.css" />

<script type="text/javascript">


// mit keys oder button steuerbar
// strips ein und ausblendbar
// weights ein und ausblendbar
// update resample predict manuell oder langsam automatisch (weiter button)
// update resample predict button (hier macht input keinen sinn, außer man hat 3 button für predict)
// mit maus car position festlegen (geringster abstand)


// herangehensweise

// 1. auto fährt 
// 2. Vorstellung der system und beobachtungsfunktion (plot)
// 3. mit maus car position festlegen, entsprechende verteilung innen und außen anzeigen
// 3a. Bayes filter approximierung außen posterior innen beobachtung (update prediction weiter)
// 4. standbild: particle anzeigen
// 5. standbild: update step (5 sek vorher 5 sek nachher) (prob strip innen anzeigen)
// 6. standbild: resampling (5 sek vorher 5 sek nachher)
// 7. standbild: predict (5 sek vorher 5 sek nachher)
// 8. update resample predict manuell (weiter button)
// 9. update resample predict automatisch (geschwindigkeit einstellbar) (steuerung über pfeiltasten)
// 10. zwei trees

	// SITE NOT LOADED!!!

	// input modes
	// 0: Automatisch langsam; sequential
	// 1: Set input per  A = backward, S = no movement, D = forward; one step
	// 2: Set input per  A = backward, S = no movement, D = forward; sequential
	// 3: Mouse exploring
	// 4: No input

	// scene_flags

	scene = [];
	scenes = [];
	scenes_name = [];
	interval = null;
	loaded = false;
	var aa = 1;
	var fast_dur = 300;
	var slow_dur = 1000;
	var ani_step = 3;


	touch_id = null;





</script>

<h2 id="derivation">Derivation</h2>

<p>We will start the derivation directly from the recursive equations of the Bayes filter with the <strong>prediction step</strong></p>

<script type="math/tex; mode=display">p(x_{t+1}|y_{0:t},u_{0:t}) = \int_{x_{t}} p(x_{t+1}|x_{t}, u_{t})p(x_{t}|y_{0:t},u_{0:t-1}) dx_{t}</script>

<p>and the <strong>update step</strong></p>

<script type="math/tex; mode=display">p(x_t|y_{0:t},u_{0:t-1}) = \frac{p(y_t|x_t)p(x_t|y_{0:t-1},u_{0:t-1})}{\int_{x_t}p(y_t|x_t)p(x_t|y_{0:t-1},u_{0:t-1}) \,dx_t} .</script>

<script type="math/tex; mode=display">% <![CDATA[
\begin{align}
 x_{t+1} &= f(x_t, u_t, w_t) \\
 y_t &= h(x_k, v_k)
 \end{align} %]]></script>

<p>with Gaussian process noise \( w_t \sim \mathcal{N}(w_t|0, Q_t) \) and Gaussian observation noise \( v_t \sim \mathcal{N}(v_t|0, R_t) \).</p>

<p>First order Taylor expansion around the current state \(x_t = x\), current input \(u_t=u\) and zero process noise \(w_t=0\)</p>

<script type="math/tex; mode=display">x_{t+1} \approx f(x_t, u_t, w_t)|_{x_t=x,u_t=u,w_t=0} + \nabla_{x_t} f(x_t, u_t, w_t)^T|_{x_t=x,u_t=u,w_t=0}(x_t - x)+ \nabla_{u_t} f(x_t, u_t, w_t)^T|_{x_t=x,u_t=u,w_t=0}(u_t - u) + \nabla_{w_t} f(x_t, u_t, w_t)^T|_{x_t=x,u_t=u,w_t=0}w_t</script>

<script type="math/tex; mode=display">x_{t+1} \approx f(x, u, 0) + A_t(x_t - x)+ B_t(u_t - u) + L_tw_t</script>

<script type="math/tex; mode=display">\hat{p}(x_{t+1}|x_t,u_t) = \mathcal{N}\left(x_{t+1}\middle| f(x, u, 0) + A_t(x_t - x)+ B_t(u_t - u),L_t^TQ_tL_t\right)</script>

<script type="math/tex; mode=display">\hat{p}(x_{t+1}|x_t,u_t) = \mathcal{N}\left(x_{t+1}\middle| f(x, u, 0) - A_tx - B_tu + A_tx_t + B_tu_t,L_t^TQ_tL_t\right)</script>

<p>First order Taylor expansion around the current state \(x_t = x\) and zero measurement noise \(v_t=0\)</p>

<script type="math/tex; mode=display">y_t \approx h(x_t, v_t)|_{x_t=x,v_t=0} + \nabla_{x_t} h(x_t, v_t)^T|_{x_t=x,v_t=0}(x_t - x) + \nabla_{v_t} h(x_t, v_t)^T|_{x_t=x,v_t=0}v_t</script>

<script type="math/tex; mode=display">y_t \approx h(x, 0) + C_t(x_t - x) + M_tv_t</script>

<script type="math/tex; mode=display">\hat{p}(y_{t}|x_t) = \mathcal{N}\left(y_{t}\middle| h(x, 0) + C_t(x_t - x),M_t^TR_tM_t\right)</script>

<script type="math/tex; mode=display">\hat{p}(y_{t}|x_t) = \mathcal{N}\left(y_{t}\middle| h(x, 0) - C_tx + C_tx_t ,M_t^TR_tM_t\right)</script>

<script type="math/tex; mode=display">% <![CDATA[
\begin{align}
p(x_t|y_{0:t},u_{0:t-1}) &:= \mathcal{N}(x_{t}|\hat x_{t|t}, P_{t|t}) \\
p(x_t|y_{0:t-1},u_{0:t-1}) &:= \mathcal{N}(x_{t}|\hat x_{t|t-1}, P_{t|t-1}) .
 \end{align} %]]></script>

<p><strong>Prediction step</strong></p>

<script type="math/tex; mode=display">\mathcal{N}(x_{t+1}|\hat x_{t+1|t}, P_{t+1|t})  = \int_{x_t}\mathcal{N}\left(x_{t+1}\middle| f(x, u, 0) - A_tx - B_tu + A_tx_t + B_tu_t,L_t^TQ_tL_t\right) \mathcal{N}(x_t|\hat x_{t|t}, P_{t|t}) dx_t.</script>

<p><strong>Update step</strong></p>

<script type="math/tex; mode=display">\mathcal{N}(x_{t}|\hat x_{t|{t}}, P_{t|t} ) = \frac{\mathcal{N}\left(y_{t}\middle| h(x, 0) - C_tx + C_tx_t ,M_t^TR_tM_t\right) \mathcal{N}(x_{t}|\hat x_{t|t-1}, P_{t|t-1})}{\int_{x_{t}}\mathcal{N}\left(y_{t}\middle| h(x, 0) - C_tx + C_tx_t ,M_t^TR_tM_t\right) \mathcal{N}(x_{t}|\hat x_{t|t-1}, P_{t|t-1}) dx_{t}}</script>

<p>Let’s try to simplify these equations!</p>

<h3 id="prediction-step">Prediction step</h3>

<p>We will start with the prediction step</p>

<script type="math/tex; mode=display">\mathcal{N}(x_{t+1}|\hat x_{t+1|t}, P_{t+1|t})  = \int_{x_t}\mathcal{N}\left(x_{t+1}\middle| f(x, u, 0) - A_tx - B_tu + A_tx_t + B_tu_t,L_t^TQ_tL_t\right) \mathcal{N}(x_t|\hat x_{t|t}, P_{t|t}) dx_t.</script>

<p>In order to find a closed form solution of this integral, we could simply plug in the corresponding expressions of the Gaussian distributions and solve the integral. Fortunately, Marc Toussaint already gathered the most important <a href="https://ipvs.informatik.uni-stuttgart.de/mlr/marc/notes/gaussians.pdf">Gaussian identities</a>, which will lighten our workload a lot.  To find an expression for our prediction step we can simply use the <em>propagation</em> formula (Formula 37, Toussaint)</p>

<script type="math/tex; mode=display">\int_{y}\mathcal{N}(x|a + Fy, A)\mathcal{N}(y|b,B) dx_t = \mathcal{N}(x|a + Fb, A + FBF^T ).</script>

<p>By comparison with our expression, we see that</p>

<script type="math/tex; mode=display">\hat x_{t+1|t} = f(x_{t|t}, u_t, 0) -A_t \hat x_{t|t} - B_tu_t + A_t \hat x_{t|t} + B_tu_t = f(x_{t|t}, u_t, 0)</script>

<script type="math/tex; mode=display">P_{t+1|t} = L_t^TQ_tL_t + A_t P_{t|t} A_t^T  .</script>

<h3 id="update-step">Update step</h3>

<p>We will start to simplify the update step</p>

<script type="math/tex; mode=display">\mathcal{N}(x_{t}|\hat x_{t|{t}}, P_{t|t} ) = \frac{\mathcal{N}\left(y_{t}\middle| h(x, 0) - C_tx + C_tx_t ,M_t^TR_tM_t\right) \mathcal{N}(x_{t}|\hat x_{t|t-1}, P_{t|t-1})}{\int_{x_{t}}\mathcal{N}\left(y_{t}\middle| h(x, 0) - C_tx + C_tx_t ,M_t^TR_tM_t\right) \mathcal{N}(x_{t}|\hat x_{t|t-1}, P_{t|t-1}) dx_{t}}</script>

<p>by focussing on the numerator first. We notice that we can rewrite it as a joint distribution (Formula 39, Toussaint)</p>

<script type="math/tex; mode=display">% <![CDATA[
\mathcal{N}(x|a,A)\mathcal{N}(y|b + Fx,B) = \mathcal{N}\left(\begin{matrix}x \\y\end{matrix}\middle|\begin{matrix}a\\b + Fa \end{matrix},\begin{matrix}A & A^TF^T\\FA & B + FA^TF^T\end{matrix}\right) . %]]></script>

<p>Then again, this joint distribution can be rewritten as</p>

<script type="math/tex; mode=display">% <![CDATA[
\mathcal{N}\left(\begin{matrix}x \\y\end{matrix}\middle|\begin{matrix}d\\e \end{matrix},\begin{matrix}D & F\\F^T & E\end{matrix}\right) = \mathcal{N}(y|e,E)\mathcal{N}(x|d + F^TE^{-1}(y-e),D - F^T E^{-1}F) . %]]></script>

<p>We can combine the two previous equations to the following expression</p>

<script type="math/tex; mode=display">\mathcal{N}(x|a,A)\mathcal{N}(y|b + Fx,B) = \mathcal{N}(y|b + Fa,B + FA^TF^T) \mathcal{N}(x|a + A^TF^T(B + FA^TF^T)^{-1}(y-b -Fa),A - A^TF^T (B + FA^TF^T)^{-1}FA) .</script>

<p>By comparison with the numerator of our update step, we obtain</p>

<script type="math/tex; mode=display">\mathcal{N}\left(y_{t}\middle| h(x, 0) - C_t x_{t|t-1} + C_t x_{t|t-1} ,M_t^TR_tM_t\right) \mathcal{N}(x_{t}|\hat x_{t|t-1}, P_{t|t-1}) = \mathcal{N}(y_{t}|h(x, 0) - C_t x_{t|t-1} + C_t\hat x_{t|t-1},M_t^TR_tM_t + C_tP_{t|t-1}C_t^T)  \mathcal{N}(x_{t}|\hat x_{t|t-1} + P_{t|t-1}C_t^T(M_t^TR_tM_t + C_tP_{t|t-1}C_t^T)^{-1}(y_{t}-h(x, 0) + C_t x_{t|t-1} -C_t\hat x_{t|t-1}),  P_{t|t-1} - P_{t|t-1}C_t^T (M_t^TR_tM_t + C_tP_{t|t-1}C_t^T)^{-1}C_tP_{t|t-1}),</script>

<p>which simplifies to</p>

<script type="math/tex; mode=display">\mathcal{N}\left(y_{t}\middle| h(x, 0) ,M_t^TR_tM_t\right) \mathcal{N}(x_{t}|\hat x_{t|t-1}, P_{t|t-1}) = \mathcal{N}(y_{t}|h(x, 0),M_t^TR_tM_t + C_tP_{t|t-1}C_t^T)  \mathcal{N}(x_{t}|\hat x_{t|t-1} + P_{t|t-1}C_t^T(M_t^TR_tM_t + C_tP_{t|t-1}C_t^T)^{-1}(y_{t}-h(x, 0)),  P_{t|t-1} - P_{t|t-1}C_t^T (M_t^TR_tM_t + C_tP_{t|t-1}C_t^T)^{-1}C_tP_{t|t-1}).</script>

<p>At a first glance, this is not looking like a simplification at all. Conceptually, we only transformed</p>

<script type="math/tex; mode=display">\frac{p(y|x)p(x)}{p(y)} \to \frac{p(y,x)}{p(y)} \to \frac{p(x|y)p(y)}{p(y)}.</script>

<p>If we look closely at the final expression, we see that \(p(y)\) is canceling out. Therefore, the result is simply the remaining part</p>

<script type="math/tex; mode=display">\mathcal{N}(x_{t}|\hat x_{t|{t}}, P_{t|t} ) = \mathcal{N}(x_{t}|\hat x_{t|t-1} + P_{t|t-1}C_t^T(M_t^TR_tM_t + C_tP_{t|t-1}C_t^T)^{-1}(y_{t}-h(x, 0)),  P_{t|t-1} - P_{t|t-1}C_t^T (M_t^TR_tM_t + C_tP_{t|t-1}C_t^T)^{-1}C_tP_{t|t-1}).</script>

<p>If our reasoning is correct the denominator should be equal to \(\mathcal{N}(y_{t}|h(x, 0),M_t^TR_tM_t + C_tP_{t|t-1}C_t^T)\), which was canceled out. The denominator can be simplified with the <em>propagation</em> formula (Formula 37, Toussaint)</p>

<script type="math/tex; mode=display">\int_{x_{t}}\mathcal{N}\left(y_{t}\middle| h(x, 0) - C_t x_{t|t-1} + C_t x_{t|t-1} ,M_t^TR_tM_t\right) \mathcal{N}(x_{t}|\hat x_{t|t-1}, P_{t|t-1}) dx_{t} =  \mathcal{N}({y_{t}}|h(x, 0) - C_t x_{t|t-1} + C_t\hat x_{t|t-1}, M_t^TR_tM_t + C_tP_{t|t-1}C_t^T ) = \mathcal{N}(y_{t}|h(x, 0),M_t^TR_tM_t + C_tP_{t|t-1}C_t^T).</script>

<p>Yay! We see, that the denominator is exactly the same as the canceled factor in the numerator.</p>

<p>Let’s summarize our results:</p>

<div class="important_box">
  <h1>Bayes filter in linear Gaussian state space models</h1>

  <p>The recursive formula for the Bayes filter in linear Gaussian state space models consists of the <strong>prediction step</strong></p>

  <script type="math/tex; mode=display">% <![CDATA[
\begin{align}\hat x_{t+1|t} &= f(x_{t|t}, u_t, 0) \\ 
P_{t+1|t} &= L_t^TQ_tL_t + A_t P_{t|t} A_t^T   \end{align} %]]></script>

  <p>and the <strong>update step</strong></p>

  <script type="math/tex; mode=display">% <![CDATA[
\begin{align}\hat x_{t|t} &= \hat x_{t|t-1} + P_{t|t-1}C_t^T(M_t^TR_tM_t + C_tP_{t|t-1}C_t^T)^{-1}(y_{t}-h(x, 0)) \\ 
P_{t|t} &= P_{t|t-1} - P_{t|t-1}C_t^T (M_t^TR_tM_t + C_tP_{t|t-1}C_t^T)^{-1}C_tP_{t|t-1}.  \end{align} %]]></script>

</div>
<p>That’s it! We derived the equations of the Bayes filter in linear Gaussian state space models, which is nothing else but the good old Kalman filter.
In the next section, we will split these equations up to finally obtain the formulation normally used for the Kalman filter.</p>

<div class="important_box">
  <h1>Equations of the Kalman filter</h1>

  <p>The recursive formula for the Kalman filter consists of the <strong>prediction step</strong></p>

  <script type="math/tex; mode=display">% <![CDATA[
\begin{align}\hat x_{t+1|t} &= f(x_{t|t}, u_t, 0) \\ 
P_{t+1|t} &= L_t^TQ_tL_t + A_t P_{t|t} A_t^T   \end{align} %]]></script>

  <p>and the <strong>update step</strong></p>

  <script type="math/tex; mode=display">% <![CDATA[
\begin{align}
z_t &= y_{t}-h(x, 0)\\
S_t &= M_t^TR_tM_t + C_tP_{t|t-1}C_t^T\\
K_t &= P_{t|t-1}C_t^TS_t^{-1} \\
\hat x_{t|t} &= \hat x_{t|t-1} + K_t z_t\\
P_{t|t} &= (I - K_tC_t)P_{t|t-1}.
\end{align} %]]></script>

</div>

<p>Additive noise</p>

<script type="math/tex; mode=display">f(x_t, u_t, w_t) = \bar{f}(x_t, u_t) + w_t</script>

<script type="math/tex; mode=display">L_t = \nabla_{w_t} f(x_t, u_t, w_t)|_{x_t=x,v_t=0} = \underbrace{\nabla_{w_t} \bar{f}(x_t, u_t)}_{0}|_{x_t=x,v_t=0} + \underbrace{\nabla_{w_t} w_t}_{I}|_{x_t=x,v_t=0} = I</script>

<script type="math/tex; mode=display">f(x_t, u_t, w_t) = \bar{f}(x_t, u_t) + w_t</script>

<script type="math/tex; mode=display">M_t = \nabla_{v_t} h(x_t, v_t)|_{x_t=x,v_t=0} = \underbrace{\nabla_{v_t} \bar{h}(x_t)}_{0}|_{x_t=x,v_t=0} + \underbrace{\nabla_{v_t} v_t}_{I}|_{x_t=x,v_t=0} = I</script>

<div class="important_box">
  <h1>Equations of the Kalman filter</h1>

  <p>The recursive formula for the Kalman filter consists of the <strong>prediction step</strong></p>

  <script type="math/tex; mode=display">% <![CDATA[
\begin{align}\hat x_{t+1|t} &= f(x_{t|t}, u_t, 0) \\ 
P_{t+1|t} &= Q_t + A_t P_{t|t} A_t^T   \end{align} %]]></script>

  <p>and the <strong>update step</strong></p>

  <script type="math/tex; mode=display">% <![CDATA[
\begin{align}
z_t &= y_{t}-h(x, 0)\\
S_t &= R_t + C_tP_{t|t-1}C_t^T\\
K_t &= P_{t|t-1}C_t^TS_t^{-1} \\
\hat x_{t|t} &= \hat x_{t|t-1} + K_t z_t\\
P_{t|t} &= (I - K_tC_t)P_{t|t-1}.
\end{align} %]]></script>

</div>

<p><a href="https://www.freepik.com/free-vector/flat-car-collection-with-side-view_1505022.htm"></a></p>

<div id="rad_to_s" style="width:100px"></div>
<div id="div1"></div>
<div id="div2"></div>
<!-- <div id="system_dist_approx"  style="width: 600px; height: 600px;"></div> -->
<!--<div id="output_dist_approx"  style="width: 600px; height: 600px;"></div>-->
<script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_SVG"></script>

<script type="text/x-mathjax-config">

var mq = window.matchMedia( "(max-width: 570px)" );
if (!mq.matches) {
    MathJax.Hub.Config({
	  CommonHTML: { linebreaks: { automatic: true } },
	  "HTML-CSS": { linebreaks: { automatic: true } },
	         SVG: { linebreaks: { automatic: true } }
	}); 
} 

</script>


  </div><a class="u-url" href="/jekyll/update/2018/10/12/nf-ekf.html" hidden></a>
</article>

      </div>
    </main>

  </body>

</html>
