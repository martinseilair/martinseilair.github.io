---
layout: post
title:  "Nonlinear filtering: Extended Kalman filter"
date:   2018-10-31 23:04:07 +0900
categories: jekyll update
excerpt_separator: <!--more-->
---
This article is the second part of the nonlinear filtering series, where we will derive the extended Kalman filter with non-additive and additive noise directly from the recursive equations of the Bayes filter.  <!--more--> If you haven't read the [introduction]({% post_url 2018-10-29-nf-intro %}), I would recommend to read it first. Before we dive into the derivation, let's try to state the main idea behind extended Kalman filter.
<!--more-->
<script src="https://d3js.org/d3.v5.min.js" charset="utf-8"></script>

  <script src="https://cdn.plot.ly/plotly-latest.min.js"></script>

<script src="{{ base.url | prepend: site.url }}/assets/js/nonlinear_filter/particle_filter.js"></script>
<script src="{{ base.url | prepend: site.url }}/assets/js/nonlinear_filter/race_car.js"></script>
<script src="{{ base.url | prepend: site.url }}/assets/js/nonlinear_filter/race_track.js"></script>

<script src="{{ base.url | prepend: site.url }}/assets/js/nonlinear_filter/util.js"></script>

<script src="{{ base.url | prepend: site.url }}/assets/js/nonlinear_filter/plot.js"></script>

<script src="{{ base.url | prepend: site.url }}/assets/js/nonlinear_filter/scene.js"></script>

<script src="{{ base.url | prepend: site.url }}/assets/js/nonlinear_filter/ekf.js"></script>
<script src="{{ base.url | prepend: site.url }}/assets/js/nonlinear_filter/discrete_bayes_filter.js"></script>


<link href="https://fonts.googleapis.com/css?family=Roboto" rel="stylesheet" />


<link rel="stylesheet" type="text/css" href="{{ base.url | prepend: site.url }}/assets/css/nonlinear_filter/style.css">




<script type="text/javascript">


	scene = [];
	scenes = [];
	scenes_name = [];
	interval = null;
	loaded = false;
	var aa = 1;
	var fast_dur = 300;
	var slow_dur = 1000;
	var ani_step = 3;


	touch_id = null;





</script>


<div class="important_box"  markdown="1">
The **extended Kalman filter** approximates the Bayes filter by linearizing the system and observation equations.
</div>

## Derivation

We will start the derivation directly from the recursive equations of the Bayes filter with the **prediction step**

$$ p(x_{t+1}|y_{0:t},u_{0:t}) = \int_{x_{t}} p(x_{t+1}|x_{t}, u_{t})p(x_{t}|y_{0:t},u_{0:t-1}) dx_{t} $$

and the **update step**

$$ p(x_t|y_{0:t},u_{0:t-1}) = \frac{p(y_t|x_t)p(x_t|y_{0:t-1},u_{0:t-1})}{\int_{x_t}p(y_t|x_t)p(x_t|y_{0:t-1},u_{0:t-1}) \,dx_t} .$$


The extended Kalman filter is normally formulated with nonlinear functions with additive noise. In this article, we directly derive the general case for non-additive noise and obtain the extended Kalman filter as a special case. Therefore, our equations of the system are

$$
\begin{align}
 x_{t+1} &= f(x_t, u_t, w_t) \\
 y_t &= h(x_k, v_k).
 \end{align}
 $$

with Gaussian process noise \\( w_t \sim \mathcal{N}(w_t\|0, Q_t) \\) and Gaussian observation noise \\( v_t \sim \mathcal{N}(v_t\|0, R_t) \\).

In our formula of the Bayes filter, we can't find any functions \\(f(x_t, u_t, w_t)\\) or \\(h(x_k, v_k)\\). Therefore, our first step will be to express these functions as probability distributions \\(p(x_{t+1}\|x_{t}, u_{t})\\) and \\(p(y_t\|x_t)\\). The next box will show how to achieve this in general. **Warning:** Distributions are very weird and the following treatment is **not rigorous**. 
 <div class="extra_box" markdown="1">
We want to calculate \\(p(y|x)\\) given the function \\(y=f(x,z)\\) and \\(p(z)\\).
We can express the deterministic function \\(y=f(x,z)\\) as probability distribution

$$ p(y|x,z) = \delta(y-f(x,z)), $$

with the [Dirac delta function](https://en.wikipedia.org/wiki/Dirac_delta_function) \\(\delta(x)\\).

In order to calculate \\(p(y\|x)\\) we can simply marginalize out \\(z\\):

$$
\begin{align}
p(y|x) &= \int_z p(y|x,z)p(z)\, dx \\
 &= \int_z \delta(y-f(x,z))p(z)\, dx 
\end{align}
$$

By using the composition rule of the Dirac delta function, we can express this as

$$ p(y|x) = \sum_i \frac{p(z_i)}{\left|\det\nabla_z f(x,z)|_{z_i}\right|}, $$

where the sum goes over all \\(z_i\\) which satisfy the equation \\(y = f(x,z)\\).
</div>

In our case, we can express our system function \\(x_{t+1} = f(x_t,u_t,w_t)\\) as a probability distribution

$$ p(x_{t+1}|x_t,u_t) = \sum_i \frac{p(w_i)}{\left|\det\nabla_w f(x_t, u_t, w_t)|_{w_i}\right|}, $$

where the sum goes over all \\(w_i\\) which satisfy \\(x_{t+1} = f(x_t,u_t,w_t)\\).

Similarly, we can express our observation function  \\(y_t = h(x_k, v_k)\\) as probability distribution

$$ p(y_t|x_t) = \sum_i \frac{p(v_i)}{\left|\det\nabla_v h(x_t, v_t)|_{v_i}\right|} $$

where the sum goes over all \\(v_i\\) which satisfy \\(x_{t+1} = h(x_t,v_t)\\).

Even if we are assuming Gaussian process and measurement noise, the resulting distributions of our model will, in general, be non-Gaussian.
This is where the extended Kalman filter comes into play. It approximates our probability distributions by using linearization.
In my limited scope, linearization of a probability distribution makes no sense. But what is linearized instead?

Instead of linearizing our probability distributions we will do this with our deterministic functions before we express them as probability distributions.

 In order to linearize, we are performing a first-order Taylor expansion

 $$ f(x_t, u_t, w_t) \approx f(x_t, u_t, w_t)|_{x_t=\hat x_{t|t},u_t=u,w_t=0} + \nabla_{x_t} f(x_t, u_t, w_t)^T|_{x_t=\hat x_{t|t},u_t=u,w_t=0}(x_t - x)+ \nabla_{u_t} f(x_t, u_t, w_t)^T|_{x_t=\hat x_{t|t},u_t=u,w_t=0}(u_t - u) + \nabla_{w_t} f(x_t, u_t, w_t)^T|_{x_t=\hat x_{t|t},u_t=u,w_t=0}w_t$$



 around the current state estimate \\(x_t = \hat x_{t\|t}\\), current input \\(u_t=u\\) and zero process noise \\(w_t=0\\).


 To unclutter the notation, we define \\(A_t = \nabla_{x_t} f(x_t, u_t, w_t)^T\|_ {x_t=\hat x_{t\|t},u_t=u,w_t=0}\\) , \\(B_t = \nabla_{u_t} f(x_t, u_t, w_t)^T\|_ {x_t=\hat x_{t\|t},u_t=u,w_t=0}\\) and \\(L_t = \nabla_{w_t} f(x_t, u_t, w_t)^T\|_ {x_t=\hat x_{t\|t},u_t=u,w_t=0}\\) to finally obtain the much cleaner representation


 

$$ \hat{f}(x_t, u_t, w_t) = f(\hat x_{t|t}, u, 0) + A_t(x_t - \hat x_{t|t})+ B_t(u_t - u)  + L_tw_t.$$

Now we are ready to transform our linearized deterministic system function into a probability distribution. We will use the same formula as above, but replace the true function \\(f(x_t, u_t, w_t)\\) with \\(\hat{f}(x_t, u_t, w_t)\\), and arrive at


$$ p(x_{t+1}|x_t,u_t) = \sum_i \frac{\mathcal{N}(w_i|0,Q_t)}{\left|\det\nabla_w \hat{f}(x_t, u_t, w_t)|_{w_i}\right|}, $$

where the sum is over all \\(w_i\\) which satisfy \\(x_{t+1} = \hat{f}(x_t, u_t, w_t)\\). Let's try to simplify this expression! First, we notice that if the matrix \\(L_t\\) is invertible, then there is exactly one \\(w\\) that satisfies \\(x_{t+1} = \hat{f}(x_t, u_t, w_t)\\). We can express it as


$$ w = L_t^{-1}\left(x_{t+1} - f(\hat x_{t|t}, u, 0) - A_t(x_t - \hat x_{t|t})- B_t(u_t - u)\right). $$

Note, that if the martrix \\(L_t\\) is not invertible, we would have to integrate over the whole null space and the sum would become an integral. 

Next, let's look at the denominator. We can express the derivative of \\(\hat{f}(x_t, u_t, w_t)\\) with respect to \\(w_t\\) as

$$ \nabla_w \hat{f}(x_t, u_t, w_t) =\nabla_w( f(\hat x_{t|t}, u, 0) + A_t(x_t - \hat x_{t|t})+ B_t(u_t - u)  + L_tw_t) = L_t. $$


Let's plug in the information our new information about \\(w\\) and the derivative:

$$ p(x_{t+1}|x_t,u_t) = \frac{\mathcal{N}(L_t^{-1}\left(x_{t+1} - f(\hat x_{t|t}, u, 0) - A_t(x_t - \hat x_{t|t})- B_t(u_t - u)\right)|0,Q_t)}{\left|\det L_t\right|}. $$

We apply the transformation identity (Formula 35, [Toussaint](https://ipvs.informatik.uni-stuttgart.de/mlr/marc/notes/gaussians.pdf)):

$$ p(x_{t+1}|x_t,u_t) = \frac{\frac{1}{\left|\det L_t^{-1}\right|}\mathcal{N}(x_{t+1} - f(\hat x_{t|t}, u, 0) - A_t(x_t - \hat x_{t|t})- B_t(u_t - u)|0,L_tQ_tL_t^T)}{\left|\det L_t\right|} $$

And apply it once more, to obtain our final result:

$$ p(x_{t+1}|x_t,u_t) = \mathcal{N}(x_{t+1}|f(\hat x_{t|t}, u, 0) + A_t(x_t - \hat x_{t|t})+ B_t(u_t - u),L_tQ_tL_t^T). $$

We are done! The linearization of our function has lead us back to Gaussianity!

With the same strategy, we obtain for our observation model

$$ p(y_t|x_t) = \mathcal{N}(y_T|h(\hat x_{t|t-1}, 0) + C_t(x_t - \hat x_{t|t-1}),M_tQ_tM_t^T), $$

with \\(C_t = \nabla_{x_t} h(x_t, v_t)^T\|_ {x_t=\hat x_{t\|t-1},v_t=0}\\) and \\(M_t = \nabla_{v_t} h(x_t, v_t)^T\|_ {x_t=\hat x_{t\|t-1},v_t=0}\\)


Our linearization led to a Gaussian system and observation model. Therefore, the distribution of the updated state estimate


$$ p(x_t|y_{0:t},u_{0:t-1}) := \mathcal{N}(x_{t}|\hat x_{t|t}, P_{t|t}) $$

and the distribution of the predicted state estimate

$$ p(x_t|y_{0:t-1},u_{0:t-1}) := \mathcal{N}(x_{t}|\hat x_{t|t-1}, P_{t|t-1}) $$

will be Gaussians as well. 

Now we are ready to plug our surrogate into the equations of the Bayes filter:
 <div class="important_box" markdown="1">
**Prediction step**

$$ \mathcal{N}(x_{t+1}|\hat x_{t+1|t}, P_{t+1|t})  = \int_{x_t}\mathcal{N}\left(x_{t+1}\middle| f(x, u, 0) + A_t(x_t - \hat x_{t|t})+ B_t(u_t - u),L_t^TQ_tL_t\right) \mathcal{N}(x_t|\hat x_{t|t}, P_{t|t}) dx_t.$$

**Update step**

$$ \mathcal{N}(x_{t}|\hat x_{t|{t}}, P_{t|t} ) = \frac{\mathcal{N}\left(y_{t}\middle| h(x, 0) C_t(x_t - \hat x_{t|t-1}) ,M_t^TR_tM_t\right) \mathcal{N}(x_{t}|\hat x_{t|t-1}, P_{t|t-1})}{\int_{x_{t}}\mathcal{N}\left(y_{t}\middle| h(x, 0) C_t(x_t - \hat x_{t|t-1}) ,M_t^TR_tM_t\right) \mathcal{N}(x_{t}|\hat x_{t|t-1}, P_{t|t-1}) dx_{t}}   $$ 

</div>


Let's try to simplify these equations!

### Prediction step

We will start with the prediction step

$$ \mathcal{N}(x_{t+1}|\hat x_{t+1|t}, P_{t+1|t})  = \int_{x_t}\mathcal{N}\left(x_{t+1}\middle| f(x, u, 0) - A_t\hat x_{t|t} - B_tu + A_tx_t + B_tu_t,L_t^TQ_tL_t\right) \mathcal{N}(x_t|\hat x_{t|t}, P_{t|t}) dx_t.$$

To find an expression for our prediction step we can simply use the *propagation* formula (Formula 37, [Toussaint](https://ipvs.informatik.uni-stuttgart.de/mlr/marc/notes/gaussians.pdf))

$$ \int_{y}\mathcal{N}(x|a + Fy, A)\mathcal{N}(y|b,B) dx_t = \mathcal{N}(x|a + Fb, A + FBF^T ). $$

By comparison with our expression, we see that

$$ \hat x_{t+1|t} = f(x_{t|t}, u_t, 0) -A_t \hat x_{t|t} - B_tu_t + A_t \hat x_{t|t} + B_tu_t = f(x_{t|t}, u_t, 0) $$


$$ P_{t+1|t} = L_t^TQ_tL_t + A_t P_{t|t} A_t^T  .$$



### Update step

We will start to simplify the update step 

$$ \mathcal{N}(x_{t}|\hat x_{t|{t}}, P_{t|t} ) = \frac{\mathcal{N}\left(y_{t}\middle| h(\hat x_{t|t-1}, 0) - C_t\hat x_{t|t-1} + C_tx_t ,M_t^TR_tM_t\right) \mathcal{N}(x_{t}|\hat x_{t|t-1}, P_{t|t-1})}{\int_{x_{t}}\mathcal{N}\left(y_{t}\middle| h(\hat x_{t|t-1}, 0) - C_t\hat x_{t|t-1} + C_tx_t ,M_t^TR_tM_t\right) \mathcal{N}(x_{t}|\hat x_{t|t-1}, P_{t|t-1}) dx_{t}}   $$ 


by focussing on the numerator first. We notice that we can rewrite it as a joint distribution (Formula 39, [Toussaint](https://ipvs.informatik.uni-stuttgart.de/mlr/marc/notes/gaussians.pdf))

$$ \mathcal{N}(x|a,A)\mathcal{N}(y|b + Fx,B) = \mathcal{N}\left(\begin{matrix}x \\y\end{matrix}\middle|\begin{matrix}a\\b + Fa \end{matrix},\begin{matrix}A & A^TF^T\\FA & B + FA^TF^T\end{matrix}\right) .$$

Then again, this joint distribution can be rewritten as 

$$ \mathcal{N}\left(\begin{matrix}x \\y\end{matrix}\middle|\begin{matrix}d\\e \end{matrix},\begin{matrix}D & F\\F^T & E\end{matrix}\right) = \mathcal{N}(y|e,E)\mathcal{N}(x|d + F^TE^{-1}(y-e),D - F^T E^{-1}F) .$$

We can combine the two previous equations to the following expression

$$ \mathcal{N}(x|a,A)\mathcal{N}(y|b + Fx,B) = \mathcal{N}(y|b + Fa,B + FA^TF^T) \mathcal{N}(x|a + A^TF^T(B + FA^TF^T)^{-1}(y-b -Fa),A - A^TF^T (B + FA^TF^T)^{-1}FA) .$$ 

By comparison with the numerator of our update step, we obtain

$$ \mathcal{N}\left(y_{t}\middle| h(\hat x_{t|t-1}, 0) - C_t x_{t|t-1} + C_t x_{t|t-1} ,M_t^TR_tM_t\right) \mathcal{N}(x_{t}|\hat x_{t|t-1}, P_{t|t-1}) = \mathcal{N}(y_{t}|h(\hat x_{t|t-1}, 0) - C_t x_{t|t-1} + C_t\hat x_{t|t-1},M_t^TR_tM_t + C_tP_{t|t-1}C_t^T)  \mathcal{N}(x_{t}|\hat x_{t|t-1} + P_{t|t-1}C_t^T(M_t^TR_tM_t + C_tP_{t|t-1}C_t^T)^{-1}(y_{t}-h(\hat x_{t|t-1}, 0) + C_t x_{t|t-1} -C_t\hat x_{t|t-1}),  P_{t|t-1} - P_{t|t-1}C_t^T (M_t^TR_tM_t + C_tP_{t|t-1}C_t^T)^{-1}C_tP_{t|t-1}), $$ 

which simplifies to

$$ \mathcal{N}\left(y_{t}\middle| h(\hat x_{t|t-1}, 0) ,M_t^TR_tM_t\right) \mathcal{N}(x_{t}|\hat x_{t|t-1}, P_{t|t-1}) = \mathcal{N}(y_{t}|h(\hat x_{t|t-1}, 0),M_t^TR_tM_t + C_tP_{t|t-1}C_t^T)  \mathcal{N}(x_{t}|\hat x_{t|t-1} + P_{t|t-1}C_t^T(M_t^TR_tM_t + C_tP_{t|t-1}C_t^T)^{-1}(y_{t}-h(\hat x_{t|t-1}, 0)),  P_{t|t-1} - P_{t|t-1}C_t^T (M_t^TR_tM_t + C_tP_{t|t-1}C_t^T)^{-1}C_tP_{t|t-1}). $$ 

We applied the same trick as in the [derivation of the Kalman filter]({% post_url 2018-10-10-kalman_filter %}): Conceptually, we only transformed 

$$ \frac{p(y|x)p(x)}{p(y)} \to \frac{p(y,x)}{p(y)} \to \frac{p(x|y)p(y)}{p(y)}. $$


If we look closely at the final expression, we see that \\(p(y)\\) is canceling out. Therefore, the result is simply the remaining part

$$ \mathcal{N}(x_{t}|\hat x_{t|{t}}, P_{t|t} ) = \mathcal{N}(x_{t}|\hat x_{t|t-1} + P_{t|t-1}C_t^T(M_t^TR_tM_t + C_tP_{t|t-1}C_t^T)^{-1}(y_{t}-h(\hat x_{t|t-1}, 0)),  P_{t|t-1} - P_{t|t-1}C_t^T (M_t^TR_tM_t + C_tP_{t|t-1}C_t^T)^{-1}C_tP_{t|t-1}). $$ 

If our reasoning is correct the denominator should be equal to \\(\mathcal{N}(y_{t}\|h(x, 0),M_t^TR_tM_t + C_tP_{t\|t-1}C_t^T)\\), which was canceled out. The denominator can be simplified with the *propagation* formula (Formula 37, [Toussaint](https://ipvs.informatik.uni-stuttgart.de/mlr/marc/notes/gaussians.pdf))

$$ \int_{x_{t}}\mathcal{N}\left(y_{t}\middle| h(\hat x_{t|t-1}, 0) - C_t x_{t|t-1} + C_t x_{t|t-1} ,M_t^TR_tM_t\right) \mathcal{N}(x_{t}|\hat x_{t|t-1}, P_{t|t-1}) dx_{t} =  \mathcal{N}({y_{t}}|h(\hat x_{t|t-1}, 0) - C_t x_{t|t-1} + C_t\hat x_{t|t-1}, M_t^TR_tM_t + C_tP_{t|t-1}C_t^T ) = \mathcal{N}(y_{t}|h(\hat x_{t|t-1}, 0),M_t^TR_tM_t + C_tP_{t|t-1}C_t^T).$$

Yay! We see, that the denominator is exactly the same as the canceled factor in the numerator.

Let's summarize our results:

<div class="important_box" markdown="1">
<h1>Extended Kalman filter with non-additive noise</h1>

The recursive formula for the extended Kalman filter with non-additive noise consists of the **prediction step**

$$ \begin{align}\hat x_{t+1|t} &= f(x_{t|t}, u_t, 0) \\ 
P_{t+1|t} &= L_t^TQ_tL_t + A_t P_{t|t} A_t^T   \end{align} $$


and the **update step**


$$ \begin{align}\hat x_{t|t} &= \hat x_{t|t-1} + P_{t|t-1}C_t^T(M_t^TR_tM_t + C_tP_{t|t-1}C_t^T)^{-1}(y_{t}-h(\hat x_{t|t-1}, 0)) \\ 
P_{t|t} &= P_{t|t-1} - P_{t|t-1}C_t^T (M_t^TR_tM_t + C_tP_{t|t-1}C_t^T)^{-1}C_tP_{t|t-1}  \end{align} $$

with

$$ \begin{align}
A_t &= \nabla_{x_t} f(x_t, u_t, w_t)^T|_ {x_t=\hat x_{t|t},u_t=u,w_t=0}\\
B_t &= \nabla_{u_t} f(x_t, u_t, w_t)^T|_ {x_t=\hat x_{t|t},u_t=u,w_t=0}\\
C_t &= \nabla_{x_t} h(x_t, v_t)^T|_ {x_t=\hat x_{t|t-1},v_t=0}\\
L_t &= \nabla_{w_t} f(x_t, u_t, w_t)^T|_ {x_t=\hat x_{t|t},u_t=u,w_t=0}\\
M_t &= \nabla_{v_t} h(x_t, v_t)^T|_ {x_t=\hat x_{t|t-1},v_t=0}.
\end{align} $$



</div>
That's it! We derived the equations of the extended Kalman filter. To bring the equations in a more implementation friendly form, we are restating the extended Kalman filter as:


<div class="important_box" markdown="1">
<h1>Extended Kalman filter with non-additive noise</h1>

The recursive formula for the extended Kalman filter with non-additive noise consists of the **prediction step**

$$ \begin{align}\hat x_{t+1|t} &= f(x_{t|t}, u_t, 0) \\ 
P_{t+1|t} &= L_t^TQ_tL_t + A_t P_{t|t} A_t^T   \end{align} $$


and the **update step**

$$ \begin{align}
z_t &= y_{t}-h(\hat x_{t|t-1}, 0)\\
S_t &= M_t^TR_tM_t + C_tP_{t|t-1}C_t^T\\
K_t &= P_{t|t-1}C_t^TS_t^{-1} \\
\hat x_{t|t} &= \hat x_{t|t-1} + K_t z_t\\
P_{t|t} &= (I - K_tC_t)P_{t|t-1}
\end{align}
 $$

with

$$ \begin{align}
A_t &= \nabla_{x_t} f(x_t, u_t, w_t)^T|_ {x_t=\hat x_{t|t},u_t=u,w_t=0}\\
B_t &= \nabla_{u_t} f(x_t, u_t, w_t)^T|_ {x_t=\hat x_{t|t},u_t=u,w_t=0}\\
C_t &= \nabla_{x_t} h(x_t, v_t)^T|_ {x_t=\hat x_{t|t-1},v_t=0}\\
L_t &= \nabla_{w_t} f(x_t, u_t, w_t)^T|_ {x_t=\hat x_{t|t},u_t=u,w_t=0}\\
M_t &= \nabla_{v_t} h(x_t, v_t)^T|_ {x_t=\hat x_{t|t-1},v_t=0}.
\end{align} $$


</div>

As promised we will also look at the special case with **additive** noise. Therefore, our functions will look like:

$$ f(x_t, u_t, w_t) = \bar{f}(x_t, u_t) + w_t. $$

$$ h(x_t, v_t) = \bar{h}(x_t) + v_t. $$

In this case, the matrix \\(L_t\\) and \\(M_t\\) will be identity matrices:

$$ L_t = \nabla_{w_t} f(x_t, u_t, w_t)|_{x_t=x,v_t=0} = \underbrace{\nabla_{w_t} \bar{f}(x_t, u_t)}_{0}|_{x_t=x,v_t=0} + \underbrace{\nabla_{w_t} w_t}_{I}|_{x_t=x,v_t=0} = I $$


$$ M_t = \nabla_{v_t} h(x_t, v_t)|_{x_t=x,v_t=0} = \underbrace{\nabla_{v_t} \bar{h}(x_t)}_{0}|_{x_t=x,v_t=0} + \underbrace{\nabla_{v_t} v_t}_{I}|_{x_t=x,v_t=0} = I. $$

Finally, we can state the equations of the extended Kalman filter with additive noise.

<div class="important_box" markdown="1">
<h1>Extended Kalman filter with additive noise</h1>

The recursive formula for the extended Kalman filter with additive noise consists of the **prediction step**

$$ \begin{align}\hat x_{t+1|t} &= f(x_{t|t}, u_t) \\ 
P_{t+1|t} &= Q_t + A_t P_{t|t} A_t^T   \end{align} $$


and the **update step**

$$ \begin{align}
z_t &= y_{t}-h(\hat x_{t|t-1})\\
S_t &= R_t + C_tP_{t|t-1}C_t^T\\
K_t &= P_{t|t-1}C_t^TS_t^{-1} \\
\hat x_{t|t} &= \hat x_{t|t-1} + K_t z_t\\
P_{t|t} &= (I - K_tC_t)P_{t|t-1}
\end{align} $$

with 

$$ \begin{align}
A_t &= \nabla_{x_t} f(x_t, u_t, w_t)^T|_ {x_t=\hat x_{t|t},u_t=u,w_t=0}\\
B_t &= \nabla_{u_t} f(x_t, u_t, w_t)^T|_ {x_t=\hat x_{t|t},u_t=u,w_t=0}\\
C_t &= \nabla_{x_t} h(x_t, v_t)^T|_ {x_t=\hat x_{t|t-1},v_t=0}\\
\end{align} $$

</div>





## Example

Enough of the dry theory! Let's play around with the grid-based filter in our race track example. 




<svg id="race_track_mar_loc" style="width:100%"  onclick="on_click()"></svg>
<script>


	n_scene = load_race_track("race_track_mar_loc","{{ base.url | prepend: site.url }}",1000);
	n_scene.mode = 2;
	n_scene.filter = "";
	n_scene.dur=slow_dur;
	// define particle filter 

	n_scene.auto_start = false;

	n_scene.t = 1;

	n_scene.ids = ["race_track_mar_loc_likelihood", "race_track_mar_loc_update","race_track_mar_loc_timestep", "race_track_mar_loc_predict" ];

	n_scene.loaded = function(){

		var outer_color = d3.piecewise(d3.interpolateRgb, [d3.rgb(this.rt.svg.style("background-color")), d3.rgb('#006eff'), d3.rgb('#00028e')]);
		var inner_color = d3.piecewise(d3.interpolateRgb, [d3.rgb(this.rt.svg.style("background-color")), d3.rgb('#ff834d'), d3.rgb('#8e3323')]);

		this.ekf = init_ekf_1D(this.rc, this.rc.state, 3*this.rc.sigma_s_no_cache(this.rc.state));
		this.rt.init_strip("inner", get_output_dist_normalized(this.rc, this.rt, this.rc.state), inner_color, 60);
		this.rt.init_strip("outer", get_gaussian_circ_normalized(this.rt.strip_pos, this.ekf.posterior_mu, this.ekf.posterior_sigma, this.rt), outer_color, 60);



		document.getElementById("race_track_mar_loc_likelihood").style.display="block";
		this.rt.hide_strip("inner");


		this.restart = function(){
			for (var i=0; i<this.ids.length;i++){

				document.getElementById(this.ids[i]).style.display="none";
			}
			document.getElementById("race_track_mar_loc_likelihood").style.display="block";
			this.rc.reset();
			this.t = 1;

			

			//this.bf.reset();
			this.ekf.reset(this.rc.state, this.rc.sigma_o_no_cache(this.rc.state))
			this.rt.hide_strip("inner");
			this.rt.show_strip("outer");
			this.rt.update_strip("outer", get_gaussian_circ_normalized(this.rt.strip_pos, this.ekf.posterior_mu, this.ekf.posterior_sigma, this.rt));
		}


		this.rt.set_restart_button(this.restart.bind(this))




	}.bind(n_scene)


	n_scene.step = function(){
		this.t++;
		for (var i=0; i<this.ids.length;i++){

			document.getElementById(this.ids[i]).style.display="none";
		}


		if(this.t % 4 == 0){
			//CHOOSE ACTION
			this.rc.step(this.rc.current_input);
			this.last_input = this.rc.current_input;
			document.getElementById("race_track_mar_loc_predict").style.display="block";
			this.rt.hide_strip("inner");
		}else if(this.t % 4 == 1){
			// PREDICT
			this.ekf.predict(this.last_input);

			// trim ekf posterior
			if(this.ekf.posterior_mu<0){
				this.ekf.posterior_mu+=this.rt.track_length;
			}
			this.ekf.posterior_mu = this.ekf.posterior_mu % this.rt.track_length;
			this.rt.update_strip("outer", get_gaussian_circ_normalized(this.rt.strip_pos, this.ekf.posterior_mu, this.ekf.posterior_sigma, this.rt));
			document.getElementById("race_track_mar_loc_likelihood").style.display="block";
		}else if(this.t % 4 == 2){
			// OBSERVE
			this.rt.show_strip("inner");
			this.output = scene.rc.output_dist_sample(0);
			var likelihood = this.ekf.get_likelihood(this.output,this.ekf.posterior_mu)
			this.rt.update_strip("inner", get_gaussian_circ_normalized(this.rt.strip_pos, likelihood.mu, likelihood.sigma, this.rt));

			document.getElementById("race_track_mar_loc_update").style.display="block";
		}else if(this.t % 4 == 3){
			// UPDATE

			this.ekf.update(this.output);

			this.rt.update_strip("outer", get_gaussian_circ_normalized(this.rt.strip_pos, this.ekf.posterior_mu, this.ekf.posterior_sigma, this.rt));

			document.getElementById("race_track_mar_loc_timestep").style.display="block";
		}

	}.bind(n_scene);

	scenes_name["race_track_mar_loc"] = n_scene;
	scenes.push(n_scene);

</script>




<div id="race_track_mar_loc_timestep" class="button_set">
<div class="bt3 bt" onclick="scenes_name['race_track_mar_loc'].rc.current_input=0;scenes_name['race_track_mar_loc'].step();">Backward</div>
<div class="bt3 bt" onclick="scenes_name['race_track_mar_loc'].rc.current_input=1;scenes_name['race_track_mar_loc'].step();">No action</div>
<div class="bt3 bt" onclick="scenes_name['race_track_mar_loc'].rc.current_input=2;scenes_name['race_track_mar_loc'].step();">Forward</div>
 <span class="stretch"></span>
</div>

<div id="race_track_mar_loc_predict" class="button_set">
<div class="bt1  bt" onclick="scenes_name['race_track_mar_loc'].step();">Predict step</div>
  <span class="stretch"></span>
</div>



<div id="race_track_mar_loc_likelihood" class="button_set">
<div class="bt1  bt" onclick="scenes_name['race_track_mar_loc'].step();">Observe</div>
  <span class="stretch"></span>
</div>

<div id="race_track_mar_loc_update" class="button_set" onclick="scenes_name['race_track_mar_loc'].step();">
<div class="bt1  bt">Update step</div>
  <span class="stretch"></span>
</div>



On the outside the race track, you will notice a blue colored strip. This strip represents our current posterior of the current position of the race car. We will start with a Gaussian prior distribution around the true mean. By pressing the __OBSERVE__ button two things will happen: first, we will take a measurement of the distance of the tree and second, we will display the likelihood for this observed distance on the brown strip inside the race track. By pressing the __UPDATE STEP__ button, we will perform our update step and show the resulting posterior at the outer strip. Now we are ready for the next time step. Take an action, by pressing the corresponding button below the race track. After the step is performed, you have to update your posterior by pressing the __PREDICT STEP__ button. You will see that the outer strip will change accordingly. Now we finished one full cycle of the filtering process and are ready to start a new cycle by taking a measurement.

If you want to reset the environment, just press the reset button in the bottom left corner.
As before you can control the car by using your keyboard: **A** (Backward), **S** (Stop),  **D** (Forward) or the buttons below the race track.

We see, that it is actually working pretty well. But one thing seems particularly weird: At certain positions on the race track, the brownish inner strip (our likelihood) seems to be uniformly distributed. This is not a bug, but a shortcoming of the linearization. We will always experience this behavior, if the part of the road at our current posterior mean is pointing only in _tangential_ direction, with the tree as the center. In other words: A small change in position wouldn't change the distance. When we are linearizing, we assume this local behavior applies for the whole system and we won't get any new information out of our measurement. To get an intuitive understanding of this, you can imagine two parallel lines. Our car is driving along one of the parallel lines and we take the nearest distance to the other line as a measurement. This measurement would be uninformative because the distance to the parallel line is always the same.




# Acknowledgement

The vector graphics of the [car](https://www.freepik.com/free-photos-vectors/car) were created by [Freepik](https://www.freepik.com/).



<a href='https://www.freepik.com/free-vector/flat-car-collection-with-side-view_1505022.htm'></a>


<div id="rad_to_s" style="width:100px"></div>
<div id="div1"></div>
<div id="div2"></div>
<!-- <div id="system_dist_approx"  style="width: 600px; height: 600px;"></div> -->
<!--<div id="output_dist_approx"  style="width: 600px; height: 600px;"></div>-->
<script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_SVG"></script>
<script type="text/x-mathjax-config">

var mq = window.matchMedia( "(max-width: 570px)" );
if (!mq.matches) {
    MathJax.Hub.Config({
	  CommonHTML: { linebreaks: { automatic: true } },
	  "HTML-CSS": { linebreaks: { automatic: true } },
	         SVG: { linebreaks: { automatic: true } }
	}); 
} 

</script>








